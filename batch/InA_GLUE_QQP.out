n27
0: n27
0: /home/kangchen/inhibited_lora/batch
08/06/2025 09:12:10 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
08/06/2025 09:12:10 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=output_final/BERT_large/QQP/InA00/runs/Aug06_09-12-10_n27,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=output_final/BERT_large/QQP/InA00/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=output_final/BERT_large/QQP/InA00/,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
08/06/2025 09:12:12 - INFO - datasets.builder - Generating dataset glue (/home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
08/06/2025 09:12:12 - INFO - datasets.builder - Downloading and preparing dataset glue/qqp to /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c...
08/06/2025 09:12:13 - INFO - datasets.download.download_manager - Downloading took 0.0 min
08/06/2025 09:12:13 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
08/06/2025 09:12:13 - INFO - datasets.builder - Generating train split
08/06/2025 09:12:13 - INFO - datasets.builder - Generating validation split
08/06/2025 09:12:13 - INFO - datasets.builder - Generating test split
08/06/2025 09:12:14 - INFO - datasets.utils.info_utils - All the splits matched successfully.
08/06/2025 09:12:14 - INFO - datasets.builder - Dataset glue downloaded and prepared to /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c. Subsequent calls will reuse this data.
The task type of PEFT is not proper!
LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='bert-large-cased', revision=None, task_type=<TaskType.SEQ_CLS: 'SEQ_CLS'>, inference_mode=False, r=4, target_modules={'value', 'query', 'key'}, lora_inhibition=0.0, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
###############
PeftModelForSequenceClassification(
  (base_model): LoraModel(
    (model): BertForSequenceClassification(
      (bert): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 1024, padding_idx=0)
          (position_embeddings): Embedding(512, 1024)
          (token_type_embeddings): Embedding(2, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0-23): 24 x BertLayer(
              (attention): BertAttention(
                (self): BertSdpaSelfAttention(
                  (query): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (key): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (value): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): ModulesToSaveWrapper(
        (original_module): Linear(in_features=1024, out_features=2, bias=True)
        (modules_to_save): ModuleDict(
          (default): Linear(in_features=1024, out_features=2, bias=True)
        )
      )
    )
  )
)
08/06/2025 09:12:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-67caa5d6ed8c4c99.arrow
08/06/2025 09:13:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-8a2e82b549ebd9cb.arrow
08/06/2025 09:13:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-3f2b69d8f7ead7aa.arrow
08/06/2025 09:14:03 - INFO - __main__ - Class distribution in train set:
08/06/2025 09:14:03 - INFO - __main__ -   Label 0: 229468 (63.07%)
08/06/2025 09:14:03 - INFO - __main__ -   Label 1: 134378 (36.93%)
08/06/2025 09:14:04 - INFO - __main__ - Class distribution in validation set:
08/06/2025 09:14:04 - INFO - __main__ -   Label 0: 25545 (63.18%)
08/06/2025 09:14:04 - INFO - __main__ -   Label 1: 14885 (36.82%)
08/06/2025 09:14:08 - INFO - __main__ - Class distribution in test set:
08/06/2025 09:14:08 - INFO - __main__ -   Label -1: 390965 (100.00%)
08/06/2025 09:14:08 - INFO - __main__ - Sample 335243 of the training set: {'question1': 'How do I crack JEE in a month?', 'question2': 'How do I crack JEE in 4-5 months?', 'label': 0, 'idx': 335243, 'input_ids': [101, 1731, 1202, 146, 8672, 147, 27073, 1107, 170, 2370, 136, 102, 1731, 1202, 146, 8672, 147, 27073, 1107, 125, 118, 126, 1808, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/06/2025 09:14:08 - INFO - __main__ - Sample 58369 of the training set: {'question1': 'Who are the greatest people in the world?', 'question2': 'Can you name some people who have really saved the world?', 'label': 0, 'idx': 58369, 'input_ids': [101, 2627, 1132, 1103, 4459, 1234, 1107, 1103, 1362, 136, 102, 2825, 1128, 1271, 1199, 1234, 1150, 1138, 1541, 4987, 1103, 1362, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/06/2025 09:14:08 - INFO - __main__ - Sample 13112 of the training set: {'question1': 'What is inside a Camel Crush cigarette?', 'question2': 'Are Camel Crush cigarettes designed to attract teen smokers?', 'label': 0, 'idx': 13112, 'input_ids': [101, 1327, 1110, 1656, 170, 23878, 1233, 140, 15432, 9983, 136, 102, 2372, 23878, 1233, 140, 15432, 16595, 2011, 1106, 9781, 13964, 5427, 1733, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/06/2025 09:14:09 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.5785, 'grad_norm': 12.660313606262207, 'learning_rate': 4.994514192739826e-05, 'epoch': 0.01}
{'loss': 0.4874, 'grad_norm': 5.074657917022705, 'learning_rate': 4.989017391877927e-05, 'epoch': 0.02}
{'loss': 0.4669, 'grad_norm': 5.384535789489746, 'learning_rate': 4.983520591016029e-05, 'epoch': 0.03}
{'loss': 0.4448, 'grad_norm': 4.975497245788574, 'learning_rate': 4.97802379015413e-05, 'epoch': 0.04}
{'loss': 0.4398, 'grad_norm': 3.30680513381958, 'learning_rate': 4.9725269892922324e-05, 'epoch': 0.05}
{'loss': 0.4334, 'grad_norm': 6.759955406188965, 'learning_rate': 4.967030188430334e-05, 'epoch': 0.07}
{'loss': 0.4327, 'grad_norm': 6.073638439178467, 'learning_rate': 4.9615333875684354e-05, 'epoch': 0.08}
{'loss': 0.3927, 'grad_norm': 12.468738555908203, 'learning_rate': 4.956036586706537e-05, 'epoch': 0.09}
{'loss': 0.406, 'grad_norm': 4.8412065505981445, 'learning_rate': 4.9505397858446385e-05, 'epoch': 0.1}
{'loss': 0.413, 'grad_norm': 8.260411262512207, 'learning_rate': 4.94504298498274e-05, 'epoch': 0.11}
{'loss': 0.384, 'grad_norm': 9.500689506530762, 'learning_rate': 4.9395461841208415e-05, 'epoch': 0.12}
{'loss': 0.3921, 'grad_norm': 11.622321128845215, 'learning_rate': 4.934049383258944e-05, 'epoch': 0.13}
{'loss': 0.403, 'grad_norm': 26.99121856689453, 'learning_rate': 4.928552582397045e-05, 'epoch': 0.14}
{'loss': 0.3909, 'grad_norm': 8.335683822631836, 'learning_rate': 4.923055781535147e-05, 'epoch': 0.15}
{'loss': 0.3762, 'grad_norm': 5.5474629402160645, 'learning_rate': 4.917558980673249e-05, 'epoch': 0.16}
{'loss': 0.3846, 'grad_norm': 4.500017166137695, 'learning_rate': 4.9120621798113504e-05, 'epoch': 0.18}
{'loss': 0.383, 'grad_norm': 3.8221800327301025, 'learning_rate': 4.906565378949451e-05, 'epoch': 0.19}
{'loss': 0.3878, 'grad_norm': 1.268046498298645, 'learning_rate': 4.9010685780875534e-05, 'epoch': 0.2}
{'loss': 0.3775, 'grad_norm': 6.653203964233398, 'learning_rate': 4.895571777225655e-05, 'epoch': 0.21}
{'loss': 0.3855, 'grad_norm': 4.123987197875977, 'learning_rate': 4.8900749763637565e-05, 'epoch': 0.22}
{'loss': 0.3727, 'grad_norm': 2.909237861633301, 'learning_rate': 4.884578175501858e-05, 'epoch': 0.23}
{'loss': 0.3849, 'grad_norm': 6.25817346572876, 'learning_rate': 4.87908137463996e-05, 'epoch': 0.24}
{'loss': 0.3718, 'grad_norm': 13.480652809143066, 'learning_rate': 4.873584573778062e-05, 'epoch': 0.25}
{'loss': 0.3633, 'grad_norm': 4.780261993408203, 'learning_rate': 4.8680877729161625e-05, 'epoch': 0.26}
{'loss': 0.3675, 'grad_norm': 12.493049621582031, 'learning_rate': 4.862590972054265e-05, 'epoch': 0.27}
{'loss': 0.3675, 'grad_norm': 12.899275779724121, 'learning_rate': 4.857094171192366e-05, 'epoch': 0.29}
{'loss': 0.3802, 'grad_norm': 6.799164295196533, 'learning_rate': 4.851597370330468e-05, 'epoch': 0.3}
{'loss': 0.3636, 'grad_norm': 7.8045806884765625, 'learning_rate': 4.84610056946857e-05, 'epoch': 0.31}
{'loss': 0.3741, 'grad_norm': 4.4612860679626465, 'learning_rate': 4.8406037686066714e-05, 'epoch': 0.32}
{'loss': 0.3901, 'grad_norm': 3.1498043537139893, 'learning_rate': 4.835106967744773e-05, 'epoch': 0.33}
{'loss': 0.3583, 'grad_norm': 4.975426197052002, 'learning_rate': 4.8296101668828744e-05, 'epoch': 0.34}
{'loss': 0.3617, 'grad_norm': 8.131381034851074, 'learning_rate': 4.824113366020976e-05, 'epoch': 0.35}
{'loss': 0.3717, 'grad_norm': 6.214816570281982, 'learning_rate': 4.8186165651590775e-05, 'epoch': 0.36}
{'loss': 0.3666, 'grad_norm': 4.601458549499512, 'learning_rate': 4.813119764297179e-05, 'epoch': 0.37}
{'loss': 0.3523, 'grad_norm': 7.476944446563721, 'learning_rate': 4.807622963435281e-05, 'epoch': 0.38}
{'loss': 0.3567, 'grad_norm': 4.409537315368652, 'learning_rate': 4.802126162573383e-05, 'epoch': 0.4}
{'loss': 0.362, 'grad_norm': 2.3782947063446045, 'learning_rate': 4.796629361711484e-05, 'epoch': 0.41}
{'loss': 0.3652, 'grad_norm': 14.420434951782227, 'learning_rate': 4.791132560849586e-05, 'epoch': 0.42}
{'loss': 0.3548, 'grad_norm': 15.60116195678711, 'learning_rate': 4.785635759987687e-05, 'epoch': 0.43}
{'loss': 0.3449, 'grad_norm': 3.4788053035736084, 'learning_rate': 4.780138959125789e-05, 'epoch': 0.44}
{'loss': 0.3648, 'grad_norm': 4.821088790893555, 'learning_rate': 4.774642158263891e-05, 'epoch': 0.45}
{'loss': 0.3596, 'grad_norm': 9.566584587097168, 'learning_rate': 4.7691453574019924e-05, 'epoch': 0.46}
{'loss': 0.3491, 'grad_norm': 4.819116115570068, 'learning_rate': 4.763648556540094e-05, 'epoch': 0.47}
{'loss': 0.3642, 'grad_norm': 6.5861687660217285, 'learning_rate': 4.7581517556781954e-05, 'epoch': 0.48}
{'loss': 0.3449, 'grad_norm': 14.750572204589844, 'learning_rate': 4.7526549548162976e-05, 'epoch': 0.49}
{'loss': 0.3641, 'grad_norm': 6.100365161895752, 'learning_rate': 4.7471581539543985e-05, 'epoch': 0.51}
{'loss': 0.3678, 'grad_norm': 16.624481201171875, 'learning_rate': 4.7416613530925e-05, 'epoch': 0.52}
{'loss': 0.3445, 'grad_norm': 9.18799114227295, 'learning_rate': 4.736164552230602e-05, 'epoch': 0.53}
{'loss': 0.3441, 'grad_norm': 7.6170477867126465, 'learning_rate': 4.730667751368704e-05, 'epoch': 0.54}
{'loss': 0.3533, 'grad_norm': 7.2432122230529785, 'learning_rate': 4.725170950506805e-05, 'epoch': 0.55}
{'loss': 0.3496, 'grad_norm': 14.112428665161133, 'learning_rate': 4.7196741496449074e-05, 'epoch': 0.56}
{'loss': 0.3672, 'grad_norm': 9.928651809692383, 'learning_rate': 4.714177348783009e-05, 'epoch': 0.57}
{'loss': 0.3644, 'grad_norm': 1.3449090719223022, 'learning_rate': 4.70868054792111e-05, 'epoch': 0.58}
{'loss': 0.3492, 'grad_norm': 4.952566146850586, 'learning_rate': 4.703183747059212e-05, 'epoch': 0.59}
{'loss': 0.338, 'grad_norm': 7.056711673736572, 'learning_rate': 4.6976869461973134e-05, 'epoch': 0.6}
{'loss': 0.3554, 'grad_norm': 3.1022658348083496, 'learning_rate': 4.692190145335415e-05, 'epoch': 0.62}
{'loss': 0.3503, 'grad_norm': 0.8288804888725281, 'learning_rate': 4.6866933444735164e-05, 'epoch': 0.63}
{'loss': 0.3391, 'grad_norm': 1.7743088006973267, 'learning_rate': 4.6811965436116186e-05, 'epoch': 0.64}
{'loss': 0.3482, 'grad_norm': 9.428120613098145, 'learning_rate': 4.67569974274972e-05, 'epoch': 0.65}
{'loss': 0.3465, 'grad_norm': 8.651213645935059, 'learning_rate': 4.670202941887821e-05, 'epoch': 0.66}
{'loss': 0.3306, 'grad_norm': 4.1347432136535645, 'learning_rate': 4.664706141025923e-05, 'epoch': 0.67}
{'loss': 0.3507, 'grad_norm': 6.125527381896973, 'learning_rate': 4.659209340164025e-05, 'epoch': 0.68}
{'loss': 0.3482, 'grad_norm': 4.868486404418945, 'learning_rate': 4.653712539302126e-05, 'epoch': 0.69}
{'loss': 0.3392, 'grad_norm': 8.24593448638916, 'learning_rate': 4.6482157384402284e-05, 'epoch': 0.7}
{'loss': 0.3356, 'grad_norm': 2.8034331798553467, 'learning_rate': 4.64271893757833e-05, 'epoch': 0.71}
{'loss': 0.3303, 'grad_norm': 5.757754325866699, 'learning_rate': 4.6372221367164314e-05, 'epoch': 0.73}
{'loss': 0.3382, 'grad_norm': 8.36219310760498, 'learning_rate': 4.631725335854533e-05, 'epoch': 0.74}
{'loss': 0.3536, 'grad_norm': 5.216170787811279, 'learning_rate': 4.6262285349926344e-05, 'epoch': 0.75}
{'loss': 0.3454, 'grad_norm': 4.911902904510498, 'learning_rate': 4.620731734130736e-05, 'epoch': 0.76}
{'loss': 0.3345, 'grad_norm': 7.381763935089111, 'learning_rate': 4.6152349332688374e-05, 'epoch': 0.77}
{'loss': 0.3376, 'grad_norm': 5.534759998321533, 'learning_rate': 4.6097381324069396e-05, 'epoch': 0.78}
{'loss': 0.3468, 'grad_norm': 10.861287117004395, 'learning_rate': 4.604241331545041e-05, 'epoch': 0.79}
{'loss': 0.3201, 'grad_norm': 8.038270950317383, 'learning_rate': 4.5987445306831427e-05, 'epoch': 0.8}
{'loss': 0.3395, 'grad_norm': 5.9085612297058105, 'learning_rate': 4.593247729821245e-05, 'epoch': 0.81}
{'loss': 0.3405, 'grad_norm': 3.917942762374878, 'learning_rate': 4.587750928959346e-05, 'epoch': 0.82}
{'loss': 0.3436, 'grad_norm': 11.806559562683105, 'learning_rate': 4.582254128097447e-05, 'epoch': 0.84}
{'loss': 0.3456, 'grad_norm': 5.344921588897705, 'learning_rate': 4.5767573272355494e-05, 'epoch': 0.85}
{'loss': 0.3318, 'grad_norm': 2.7331180572509766, 'learning_rate': 4.571260526373651e-05, 'epoch': 0.86}
{'loss': 0.3381, 'grad_norm': 5.556344985961914, 'learning_rate': 4.5657637255117524e-05, 'epoch': 0.87}
{'loss': 0.3578, 'grad_norm': 3.0379350185394287, 'learning_rate': 4.560266924649854e-05, 'epoch': 0.88}
{'loss': 0.3309, 'grad_norm': 10.484158515930176, 'learning_rate': 4.554770123787956e-05, 'epoch': 0.89}
{'loss': 0.3391, 'grad_norm': 4.727932453155518, 'learning_rate': 4.549273322926057e-05, 'epoch': 0.9}
{'loss': 0.3312, 'grad_norm': 1.4484784603118896, 'learning_rate': 4.5437765220641584e-05, 'epoch': 0.91}
{'loss': 0.3428, 'grad_norm': 3.9162023067474365, 'learning_rate': 4.5382797212022606e-05, 'epoch': 0.92}
{'loss': 0.3469, 'grad_norm': 13.400925636291504, 'learning_rate': 4.532782920340362e-05, 'epoch': 0.93}
{'loss': 0.3358, 'grad_norm': 7.244716644287109, 'learning_rate': 4.5272861194784637e-05, 'epoch': 0.95}
{'loss': 0.3324, 'grad_norm': 50.04055404663086, 'learning_rate': 4.521789318616566e-05, 'epoch': 0.96}
{'loss': 0.3342, 'grad_norm': 1.5928322076797485, 'learning_rate': 4.5162925177546674e-05, 'epoch': 0.97}
{'loss': 0.3222, 'grad_norm': 2.406778335571289, 'learning_rate': 4.510795716892768e-05, 'epoch': 0.98}
{'loss': 0.3415, 'grad_norm': 7.802639961242676, 'learning_rate': 4.5052989160308704e-05, 'epoch': 0.99}
{'loss': 0.3323, 'grad_norm': 6.250036716461182, 'learning_rate': 4.499802115168972e-05, 'epoch': 1.0}
{'loss': 0.3142, 'grad_norm': 5.126342296600342, 'learning_rate': 4.4943053143070734e-05, 'epoch': 1.01}
{'loss': 0.3245, 'grad_norm': 5.8610920906066895, 'learning_rate': 4.488808513445175e-05, 'epoch': 1.02}
{'loss': 0.3399, 'grad_norm': 11.111745834350586, 'learning_rate': 4.483311712583277e-05, 'epoch': 1.03}
{'loss': 0.3094, 'grad_norm': 2.3276267051696777, 'learning_rate': 4.4778149117213786e-05, 'epoch': 1.04}
{'loss': 0.3553, 'grad_norm': 10.724480628967285, 'learning_rate': 4.47231811085948e-05, 'epoch': 1.06}
{'loss': 0.3229, 'grad_norm': 6.816959381103516, 'learning_rate': 4.4668213099975816e-05, 'epoch': 1.07}
{'loss': 0.3281, 'grad_norm': 9.322823524475098, 'learning_rate': 4.461324509135683e-05, 'epoch': 1.08}
{'loss': 0.3194, 'grad_norm': 4.714510917663574, 'learning_rate': 4.4558277082737847e-05, 'epoch': 1.09}
{'loss': 0.327, 'grad_norm': 7.4790873527526855, 'learning_rate': 4.450330907411887e-05, 'epoch': 1.1}
{'loss': 0.3338, 'grad_norm': 13.549468040466309, 'learning_rate': 4.4448341065499884e-05, 'epoch': 1.11}
{'loss': 0.315, 'grad_norm': 11.970882415771484, 'learning_rate': 4.43933730568809e-05, 'epoch': 1.12}
{'loss': 0.3299, 'grad_norm': 10.85252571105957, 'learning_rate': 4.4338405048261914e-05, 'epoch': 1.13}
{'loss': 0.3254, 'grad_norm': 10.784136772155762, 'learning_rate': 4.428343703964293e-05, 'epoch': 1.14}
{'loss': 0.339, 'grad_norm': 1.622444748878479, 'learning_rate': 4.4228469031023944e-05, 'epoch': 1.15}
{'loss': 0.3359, 'grad_norm': 43.40085983276367, 'learning_rate': 4.417350102240496e-05, 'epoch': 1.17}
{'loss': 0.3243, 'grad_norm': 2.5507776737213135, 'learning_rate': 4.411853301378598e-05, 'epoch': 1.18}
{'loss': 0.3116, 'grad_norm': 7.1784796714782715, 'learning_rate': 4.4063565005166996e-05, 'epoch': 1.19}
{'loss': 0.3304, 'grad_norm': 6.748432636260986, 'learning_rate': 4.400859699654801e-05, 'epoch': 1.2}
{'loss': 0.3276, 'grad_norm': 6.946142673492432, 'learning_rate': 4.3953628987929026e-05, 'epoch': 1.21}
{'loss': 0.3086, 'grad_norm': 1.9610453844070435, 'learning_rate': 4.389866097931004e-05, 'epoch': 1.22}
{'loss': 0.3252, 'grad_norm': 14.188645362854004, 'learning_rate': 4.384369297069106e-05, 'epoch': 1.23}
{'loss': 0.3249, 'grad_norm': 5.430747032165527, 'learning_rate': 4.378872496207208e-05, 'epoch': 1.24}
{'loss': 0.3212, 'grad_norm': 9.545607566833496, 'learning_rate': 4.3733756953453094e-05, 'epoch': 1.25}
{'loss': 0.3168, 'grad_norm': 9.018916130065918, 'learning_rate': 4.367878894483411e-05, 'epoch': 1.26}
{'loss': 0.3099, 'grad_norm': 1.2648240327835083, 'learning_rate': 4.3623820936215124e-05, 'epoch': 1.28}
{'loss': 0.3137, 'grad_norm': 6.8696513175964355, 'learning_rate': 4.3568852927596146e-05, 'epoch': 1.29}
{'loss': 0.311, 'grad_norm': 6.86074686050415, 'learning_rate': 4.3513884918977154e-05, 'epoch': 1.3}
{'loss': 0.3279, 'grad_norm': 6.923558235168457, 'learning_rate': 4.345891691035817e-05, 'epoch': 1.31}
{'loss': 0.3164, 'grad_norm': 6.823428630828857, 'learning_rate': 4.340394890173919e-05, 'epoch': 1.32}
{'loss': 0.317, 'grad_norm': 15.35879898071289, 'learning_rate': 4.3348980893120206e-05, 'epoch': 1.33}
{'loss': 0.3064, 'grad_norm': 10.110989570617676, 'learning_rate': 4.329401288450122e-05, 'epoch': 1.34}
{'loss': 0.3284, 'grad_norm': 11.222654342651367, 'learning_rate': 4.3239044875882236e-05, 'epoch': 1.35}
{'loss': 0.3181, 'grad_norm': 6.541056156158447, 'learning_rate': 4.318407686726326e-05, 'epoch': 1.36}
{'loss': 0.3353, 'grad_norm': 10.668859481811523, 'learning_rate': 4.3129108858644273e-05, 'epoch': 1.37}
{'loss': 0.3207, 'grad_norm': 4.842268943786621, 'learning_rate': 4.307414085002529e-05, 'epoch': 1.39}
{'loss': 0.3222, 'grad_norm': 11.421856880187988, 'learning_rate': 4.3019172841406304e-05, 'epoch': 1.4}
{'loss': 0.317, 'grad_norm': 8.708451271057129, 'learning_rate': 4.296420483278732e-05, 'epoch': 1.41}
{'loss': 0.311, 'grad_norm': 11.524147033691406, 'learning_rate': 4.2909236824168334e-05, 'epoch': 1.42}
{'loss': 0.314, 'grad_norm': 8.493680000305176, 'learning_rate': 4.2854268815549356e-05, 'epoch': 1.43}
{'loss': 0.3156, 'grad_norm': 8.822970390319824, 'learning_rate': 4.279930080693037e-05, 'epoch': 1.44}
{'loss': 0.3142, 'grad_norm': 4.579957485198975, 'learning_rate': 4.2744332798311386e-05, 'epoch': 1.45}
{'loss': 0.3189, 'grad_norm': 8.91949462890625, 'learning_rate': 4.26893647896924e-05, 'epoch': 1.46}
{'loss': 0.3186, 'grad_norm': 11.067248344421387, 'learning_rate': 4.2634396781073416e-05, 'epoch': 1.47}
{'loss': 0.3252, 'grad_norm': 1.258942723274231, 'learning_rate': 4.257942877245443e-05, 'epoch': 1.48}
{'loss': 0.3249, 'grad_norm': 9.3698091506958, 'learning_rate': 4.2524460763835446e-05, 'epoch': 1.5}
{'loss': 0.3012, 'grad_norm': 9.80678939819336, 'learning_rate': 4.246949275521647e-05, 'epoch': 1.51}
{'loss': 0.336, 'grad_norm': 12.210348129272461, 'learning_rate': 4.2414524746597483e-05, 'epoch': 1.52}
{'loss': 0.3104, 'grad_norm': 10.103690147399902, 'learning_rate': 4.23595567379785e-05, 'epoch': 1.53}
{'loss': 0.3141, 'grad_norm': 12.642767906188965, 'learning_rate': 4.2304588729359514e-05, 'epoch': 1.54}
{'loss': 0.3199, 'grad_norm': 12.4256591796875, 'learning_rate': 4.224962072074053e-05, 'epoch': 1.55}
{'loss': 0.3162, 'grad_norm': 2.297490358352661, 'learning_rate': 4.2194652712121544e-05, 'epoch': 1.56}
{'loss': 0.3368, 'grad_norm': 7.098315715789795, 'learning_rate': 4.2139684703502566e-05, 'epoch': 1.57}
{'loss': 0.3222, 'grad_norm': 9.446782112121582, 'learning_rate': 4.208471669488358e-05, 'epoch': 1.58}
{'loss': 0.3324, 'grad_norm': 2.159083366394043, 'learning_rate': 4.2029748686264596e-05, 'epoch': 1.59}
{'loss': 0.3275, 'grad_norm': 8.672493934631348, 'learning_rate': 4.197478067764561e-05, 'epoch': 1.61}
{'loss': 0.3022, 'grad_norm': 59.90230941772461, 'learning_rate': 4.1919812669026626e-05, 'epoch': 1.62}
{'loss': 0.302, 'grad_norm': 3.7299256324768066, 'learning_rate': 4.186484466040764e-05, 'epoch': 1.63}
{'loss': 0.3326, 'grad_norm': 1.9799489974975586, 'learning_rate': 4.1809876651788657e-05, 'epoch': 1.64}
{'loss': 0.3341, 'grad_norm': 3.5191292762756348, 'learning_rate': 4.175490864316968e-05, 'epoch': 1.65}
{'loss': 0.3223, 'grad_norm': 8.155940055847168, 'learning_rate': 4.1699940634550694e-05, 'epoch': 1.66}
{'loss': 0.3161, 'grad_norm': 11.969199180603027, 'learning_rate': 4.164497262593171e-05, 'epoch': 1.67}
{'loss': 0.3111, 'grad_norm': 6.272096157073975, 'learning_rate': 4.159000461731273e-05, 'epoch': 1.68}
{'loss': 0.2978, 'grad_norm': 8.18444538116455, 'learning_rate': 4.1535036608693746e-05, 'epoch': 1.69}
{'loss': 0.3115, 'grad_norm': 3.5265398025512695, 'learning_rate': 4.1480068600074754e-05, 'epoch': 1.7}
{'loss': 0.3332, 'grad_norm': 11.159759521484375, 'learning_rate': 4.1425100591455776e-05, 'epoch': 1.72}
{'loss': 0.3041, 'grad_norm': 3.9695756435394287, 'learning_rate': 4.137013258283679e-05, 'epoch': 1.73}
{'loss': 0.3217, 'grad_norm': 9.84706974029541, 'learning_rate': 4.1315164574217806e-05, 'epoch': 1.74}
{'loss': 0.3215, 'grad_norm': 1.5455602407455444, 'learning_rate': 4.126019656559882e-05, 'epoch': 1.75}
{'loss': 0.3153, 'grad_norm': 9.262640953063965, 'learning_rate': 4.120522855697984e-05, 'epoch': 1.76}
{'loss': 0.3038, 'grad_norm': 14.162032127380371, 'learning_rate': 4.115026054836086e-05, 'epoch': 1.77}
{'loss': 0.3048, 'grad_norm': 13.123693466186523, 'learning_rate': 4.1095292539741867e-05, 'epoch': 1.78}
{'loss': 0.3161, 'grad_norm': 1.0989173650741577, 'learning_rate': 4.104032453112289e-05, 'epoch': 1.79}
{'loss': 0.3166, 'grad_norm': 5.385015487670898, 'learning_rate': 4.0985356522503904e-05, 'epoch': 1.8}
{'loss': 0.3074, 'grad_norm': 1.5322954654693604, 'learning_rate': 4.093038851388492e-05, 'epoch': 1.81}
{'loss': 0.3194, 'grad_norm': 11.671422004699707, 'learning_rate': 4.087542050526594e-05, 'epoch': 1.82}
{'loss': 0.3223, 'grad_norm': 14.900120735168457, 'learning_rate': 4.0820452496646956e-05, 'epoch': 1.84}
{'loss': 0.3229, 'grad_norm': 7.150140285491943, 'learning_rate': 4.076548448802797e-05, 'epoch': 1.85}
{'loss': 0.3125, 'grad_norm': 10.951445579528809, 'learning_rate': 4.0710516479408986e-05, 'epoch': 1.86}
{'loss': 0.3361, 'grad_norm': 5.4015092849731445, 'learning_rate': 4.065554847079e-05, 'epoch': 1.87}
{'loss': 0.3112, 'grad_norm': 6.9761128425598145, 'learning_rate': 4.0600580462171016e-05, 'epoch': 1.88}
{'loss': 0.3294, 'grad_norm': 1.6438030004501343, 'learning_rate': 4.054561245355203e-05, 'epoch': 1.89}
{'loss': 0.3033, 'grad_norm': 12.635666847229004, 'learning_rate': 4.049064444493305e-05, 'epoch': 1.9}
{'loss': 0.3088, 'grad_norm': 1.8293393850326538, 'learning_rate': 4.043567643631407e-05, 'epoch': 1.91}
{'loss': 0.3126, 'grad_norm': 9.099433898925781, 'learning_rate': 4.038070842769508e-05, 'epoch': 1.92}
{'loss': 0.329, 'grad_norm': 7.671930313110352, 'learning_rate': 4.0325740419076105e-05, 'epoch': 1.93}
{'loss': 0.3199, 'grad_norm': 1.3941655158996582, 'learning_rate': 4.0270772410457114e-05, 'epoch': 1.95}
{'loss': 0.3108, 'grad_norm': 9.637309074401855, 'learning_rate': 4.021580440183813e-05, 'epoch': 1.96}
{'loss': 0.3042, 'grad_norm': 0.9559910297393799, 'learning_rate': 4.016083639321915e-05, 'epoch': 1.97}
{'loss': 0.3387, 'grad_norm': 1.0116803646087646, 'learning_rate': 4.0105868384600166e-05, 'epoch': 1.98}
{'loss': 0.311, 'grad_norm': 0.8181836009025574, 'learning_rate': 4.005090037598118e-05, 'epoch': 1.99}
{'loss': 0.315, 'grad_norm': 9.865342140197754, 'learning_rate': 3.9995932367362196e-05, 'epoch': 2.0}
{'loss': 0.3039, 'grad_norm': 10.645466804504395, 'learning_rate': 3.994096435874322e-05, 'epoch': 2.01}
{'loss': 0.3006, 'grad_norm': 2.6725611686706543, 'learning_rate': 3.9885996350124226e-05, 'epoch': 2.02}
{'loss': 0.3114, 'grad_norm': 8.495718955993652, 'learning_rate': 3.983102834150524e-05, 'epoch': 2.03}
{'loss': 0.3101, 'grad_norm': 4.050534725189209, 'learning_rate': 3.977606033288626e-05, 'epoch': 2.04}
{'loss': 0.3034, 'grad_norm': 9.678757667541504, 'learning_rate': 3.972109232426728e-05, 'epoch': 2.06}
{'loss': 0.3031, 'grad_norm': 7.1358842849731445, 'learning_rate': 3.9666124315648293e-05, 'epoch': 2.07}
{'loss': 0.3061, 'grad_norm': 1.185701608657837, 'learning_rate': 3.9611156307029315e-05, 'epoch': 2.08}
{'loss': 0.2968, 'grad_norm': 5.692849636077881, 'learning_rate': 3.955618829841033e-05, 'epoch': 2.09}
{'loss': 0.3211, 'grad_norm': 2.2216100692749023, 'learning_rate': 3.950122028979134e-05, 'epoch': 2.1}
{'loss': 0.3008, 'grad_norm': 11.643511772155762, 'learning_rate': 3.944625228117236e-05, 'epoch': 2.11}
{'loss': 0.3194, 'grad_norm': 7.496740818023682, 'learning_rate': 3.9391284272553376e-05, 'epoch': 2.12}
{'loss': 0.3113, 'grad_norm': 3.3536930084228516, 'learning_rate': 3.933631626393439e-05, 'epoch': 2.13}
{'loss': 0.3048, 'grad_norm': 8.354691505432129, 'learning_rate': 3.9281348255315406e-05, 'epoch': 2.14}
{'loss': 0.3175, 'grad_norm': 9.404593467712402, 'learning_rate': 3.922638024669643e-05, 'epoch': 2.15}
{'loss': 0.3189, 'grad_norm': 15.68801212310791, 'learning_rate': 3.917141223807744e-05, 'epoch': 2.17}
{'loss': 0.3011, 'grad_norm': 0.9393897652626038, 'learning_rate': 3.911644422945845e-05, 'epoch': 2.18}
{'loss': 0.3161, 'grad_norm': 6.319961071014404, 'learning_rate': 3.906147622083947e-05, 'epoch': 2.19}
{'loss': 0.3026, 'grad_norm': 0.25479209423065186, 'learning_rate': 3.900650821222049e-05, 'epoch': 2.2}
{'loss': 0.301, 'grad_norm': 1.4826370477676392, 'learning_rate': 3.8951540203601503e-05, 'epoch': 2.21}
{'loss': 0.3018, 'grad_norm': 12.064138412475586, 'learning_rate': 3.8896572194982525e-05, 'epoch': 2.22}
{'loss': 0.3121, 'grad_norm': 2.757827043533325, 'learning_rate': 3.884160418636354e-05, 'epoch': 2.23}
{'loss': 0.296, 'grad_norm': 9.334854125976562, 'learning_rate': 3.8786636177744556e-05, 'epoch': 2.24}
{'loss': 0.2808, 'grad_norm': 11.124839782714844, 'learning_rate': 3.873166816912557e-05, 'epoch': 2.25}
{'loss': 0.3158, 'grad_norm': 10.933819770812988, 'learning_rate': 3.8676700160506586e-05, 'epoch': 2.26}
{'loss': 0.3178, 'grad_norm': 10.800768852233887, 'learning_rate': 3.86217321518876e-05, 'epoch': 2.28}
{'loss': 0.302, 'grad_norm': 8.5425443649292, 'learning_rate': 3.8566764143268616e-05, 'epoch': 2.29}
{'loss': 0.3117, 'grad_norm': 6.126797676086426, 'learning_rate': 3.851179613464964e-05, 'epoch': 2.3}
{'loss': 0.3047, 'grad_norm': 9.902619361877441, 'learning_rate': 3.845682812603065e-05, 'epoch': 2.31}
{'loss': 0.2941, 'grad_norm': 6.866889476776123, 'learning_rate': 3.840186011741167e-05, 'epoch': 2.32}
{'loss': 0.315, 'grad_norm': 12.1033296585083, 'learning_rate': 3.834689210879269e-05, 'epoch': 2.33}
{'loss': 0.3058, 'grad_norm': 9.344437599182129, 'learning_rate': 3.82919241001737e-05, 'epoch': 2.34}
{'loss': 0.3053, 'grad_norm': 1.799941897392273, 'learning_rate': 3.8236956091554713e-05, 'epoch': 2.35}
{'loss': 0.2994, 'grad_norm': 2.097012758255005, 'learning_rate': 3.8181988082935735e-05, 'epoch': 2.36}
{'loss': 0.3233, 'grad_norm': 3.5548250675201416, 'learning_rate': 3.812702007431675e-05, 'epoch': 2.37}
{'loss': 0.2944, 'grad_norm': 0.5422198176383972, 'learning_rate': 3.8072052065697766e-05, 'epoch': 2.39}
{'loss': 0.2807, 'grad_norm': 0.31997764110565186, 'learning_rate': 3.801708405707878e-05, 'epoch': 2.4}
{'loss': 0.3087, 'grad_norm': 5.933233261108398, 'learning_rate': 3.79621160484598e-05, 'epoch': 2.41}
{'loss': 0.2966, 'grad_norm': 6.728976249694824, 'learning_rate': 3.790714803984081e-05, 'epoch': 2.42}
{'loss': 0.2822, 'grad_norm': 4.2829718589782715, 'learning_rate': 3.7852180031221826e-05, 'epoch': 2.43}
{'loss': 0.3023, 'grad_norm': 0.5274419784545898, 'learning_rate': 3.779721202260285e-05, 'epoch': 2.44}
{'loss': 0.3292, 'grad_norm': 9.847600936889648, 'learning_rate': 3.774224401398386e-05, 'epoch': 2.45}
{'loss': 0.3052, 'grad_norm': 7.965893268585205, 'learning_rate': 3.768727600536488e-05, 'epoch': 2.46}
{'loss': 0.2935, 'grad_norm': 20.956584930419922, 'learning_rate': 3.76323079967459e-05, 'epoch': 2.47}
{'loss': 0.2835, 'grad_norm': 1.0456161499023438, 'learning_rate': 3.7577339988126915e-05, 'epoch': 2.48}
{'loss': 0.3199, 'grad_norm': 1.101731300354004, 'learning_rate': 3.752237197950793e-05, 'epoch': 2.5}
{'loss': 0.3039, 'grad_norm': 4.554466247558594, 'learning_rate': 3.7467403970888945e-05, 'epoch': 2.51}
{'loss': 0.3099, 'grad_norm': 1.063336730003357, 'learning_rate': 3.741243596226996e-05, 'epoch': 2.52}
{'loss': 0.2975, 'grad_norm': 3.494676113128662, 'learning_rate': 3.7357467953650976e-05, 'epoch': 2.53}
{'loss': 0.2876, 'grad_norm': 7.187907695770264, 'learning_rate': 3.730249994503199e-05, 'epoch': 2.54}
{'loss': 0.3021, 'grad_norm': 0.7576963305473328, 'learning_rate': 3.724753193641301e-05, 'epoch': 2.55}
{'loss': 0.305, 'grad_norm': 1.4913263320922852, 'learning_rate': 3.719256392779403e-05, 'epoch': 2.56}
{'loss': 0.3026, 'grad_norm': 10.317115783691406, 'learning_rate': 3.713759591917504e-05, 'epoch': 2.57}
{'loss': 0.2917, 'grad_norm': 13.697500228881836, 'learning_rate': 3.708262791055606e-05, 'epoch': 2.58}
{'loss': 0.2973, 'grad_norm': 6.44077730178833, 'learning_rate': 3.702765990193707e-05, 'epoch': 2.59}
{'loss': 0.2943, 'grad_norm': 7.023762226104736, 'learning_rate': 3.697269189331809e-05, 'epoch': 2.61}
{'loss': 0.3194, 'grad_norm': 19.223806381225586, 'learning_rate': 3.691772388469911e-05, 'epoch': 2.62}
{'loss': 0.3023, 'grad_norm': 8.380880355834961, 'learning_rate': 3.6862755876080125e-05, 'epoch': 2.63}
{'loss': 0.2949, 'grad_norm': 11.10332202911377, 'learning_rate': 3.680778786746114e-05, 'epoch': 2.64}
{'loss': 0.3036, 'grad_norm': 2.5547420978546143, 'learning_rate': 3.6752819858842155e-05, 'epoch': 2.65}
{'loss': 0.3035, 'grad_norm': 10.149148941040039, 'learning_rate': 3.669785185022317e-05, 'epoch': 2.66}
{'loss': 0.3112, 'grad_norm': 1.7927303314208984, 'learning_rate': 3.6642883841604186e-05, 'epoch': 2.67}
{'loss': 0.3221, 'grad_norm': 6.049162864685059, 'learning_rate': 3.65879158329852e-05, 'epoch': 2.68}
{'loss': 0.3009, 'grad_norm': 4.089443206787109, 'learning_rate': 3.653294782436622e-05, 'epoch': 2.69}
{'loss': 0.2916, 'grad_norm': 18.39468765258789, 'learning_rate': 3.647797981574724e-05, 'epoch': 2.7}
{'loss': 0.2789, 'grad_norm': 0.5081496834754944, 'learning_rate': 3.642301180712825e-05, 'epoch': 2.72}
{'loss': 0.3083, 'grad_norm': 13.047924041748047, 'learning_rate': 3.6368043798509275e-05, 'epoch': 2.73}
{'loss': 0.3002, 'grad_norm': 13.293658256530762, 'learning_rate': 3.631307578989028e-05, 'epoch': 2.74}
{'loss': 0.3092, 'grad_norm': 13.249524116516113, 'learning_rate': 3.62581077812713e-05, 'epoch': 2.75}
{'loss': 0.3058, 'grad_norm': 19.654735565185547, 'learning_rate': 3.620313977265232e-05, 'epoch': 2.76}
{'loss': 0.3015, 'grad_norm': 14.121988296508789, 'learning_rate': 3.6148171764033335e-05, 'epoch': 2.77}
{'loss': 0.3018, 'grad_norm': 12.813506126403809, 'learning_rate': 3.609320375541435e-05, 'epoch': 2.78}
{'loss': 0.3043, 'grad_norm': 11.71113395690918, 'learning_rate': 3.6038235746795365e-05, 'epoch': 2.79}
{'loss': 0.3059, 'grad_norm': 12.854676246643066, 'learning_rate': 3.598326773817639e-05, 'epoch': 2.8}
{'loss': 0.2926, 'grad_norm': 0.5513259172439575, 'learning_rate': 3.59282997295574e-05, 'epoch': 2.81}
{'loss': 0.2905, 'grad_norm': 13.774333953857422, 'learning_rate': 3.587333172093841e-05, 'epoch': 2.83}
{'loss': 0.2969, 'grad_norm': 8.444316864013672, 'learning_rate': 3.581836371231943e-05, 'epoch': 2.84}
{'loss': 0.3031, 'grad_norm': 5.209111213684082, 'learning_rate': 3.576339570370045e-05, 'epoch': 2.85}
{'loss': 0.3031, 'grad_norm': 4.918737888336182, 'learning_rate': 3.570842769508146e-05, 'epoch': 2.86}
{'loss': 0.2973, 'grad_norm': 16.64807891845703, 'learning_rate': 3.5653459686462485e-05, 'epoch': 2.87}
{'loss': 0.294, 'grad_norm': 12.479476928710938, 'learning_rate': 3.55984916778435e-05, 'epoch': 2.88}
{'loss': 0.2996, 'grad_norm': 1.2764140367507935, 'learning_rate': 3.5543523669224515e-05, 'epoch': 2.89}
{'loss': 0.2882, 'grad_norm': 6.306889057159424, 'learning_rate': 3.548855566060553e-05, 'epoch': 2.9}
{'loss': 0.3029, 'grad_norm': 13.864242553710938, 'learning_rate': 3.5433587651986545e-05, 'epoch': 2.91}
{'loss': 0.285, 'grad_norm': 4.046827793121338, 'learning_rate': 3.537861964336756e-05, 'epoch': 2.92}
{'loss': 0.2983, 'grad_norm': 1.2483056783676147, 'learning_rate': 3.5323651634748575e-05, 'epoch': 2.94}
{'loss': 0.2985, 'grad_norm': 10.385467529296875, 'learning_rate': 3.52686836261296e-05, 'epoch': 2.95}
{'loss': 0.2998, 'grad_norm': 9.135749816894531, 'learning_rate': 3.521371561751061e-05, 'epoch': 2.96}
{'loss': 0.3006, 'grad_norm': 5.7887187004089355, 'learning_rate': 3.515874760889163e-05, 'epoch': 2.97}
{'loss': 0.2929, 'grad_norm': 11.468867301940918, 'learning_rate': 3.510377960027264e-05, 'epoch': 2.98}
{'loss': 0.2994, 'grad_norm': 7.03387451171875, 'learning_rate': 3.504881159165366e-05, 'epoch': 2.99}
{'loss': 0.2847, 'grad_norm': 4.151477336883545, 'learning_rate': 3.499384358303467e-05, 'epoch': 3.0}
{'loss': 0.296, 'grad_norm': 0.63908451795578, 'learning_rate': 3.4938875574415695e-05, 'epoch': 3.01}
{'loss': 0.3051, 'grad_norm': 6.63067102432251, 'learning_rate': 3.488390756579671e-05, 'epoch': 3.02}
{'loss': 0.2909, 'grad_norm': 9.608457565307617, 'learning_rate': 3.4828939557177725e-05, 'epoch': 3.03}
{'loss': 0.2943, 'grad_norm': 38.31596374511719, 'learning_rate': 3.477397154855874e-05, 'epoch': 3.05}
{'loss': 0.3051, 'grad_norm': 0.4342547357082367, 'learning_rate': 3.4719003539939755e-05, 'epoch': 3.06}
{'loss': 0.2884, 'grad_norm': 7.807497978210449, 'learning_rate': 3.466403553132077e-05, 'epoch': 3.07}
{'loss': 0.2843, 'grad_norm': 5.541719913482666, 'learning_rate': 3.4609067522701786e-05, 'epoch': 3.08}
{'loss': 0.2957, 'grad_norm': 0.37382790446281433, 'learning_rate': 3.455409951408281e-05, 'epoch': 3.09}
{'loss': 0.2954, 'grad_norm': 16.81133270263672, 'learning_rate': 3.449913150546382e-05, 'epoch': 3.1}
{'loss': 0.2818, 'grad_norm': 14.021695137023926, 'learning_rate': 3.444416349684484e-05, 'epoch': 3.11}
{'loss': 0.2863, 'grad_norm': 7.998987197875977, 'learning_rate': 3.438919548822585e-05, 'epoch': 3.12}
{'loss': 0.2884, 'grad_norm': 7.910961627960205, 'learning_rate': 3.4334227479606875e-05, 'epoch': 3.13}
{'loss': 0.2968, 'grad_norm': 9.19328498840332, 'learning_rate': 3.427925947098788e-05, 'epoch': 3.14}
{'loss': 0.2842, 'grad_norm': 1.1894488334655762, 'learning_rate': 3.42242914623689e-05, 'epoch': 3.16}
{'loss': 0.2919, 'grad_norm': 4.250494003295898, 'learning_rate': 3.416932345374992e-05, 'epoch': 3.17}
{'loss': 0.2854, 'grad_norm': 1.1123703718185425, 'learning_rate': 3.4114355445130935e-05, 'epoch': 3.18}
{'loss': 0.288, 'grad_norm': 1.50236976146698, 'learning_rate': 3.405938743651195e-05, 'epoch': 3.19}
{'loss': 0.2871, 'grad_norm': 0.5388885736465454, 'learning_rate': 3.400441942789297e-05, 'epoch': 3.2}
{'loss': 0.2849, 'grad_norm': 7.373965740203857, 'learning_rate': 3.394945141927399e-05, 'epoch': 3.21}
{'loss': 0.3122, 'grad_norm': 14.169344902038574, 'learning_rate': 3.3894483410654996e-05, 'epoch': 3.22}
{'loss': 0.2933, 'grad_norm': 7.653840065002441, 'learning_rate': 3.383951540203602e-05, 'epoch': 3.23}
{'loss': 0.2696, 'grad_norm': 19.90491485595703, 'learning_rate': 3.378454739341703e-05, 'epoch': 3.24}
{'loss': 0.2954, 'grad_norm': 16.71002769470215, 'learning_rate': 3.372957938479805e-05, 'epoch': 3.25}
{'loss': 0.2992, 'grad_norm': 8.204931259155273, 'learning_rate': 3.367461137617906e-05, 'epoch': 3.27}
{'loss': 0.3091, 'grad_norm': 15.129700660705566, 'learning_rate': 3.3619643367560085e-05, 'epoch': 3.28}
{'loss': 0.2916, 'grad_norm': 7.756717681884766, 'learning_rate': 3.35646753589411e-05, 'epoch': 3.29}
{'loss': 0.2804, 'grad_norm': 12.551115036010742, 'learning_rate': 3.350970735032211e-05, 'epoch': 3.3}
{'loss': 0.3079, 'grad_norm': 6.938497543334961, 'learning_rate': 3.345473934170313e-05, 'epoch': 3.31}
{'loss': 0.3087, 'grad_norm': 0.8755176067352295, 'learning_rate': 3.3399771333084145e-05, 'epoch': 3.32}
{'loss': 0.2968, 'grad_norm': 13.346745491027832, 'learning_rate': 3.334480332446516e-05, 'epoch': 3.33}
{'loss': 0.2889, 'grad_norm': 15.3798246383667, 'learning_rate': 3.328983531584618e-05, 'epoch': 3.34}
{'loss': 0.2931, 'grad_norm': 11.675865173339844, 'learning_rate': 3.32348673072272e-05, 'epoch': 3.35}
{'loss': 0.2891, 'grad_norm': 3.3035695552825928, 'learning_rate': 3.317989929860821e-05, 'epoch': 3.36}
{'loss': 0.2838, 'grad_norm': 5.506224632263184, 'learning_rate': 3.312493128998923e-05, 'epoch': 3.38}
{'loss': 0.2924, 'grad_norm': 0.5243566632270813, 'learning_rate': 3.306996328137024e-05, 'epoch': 3.39}
{'loss': 0.2944, 'grad_norm': 9.33509635925293, 'learning_rate': 3.301499527275126e-05, 'epoch': 3.4}
{'loss': 0.3037, 'grad_norm': 0.5014046430587769, 'learning_rate': 3.296002726413227e-05, 'epoch': 3.41}
{'loss': 0.3044, 'grad_norm': 5.47611665725708, 'learning_rate': 3.2905059255513295e-05, 'epoch': 3.42}
{'loss': 0.3027, 'grad_norm': 91.87459564208984, 'learning_rate': 3.285009124689431e-05, 'epoch': 3.43}
{'loss': 0.3041, 'grad_norm': 16.05875587463379, 'learning_rate': 3.2795123238275325e-05, 'epoch': 3.44}
{'loss': 0.2757, 'grad_norm': 18.708093643188477, 'learning_rate': 3.274015522965635e-05, 'epoch': 3.45}
{'loss': 0.3023, 'grad_norm': 7.951850414276123, 'learning_rate': 3.2685187221037355e-05, 'epoch': 3.46}
{'loss': 0.2808, 'grad_norm': 2.5825109481811523, 'learning_rate': 3.263021921241837e-05, 'epoch': 3.47}
{'loss': 0.2869, 'grad_norm': 17.3467960357666, 'learning_rate': 3.257525120379939e-05, 'epoch': 3.48}
{'loss': 0.2849, 'grad_norm': 17.970930099487305, 'learning_rate': 3.252028319518041e-05, 'epoch': 3.5}
{'loss': 0.2792, 'grad_norm': 16.126754760742188, 'learning_rate': 3.246531518656142e-05, 'epoch': 3.51}
{'loss': 0.276, 'grad_norm': 1.4622963666915894, 'learning_rate': 3.241034717794244e-05, 'epoch': 3.52}
{'loss': 0.2942, 'grad_norm': 6.16251802444458, 'learning_rate': 3.235537916932346e-05, 'epoch': 3.53}
{'loss': 0.2907, 'grad_norm': 10.926855087280273, 'learning_rate': 3.230041116070447e-05, 'epoch': 3.54}
{'loss': 0.2799, 'grad_norm': 10.533696174621582, 'learning_rate': 3.224544315208548e-05, 'epoch': 3.55}
{'loss': 0.2923, 'grad_norm': 14.110986709594727, 'learning_rate': 3.2190475143466505e-05, 'epoch': 3.56}
{'loss': 0.2876, 'grad_norm': 4.057143211364746, 'learning_rate': 3.213550713484752e-05, 'epoch': 3.57}
{'loss': 0.2848, 'grad_norm': 11.691658973693848, 'learning_rate': 3.2080539126228535e-05, 'epoch': 3.58}
{'loss': 0.2902, 'grad_norm': 2.7102091312408447, 'learning_rate': 3.202557111760956e-05, 'epoch': 3.59}
{'loss': 0.2916, 'grad_norm': 6.770330429077148, 'learning_rate': 3.197060310899057e-05, 'epoch': 3.61}
{'loss': 0.3035, 'grad_norm': 1.212012529373169, 'learning_rate': 3.191563510037158e-05, 'epoch': 3.62}
{'loss': 0.2961, 'grad_norm': 12.022546768188477, 'learning_rate': 3.18606670917526e-05, 'epoch': 3.63}
{'loss': 0.2737, 'grad_norm': 11.471626281738281, 'learning_rate': 3.180569908313362e-05, 'epoch': 3.64}
{'loss': 0.2803, 'grad_norm': 1.8199399709701538, 'learning_rate': 3.175073107451463e-05, 'epoch': 3.65}
{'loss': 0.2841, 'grad_norm': 0.49397334456443787, 'learning_rate': 3.169576306589565e-05, 'epoch': 3.66}
{'loss': 0.2995, 'grad_norm': 6.156454563140869, 'learning_rate': 3.164079505727667e-05, 'epoch': 3.67}
{'loss': 0.2767, 'grad_norm': 6.8086957931518555, 'learning_rate': 3.1585827048657685e-05, 'epoch': 3.68}
{'loss': 0.2823, 'grad_norm': 0.3053564727306366, 'learning_rate': 3.15308590400387e-05, 'epoch': 3.69}
{'loss': 0.3101, 'grad_norm': 12.513322830200195, 'learning_rate': 3.1475891031419715e-05, 'epoch': 3.7}
{'loss': 0.2913, 'grad_norm': 13.03089427947998, 'learning_rate': 3.142092302280073e-05, 'epoch': 3.72}
{'loss': 0.2982, 'grad_norm': 14.645920753479004, 'learning_rate': 3.1365955014181745e-05, 'epoch': 3.73}
{'loss': 0.3021, 'grad_norm': 0.6779377460479736, 'learning_rate': 3.131098700556277e-05, 'epoch': 3.74}
{'loss': 0.2771, 'grad_norm': 0.32249969244003296, 'learning_rate': 3.125601899694378e-05, 'epoch': 3.75}
{'loss': 0.2968, 'grad_norm': 6.418672561645508, 'learning_rate': 3.12010509883248e-05, 'epoch': 3.76}
{'loss': 0.2986, 'grad_norm': 7.455796241760254, 'learning_rate': 3.114608297970581e-05, 'epoch': 3.77}
{'loss': 0.3015, 'grad_norm': 6.8785552978515625, 'learning_rate': 3.109111497108683e-05, 'epoch': 3.78}
{'loss': 0.3059, 'grad_norm': 2.9195897579193115, 'learning_rate': 3.103614696246784e-05, 'epoch': 3.79}
{'loss': 0.2812, 'grad_norm': 0.8255017399787903, 'learning_rate': 3.098117895384886e-05, 'epoch': 3.8}
{'loss': 0.2902, 'grad_norm': 9.398905754089355, 'learning_rate': 3.092621094522988e-05, 'epoch': 3.81}
{'loss': 0.2939, 'grad_norm': 5.028994083404541, 'learning_rate': 3.0871242936610895e-05, 'epoch': 3.83}
{'loss': 0.2953, 'grad_norm': 6.00448751449585, 'learning_rate': 3.081627492799191e-05, 'epoch': 3.84}
{'loss': 0.2892, 'grad_norm': 11.38614559173584, 'learning_rate': 3.076130691937293e-05, 'epoch': 3.85}
{'loss': 0.2685, 'grad_norm': 8.052933692932129, 'learning_rate': 3.070633891075394e-05, 'epoch': 3.86}
{'loss': 0.2877, 'grad_norm': 19.311359405517578, 'learning_rate': 3.0651370902134955e-05, 'epoch': 3.87}
{'loss': 0.2867, 'grad_norm': 13.189095497131348, 'learning_rate': 3.059640289351598e-05, 'epoch': 3.88}
{'loss': 0.2923, 'grad_norm': 5.865490436553955, 'learning_rate': 3.054143488489699e-05, 'epoch': 3.89}
{'loss': 0.2859, 'grad_norm': 2.7876639366149902, 'learning_rate': 3.0486466876278007e-05, 'epoch': 3.9}
{'loss': 0.2996, 'grad_norm': 2.5812528133392334, 'learning_rate': 3.0431498867659026e-05, 'epoch': 3.91}
{'loss': 0.2993, 'grad_norm': 22.17088508605957, 'learning_rate': 3.037653085904004e-05, 'epoch': 3.92}
{'loss': 0.2882, 'grad_norm': 11.265103340148926, 'learning_rate': 3.032156285042106e-05, 'epoch': 3.94}
{'loss': 0.2925, 'grad_norm': 1.9530328512191772, 'learning_rate': 3.026659484180207e-05, 'epoch': 3.95}
{'loss': 0.2845, 'grad_norm': 14.542168617248535, 'learning_rate': 3.0211626833183086e-05, 'epoch': 3.96}
{'loss': 0.2884, 'grad_norm': 10.891446113586426, 'learning_rate': 3.0156658824564105e-05, 'epoch': 3.97}
{'loss': 0.2798, 'grad_norm': 9.870865821838379, 'learning_rate': 3.0101690815945123e-05, 'epoch': 3.98}
{'loss': 0.2934, 'grad_norm': 15.107434272766113, 'learning_rate': 3.0046722807326138e-05, 'epoch': 3.99}
{'loss': 0.2799, 'grad_norm': 2.980036973953247, 'learning_rate': 2.9991754798707157e-05, 'epoch': 4.0}
{'loss': 0.2768, 'grad_norm': 9.302570343017578, 'learning_rate': 2.9936786790088172e-05, 'epoch': 4.01}
{'loss': 0.3002, 'grad_norm': 1.0592466592788696, 'learning_rate': 2.9881818781469184e-05, 'epoch': 4.02}
{'loss': 0.2848, 'grad_norm': 2.493684768676758, 'learning_rate': 2.9826850772850202e-05, 'epoch': 4.03}
{'loss': 0.2748, 'grad_norm': 3.0801236629486084, 'learning_rate': 2.9771882764231217e-05, 'epoch': 4.05}
{'loss': 0.2707, 'grad_norm': 6.035112380981445, 'learning_rate': 2.9716914755612236e-05, 'epoch': 4.06}
{'loss': 0.2849, 'grad_norm': 9.477520942687988, 'learning_rate': 2.966194674699325e-05, 'epoch': 4.07}
{'loss': 0.2715, 'grad_norm': 0.4312649369239807, 'learning_rate': 2.960697873837427e-05, 'epoch': 4.08}
{'loss': 0.2862, 'grad_norm': 0.9321169257164001, 'learning_rate': 2.9552010729755288e-05, 'epoch': 4.09}
{'loss': 0.2849, 'grad_norm': 0.2938496768474579, 'learning_rate': 2.9497042721136296e-05, 'epoch': 4.1}
{'loss': 0.2884, 'grad_norm': 10.14545726776123, 'learning_rate': 2.9442074712517315e-05, 'epoch': 4.11}
{'loss': 0.2767, 'grad_norm': 10.802544593811035, 'learning_rate': 2.9387106703898333e-05, 'epoch': 4.12}
{'loss': 0.2643, 'grad_norm': 9.25711441040039, 'learning_rate': 2.9332138695279348e-05, 'epoch': 4.13}
{'loss': 0.2799, 'grad_norm': 0.5568578243255615, 'learning_rate': 2.9277170686660367e-05, 'epoch': 4.14}
{'loss': 0.2776, 'grad_norm': 14.10058879852295, 'learning_rate': 2.9222202678041382e-05, 'epoch': 4.16}
{'loss': 0.2802, 'grad_norm': 0.27841830253601074, 'learning_rate': 2.91672346694224e-05, 'epoch': 4.17}
{'loss': 0.2679, 'grad_norm': 9.741232872009277, 'learning_rate': 2.9112266660803412e-05, 'epoch': 4.18}
{'loss': 0.2782, 'grad_norm': 0.33416494727134705, 'learning_rate': 2.9057298652184427e-05, 'epoch': 4.19}
{'loss': 0.2702, 'grad_norm': 20.807531356811523, 'learning_rate': 2.9002330643565446e-05, 'epoch': 4.2}
{'loss': 0.2985, 'grad_norm': 4.990043640136719, 'learning_rate': 2.894736263494646e-05, 'epoch': 4.21}
{'loss': 0.2875, 'grad_norm': 12.40206527709961, 'learning_rate': 2.889239462632748e-05, 'epoch': 4.22}
{'loss': 0.2646, 'grad_norm': 7.094698429107666, 'learning_rate': 2.8837426617708498e-05, 'epoch': 4.23}
{'loss': 0.2946, 'grad_norm': 12.614456176757812, 'learning_rate': 2.8782458609089513e-05, 'epoch': 4.24}
{'loss': 0.2803, 'grad_norm': 12.409491539001465, 'learning_rate': 2.872749060047053e-05, 'epoch': 4.25}
{'loss': 0.2891, 'grad_norm': 21.68822479248047, 'learning_rate': 2.8672522591851543e-05, 'epoch': 4.27}
{'loss': 0.2924, 'grad_norm': 11.497876167297363, 'learning_rate': 2.861755458323256e-05, 'epoch': 4.28}
{'loss': 0.2715, 'grad_norm': 8.792983055114746, 'learning_rate': 2.8562586574613577e-05, 'epoch': 4.29}
{'loss': 0.2802, 'grad_norm': 9.291259765625, 'learning_rate': 2.8507618565994592e-05, 'epoch': 4.3}
{'loss': 0.2952, 'grad_norm': 14.404077529907227, 'learning_rate': 2.845265055737561e-05, 'epoch': 4.31}
{'loss': 0.2672, 'grad_norm': 14.871371269226074, 'learning_rate': 2.8397682548756626e-05, 'epoch': 4.32}
{'loss': 0.2729, 'grad_norm': 7.801172256469727, 'learning_rate': 2.8342714540137644e-05, 'epoch': 4.33}
{'loss': 0.2918, 'grad_norm': 6.270750522613525, 'learning_rate': 2.8287746531518656e-05, 'epoch': 4.34}
{'loss': 0.292, 'grad_norm': 0.4025278389453888, 'learning_rate': 2.823277852289967e-05, 'epoch': 4.35}
{'loss': 0.2671, 'grad_norm': 0.3161731958389282, 'learning_rate': 2.817781051428069e-05, 'epoch': 4.36}
{'loss': 0.2951, 'grad_norm': 6.233709335327148, 'learning_rate': 2.8122842505661705e-05, 'epoch': 4.38}
{'loss': 0.2738, 'grad_norm': 0.673202633857727, 'learning_rate': 2.8067874497042723e-05, 'epoch': 4.39}
{'loss': 0.2662, 'grad_norm': 13.60539722442627, 'learning_rate': 2.801290648842374e-05, 'epoch': 4.4}
{'loss': 0.2787, 'grad_norm': 1.9216920137405396, 'learning_rate': 2.7957938479804757e-05, 'epoch': 4.41}
{'loss': 0.2795, 'grad_norm': 15.355144500732422, 'learning_rate': 2.790297047118577e-05, 'epoch': 4.42}
{'loss': 0.2784, 'grad_norm': 7.8315606117248535, 'learning_rate': 2.7848002462566787e-05, 'epoch': 4.43}
{'loss': 0.2632, 'grad_norm': 7.8024725914001465, 'learning_rate': 2.7793034453947802e-05, 'epoch': 4.44}
{'loss': 0.2781, 'grad_norm': 19.893861770629883, 'learning_rate': 2.773806644532882e-05, 'epoch': 4.45}
{'loss': 0.2849, 'grad_norm': 7.059620380401611, 'learning_rate': 2.7683098436709836e-05, 'epoch': 4.46}
{'loss': 0.2765, 'grad_norm': 1.010055422782898, 'learning_rate': 2.7628130428090854e-05, 'epoch': 4.47}
{'loss': 0.2842, 'grad_norm': 18.69727325439453, 'learning_rate': 2.757316241947187e-05, 'epoch': 4.49}
{'loss': 0.274, 'grad_norm': 6.222092628479004, 'learning_rate': 2.751819441085288e-05, 'epoch': 4.5}
{'loss': 0.275, 'grad_norm': 8.013936996459961, 'learning_rate': 2.74632264022339e-05, 'epoch': 4.51}
{'loss': 0.2851, 'grad_norm': 10.256958961486816, 'learning_rate': 2.7408258393614915e-05, 'epoch': 4.52}
{'loss': 0.2705, 'grad_norm': 8.52966594696045, 'learning_rate': 2.7353290384995933e-05, 'epoch': 4.53}
{'loss': 0.2835, 'grad_norm': 1.0093050003051758, 'learning_rate': 2.729832237637695e-05, 'epoch': 4.54}
{'loss': 0.2957, 'grad_norm': 12.679258346557617, 'learning_rate': 2.7243354367757967e-05, 'epoch': 4.55}
{'loss': 0.2755, 'grad_norm': 21.51849365234375, 'learning_rate': 2.7188386359138985e-05, 'epoch': 4.56}
{'loss': 0.2871, 'grad_norm': 4.683279037475586, 'learning_rate': 2.713341835052e-05, 'epoch': 4.57}
{'loss': 0.2964, 'grad_norm': 17.53233528137207, 'learning_rate': 2.7078450341901012e-05, 'epoch': 4.58}
{'loss': 0.2718, 'grad_norm': 1.7800623178482056, 'learning_rate': 2.702348233328203e-05, 'epoch': 4.6}
{'loss': 0.2919, 'grad_norm': 17.32254981994629, 'learning_rate': 2.6968514324663046e-05, 'epoch': 4.61}
{'loss': 0.2917, 'grad_norm': 0.6261805295944214, 'learning_rate': 2.6913546316044064e-05, 'epoch': 4.62}
{'loss': 0.2802, 'grad_norm': 9.729216575622559, 'learning_rate': 2.685857830742508e-05, 'epoch': 4.63}
{'loss': 0.269, 'grad_norm': 0.7912858724594116, 'learning_rate': 2.6803610298806098e-05, 'epoch': 4.64}
{'loss': 0.2985, 'grad_norm': 10.349013328552246, 'learning_rate': 2.6748642290187116e-05, 'epoch': 4.65}
{'loss': 0.2824, 'grad_norm': 1.4406890869140625, 'learning_rate': 2.6693674281568125e-05, 'epoch': 4.66}
{'loss': 0.2859, 'grad_norm': 0.1872672736644745, 'learning_rate': 2.6638706272949143e-05, 'epoch': 4.67}
{'loss': 0.2713, 'grad_norm': 11.05215835571289, 'learning_rate': 2.658373826433016e-05, 'epoch': 4.68}
{'loss': 0.2759, 'grad_norm': 25.16408920288086, 'learning_rate': 2.6528770255711177e-05, 'epoch': 4.69}
{'loss': 0.2865, 'grad_norm': 13.880818367004395, 'learning_rate': 2.6473802247092195e-05, 'epoch': 4.71}
{'loss': 0.2912, 'grad_norm': 0.1247299388051033, 'learning_rate': 2.641883423847321e-05, 'epoch': 4.72}
{'loss': 0.2756, 'grad_norm': 13.998242378234863, 'learning_rate': 2.636386622985423e-05, 'epoch': 4.73}
{'loss': 0.2874, 'grad_norm': 11.941643714904785, 'learning_rate': 2.630889822123524e-05, 'epoch': 4.74}
{'loss': 0.2899, 'grad_norm': 1.483677625656128, 'learning_rate': 2.6253930212616256e-05, 'epoch': 4.75}
{'loss': 0.2882, 'grad_norm': 1.431413173675537, 'learning_rate': 2.6198962203997274e-05, 'epoch': 4.76}
{'loss': 0.2742, 'grad_norm': 17.06234359741211, 'learning_rate': 2.614399419537829e-05, 'epoch': 4.77}
{'loss': 0.2957, 'grad_norm': 0.4278561472892761, 'learning_rate': 2.6089026186759308e-05, 'epoch': 4.78}
{'loss': 0.2801, 'grad_norm': 11.261299133300781, 'learning_rate': 2.6034058178140326e-05, 'epoch': 4.79}
{'loss': 0.295, 'grad_norm': 5.906264305114746, 'learning_rate': 2.597909016952134e-05, 'epoch': 4.8}
{'loss': 0.2897, 'grad_norm': 26.210229873657227, 'learning_rate': 2.592412216090236e-05, 'epoch': 4.82}
{'loss': 0.2971, 'grad_norm': 6.645903587341309, 'learning_rate': 2.586915415228337e-05, 'epoch': 4.83}
{'loss': 0.2874, 'grad_norm': 9.25091552734375, 'learning_rate': 2.5814186143664387e-05, 'epoch': 4.84}
{'loss': 0.2698, 'grad_norm': 2.984302520751953, 'learning_rate': 2.5759218135045405e-05, 'epoch': 4.85}
{'loss': 0.2824, 'grad_norm': 9.211226463317871, 'learning_rate': 2.570425012642642e-05, 'epoch': 4.86}
{'loss': 0.285, 'grad_norm': 16.32169532775879, 'learning_rate': 2.564928211780744e-05, 'epoch': 4.87}
{'loss': 0.2814, 'grad_norm': 10.376031875610352, 'learning_rate': 2.5594314109188454e-05, 'epoch': 4.88}
{'loss': 0.3005, 'grad_norm': 19.765552520751953, 'learning_rate': 2.5539346100569472e-05, 'epoch': 4.89}
{'loss': 0.2821, 'grad_norm': 0.45602408051490784, 'learning_rate': 2.5484378091950484e-05, 'epoch': 4.9}
{'loss': 0.2765, 'grad_norm': 1.346720576286316, 'learning_rate': 2.54294100833315e-05, 'epoch': 4.91}
{'loss': 0.2759, 'grad_norm': 0.5892652869224548, 'learning_rate': 2.5374442074712518e-05, 'epoch': 4.93}
{'loss': 0.2752, 'grad_norm': 16.852113723754883, 'learning_rate': 2.5319474066093536e-05, 'epoch': 4.94}
{'loss': 0.2682, 'grad_norm': 0.3536875247955322, 'learning_rate': 2.526450605747455e-05, 'epoch': 4.95}
{'loss': 0.3007, 'grad_norm': 12.363527297973633, 'learning_rate': 2.520953804885557e-05, 'epoch': 4.96}
{'loss': 0.2818, 'grad_norm': 1.1149711608886719, 'learning_rate': 2.5154570040236585e-05, 'epoch': 4.97}
{'loss': 0.2851, 'grad_norm': 4.127918720245361, 'learning_rate': 2.5099602031617597e-05, 'epoch': 4.98}
{'loss': 0.2788, 'grad_norm': 7.331664562225342, 'learning_rate': 2.5044634022998615e-05, 'epoch': 4.99}
{'loss': 0.2696, 'grad_norm': 11.66906452178955, 'learning_rate': 2.498966601437963e-05, 'epoch': 5.0}
{'loss': 0.2838, 'grad_norm': 6.035951137542725, 'learning_rate': 2.493469800576065e-05, 'epoch': 5.01}
{'loss': 0.2757, 'grad_norm': 11.381061553955078, 'learning_rate': 2.4879729997141664e-05, 'epoch': 5.02}
{'loss': 0.2655, 'grad_norm': 1.3383537530899048, 'learning_rate': 2.4824761988522683e-05, 'epoch': 5.04}
{'loss': 0.273, 'grad_norm': 8.908550262451172, 'learning_rate': 2.4769793979903698e-05, 'epoch': 5.05}
{'loss': 0.2891, 'grad_norm': 0.34972140192985535, 'learning_rate': 2.4714825971284713e-05, 'epoch': 5.06}
{'loss': 0.301, 'grad_norm': 5.585142135620117, 'learning_rate': 2.465985796266573e-05, 'epoch': 5.07}
{'loss': 0.2752, 'grad_norm': 3.1081197261810303, 'learning_rate': 2.4604889954046746e-05, 'epoch': 5.08}
{'loss': 0.2778, 'grad_norm': 16.281269073486328, 'learning_rate': 2.454992194542776e-05, 'epoch': 5.09}
{'loss': 0.263, 'grad_norm': 9.074775695800781, 'learning_rate': 2.449495393680878e-05, 'epoch': 5.1}
{'loss': 0.2844, 'grad_norm': 12.635969161987305, 'learning_rate': 2.4439985928189795e-05, 'epoch': 5.11}
{'loss': 0.2761, 'grad_norm': 11.491802215576172, 'learning_rate': 2.438501791957081e-05, 'epoch': 5.12}
{'loss': 0.2741, 'grad_norm': 0.32805952429771423, 'learning_rate': 2.433004991095183e-05, 'epoch': 5.13}
{'loss': 0.2753, 'grad_norm': 0.5452677011489868, 'learning_rate': 2.4275081902332844e-05, 'epoch': 5.15}
{'loss': 0.2722, 'grad_norm': 18.636051177978516, 'learning_rate': 2.4220113893713862e-05, 'epoch': 5.16}
{'loss': 0.2756, 'grad_norm': 0.3345981240272522, 'learning_rate': 2.4165145885094874e-05, 'epoch': 5.17}
{'loss': 0.2715, 'grad_norm': 13.528042793273926, 'learning_rate': 2.4110177876475893e-05, 'epoch': 5.18}
{'loss': 0.2951, 'grad_norm': 2.0086822509765625, 'learning_rate': 2.4055209867856908e-05, 'epoch': 5.19}
{'loss': 0.2911, 'grad_norm': 14.498665809631348, 'learning_rate': 2.4000241859237923e-05, 'epoch': 5.2}
{'loss': 0.2911, 'grad_norm': 7.604376316070557, 'learning_rate': 2.394527385061894e-05, 'epoch': 5.21}
{'loss': 0.2531, 'grad_norm': 8.649808883666992, 'learning_rate': 2.3890305841999956e-05, 'epoch': 5.22}
{'loss': 0.2838, 'grad_norm': 2.0484209060668945, 'learning_rate': 2.3835337833380975e-05, 'epoch': 5.23}
{'loss': 0.2657, 'grad_norm': 13.586066246032715, 'learning_rate': 2.378036982476199e-05, 'epoch': 5.24}
{'loss': 0.269, 'grad_norm': 4.074124336242676, 'learning_rate': 2.3725401816143005e-05, 'epoch': 5.25}
{'loss': 0.2749, 'grad_norm': 46.605316162109375, 'learning_rate': 2.3670433807524024e-05, 'epoch': 5.27}
{'loss': 0.2502, 'grad_norm': 0.8337525129318237, 'learning_rate': 2.361546579890504e-05, 'epoch': 5.28}
{'loss': 0.2977, 'grad_norm': 3.1130142211914062, 'learning_rate': 2.3560497790286054e-05, 'epoch': 5.29}
{'loss': 0.2754, 'grad_norm': 0.3753397464752197, 'learning_rate': 2.3505529781667072e-05, 'epoch': 5.3}
{'loss': 0.2813, 'grad_norm': 9.35236930847168, 'learning_rate': 2.3450561773048087e-05, 'epoch': 5.31}
{'loss': 0.2841, 'grad_norm': 12.886363983154297, 'learning_rate': 2.3395593764429103e-05, 'epoch': 5.32}
{'loss': 0.2826, 'grad_norm': 0.5303388833999634, 'learning_rate': 2.3340625755810118e-05, 'epoch': 5.33}
{'loss': 0.2685, 'grad_norm': 0.20306125283241272, 'learning_rate': 2.3285657747191136e-05, 'epoch': 5.34}
{'loss': 0.2841, 'grad_norm': 20.73016357421875, 'learning_rate': 2.3230689738572155e-05, 'epoch': 5.35}
{'loss': 0.2677, 'grad_norm': 0.4133450388908386, 'learning_rate': 2.3175721729953166e-05, 'epoch': 5.36}
{'loss': 0.2834, 'grad_norm': 13.086383819580078, 'learning_rate': 2.3120753721334185e-05, 'epoch': 5.38}
{'loss': 0.2808, 'grad_norm': 12.282903671264648, 'learning_rate': 2.30657857127152e-05, 'epoch': 5.39}
{'loss': 0.2685, 'grad_norm': 0.5758650302886963, 'learning_rate': 2.3010817704096215e-05, 'epoch': 5.4}
{'loss': 0.2733, 'grad_norm': 0.913515031337738, 'learning_rate': 2.2955849695477234e-05, 'epoch': 5.41}
{'loss': 0.2606, 'grad_norm': 5.602423191070557, 'learning_rate': 2.290088168685825e-05, 'epoch': 5.42}
{'loss': 0.293, 'grad_norm': 12.185246467590332, 'learning_rate': 2.2845913678239267e-05, 'epoch': 5.43}
{'loss': 0.2606, 'grad_norm': 9.332497596740723, 'learning_rate': 2.2790945669620282e-05, 'epoch': 5.44}
{'loss': 0.3024, 'grad_norm': 15.638381004333496, 'learning_rate': 2.2735977661001297e-05, 'epoch': 5.45}
{'loss': 0.2793, 'grad_norm': 7.892204284667969, 'learning_rate': 2.2681009652382316e-05, 'epoch': 5.46}
{'loss': 0.2595, 'grad_norm': 0.5271374583244324, 'learning_rate': 2.262604164376333e-05, 'epoch': 5.47}
{'loss': 0.2724, 'grad_norm': 6.844726085662842, 'learning_rate': 2.2571073635144346e-05, 'epoch': 5.49}
{'loss': 0.2876, 'grad_norm': 2.488741159439087, 'learning_rate': 2.2516105626525365e-05, 'epoch': 5.5}
{'loss': 0.2701, 'grad_norm': 4.955134868621826, 'learning_rate': 2.246113761790638e-05, 'epoch': 5.51}
{'loss': 0.2651, 'grad_norm': 19.265901565551758, 'learning_rate': 2.2406169609287395e-05, 'epoch': 5.52}
{'loss': 0.2849, 'grad_norm': 6.597935676574707, 'learning_rate': 2.235120160066841e-05, 'epoch': 5.53}
{'loss': 0.2838, 'grad_norm': 12.157054901123047, 'learning_rate': 2.229623359204943e-05, 'epoch': 5.54}
{'loss': 0.2671, 'grad_norm': 14.59920597076416, 'learning_rate': 2.2241265583430447e-05, 'epoch': 5.55}
{'loss': 0.2595, 'grad_norm': 0.7690017223358154, 'learning_rate': 2.218629757481146e-05, 'epoch': 5.56}
{'loss': 0.2675, 'grad_norm': 28.348628997802734, 'learning_rate': 2.2131329566192477e-05, 'epoch': 5.57}
{'loss': 0.2928, 'grad_norm': 0.8166775703430176, 'learning_rate': 2.2076361557573492e-05, 'epoch': 5.58}
{'loss': 0.2771, 'grad_norm': 27.495237350463867, 'learning_rate': 2.202139354895451e-05, 'epoch': 5.6}
{'loss': 0.2796, 'grad_norm': 5.010690689086914, 'learning_rate': 2.1966425540335526e-05, 'epoch': 5.61}
{'loss': 0.2857, 'grad_norm': 8.571292877197266, 'learning_rate': 2.191145753171654e-05, 'epoch': 5.62}
{'loss': 0.2698, 'grad_norm': 19.500751495361328, 'learning_rate': 2.185648952309756e-05, 'epoch': 5.63}
{'loss': 0.2857, 'grad_norm': 9.32770824432373, 'learning_rate': 2.1801521514478575e-05, 'epoch': 5.64}
{'loss': 0.2863, 'grad_norm': 0.4631577432155609, 'learning_rate': 2.174655350585959e-05, 'epoch': 5.65}
{'loss': 0.2749, 'grad_norm': 12.864089965820312, 'learning_rate': 2.169158549724061e-05, 'epoch': 5.66}
{'loss': 0.2967, 'grad_norm': 0.25792744755744934, 'learning_rate': 2.1636617488621623e-05, 'epoch': 5.67}
{'loss': 0.2827, 'grad_norm': 16.9388484954834, 'learning_rate': 2.158164948000264e-05, 'epoch': 5.68}
{'loss': 0.2794, 'grad_norm': 7.523621082305908, 'learning_rate': 2.1526681471383657e-05, 'epoch': 5.69}
{'loss': 0.265, 'grad_norm': 16.111387252807617, 'learning_rate': 2.1471713462764672e-05, 'epoch': 5.71}
{'loss': 0.2614, 'grad_norm': 14.801931381225586, 'learning_rate': 2.1416745454145687e-05, 'epoch': 5.72}
{'loss': 0.2592, 'grad_norm': 7.158009052276611, 'learning_rate': 2.1361777445526702e-05, 'epoch': 5.73}
{'loss': 0.273, 'grad_norm': 7.957882404327393, 'learning_rate': 2.130680943690772e-05, 'epoch': 5.74}
{'loss': 0.2906, 'grad_norm': 8.201266288757324, 'learning_rate': 2.125184142828874e-05, 'epoch': 5.75}
{'loss': 0.2576, 'grad_norm': 28.154571533203125, 'learning_rate': 2.119687341966975e-05, 'epoch': 5.76}
{'loss': 0.287, 'grad_norm': 1.7552863359451294, 'learning_rate': 2.114190541105077e-05, 'epoch': 5.77}
{'loss': 0.2833, 'grad_norm': 0.49746382236480713, 'learning_rate': 2.1086937402431785e-05, 'epoch': 5.78}
{'loss': 0.2759, 'grad_norm': 0.6685019135475159, 'learning_rate': 2.1031969393812803e-05, 'epoch': 5.79}
{'loss': 0.2765, 'grad_norm': 10.25273609161377, 'learning_rate': 2.097700138519382e-05, 'epoch': 5.8}
{'loss': 0.2957, 'grad_norm': 14.122756004333496, 'learning_rate': 2.0922033376574834e-05, 'epoch': 5.82}
{'loss': 0.2647, 'grad_norm': 19.042037963867188, 'learning_rate': 2.0867065367955852e-05, 'epoch': 5.83}
{'loss': 0.278, 'grad_norm': 0.19651558995246887, 'learning_rate': 2.0812097359336867e-05, 'epoch': 5.84}
{'loss': 0.2699, 'grad_norm': 7.7542901039123535, 'learning_rate': 2.0757129350717882e-05, 'epoch': 5.85}
{'loss': 0.2902, 'grad_norm': 14.042734146118164, 'learning_rate': 2.07021613420989e-05, 'epoch': 5.86}
{'loss': 0.2757, 'grad_norm': 0.35630714893341064, 'learning_rate': 2.0647193333479916e-05, 'epoch': 5.87}
{'loss': 0.2637, 'grad_norm': 19.886438369750977, 'learning_rate': 2.059222532486093e-05, 'epoch': 5.88}
{'loss': 0.291, 'grad_norm': 0.49246740341186523, 'learning_rate': 2.053725731624195e-05, 'epoch': 5.89}
{'loss': 0.2803, 'grad_norm': 0.7969474196434021, 'learning_rate': 2.0482289307622965e-05, 'epoch': 5.9}
{'loss': 0.2668, 'grad_norm': 9.402531623840332, 'learning_rate': 2.0427321299003983e-05, 'epoch': 5.91}
{'loss': 0.2924, 'grad_norm': 0.5412302017211914, 'learning_rate': 2.0372353290384995e-05, 'epoch': 5.93}
{'loss': 0.2689, 'grad_norm': 22.80775260925293, 'learning_rate': 2.0317385281766013e-05, 'epoch': 5.94}
{'loss': 0.2782, 'grad_norm': 13.241375923156738, 'learning_rate': 2.0262417273147032e-05, 'epoch': 5.95}
{'loss': 0.2831, 'grad_norm': 17.45516014099121, 'learning_rate': 2.0207449264528044e-05, 'epoch': 5.96}
{'loss': 0.2795, 'grad_norm': 12.434664726257324, 'learning_rate': 2.0152481255909062e-05, 'epoch': 5.97}
{'loss': 0.271, 'grad_norm': 3.3043744564056396, 'learning_rate': 2.0097513247290077e-05, 'epoch': 5.98}
{'loss': 0.2905, 'grad_norm': 16.330381393432617, 'learning_rate': 2.0042545238671096e-05, 'epoch': 5.99}
{'loss': 0.2625, 'grad_norm': 7.6294426918029785, 'learning_rate': 1.998757723005211e-05, 'epoch': 6.0}
{'loss': 0.2819, 'grad_norm': 0.896478533744812, 'learning_rate': 1.9932609221433126e-05, 'epoch': 6.01}
{'loss': 0.2648, 'grad_norm': 17.469039916992188, 'learning_rate': 1.9877641212814144e-05, 'epoch': 6.02}
{'loss': 0.2589, 'grad_norm': 3.831825017929077, 'learning_rate': 1.982267320419516e-05, 'epoch': 6.04}
{'loss': 0.2672, 'grad_norm': 23.13195037841797, 'learning_rate': 1.9767705195576175e-05, 'epoch': 6.05}
{'loss': 0.2547, 'grad_norm': 7.1002912521362305, 'learning_rate': 1.9712737186957193e-05, 'epoch': 6.06}
{'loss': 0.2671, 'grad_norm': 2.0739102363586426, 'learning_rate': 1.9657769178338208e-05, 'epoch': 6.07}
{'loss': 0.2525, 'grad_norm': 820.1348266601562, 'learning_rate': 1.9602801169719223e-05, 'epoch': 6.08}
{'loss': 0.2842, 'grad_norm': 0.13700884580612183, 'learning_rate': 1.9547833161100242e-05, 'epoch': 6.09}
{'loss': 0.2871, 'grad_norm': 10.450754165649414, 'learning_rate': 1.9492865152481257e-05, 'epoch': 6.1}
{'loss': 0.2667, 'grad_norm': 1.4027057886123657, 'learning_rate': 1.9437897143862275e-05, 'epoch': 6.11}
{'loss': 0.2498, 'grad_norm': 17.552833557128906, 'learning_rate': 1.9382929135243287e-05, 'epoch': 6.12}
{'loss': 0.2877, 'grad_norm': 3.6855967044830322, 'learning_rate': 1.9327961126624306e-05, 'epoch': 6.13}
{'loss': 0.2687, 'grad_norm': 1.7342815399169922, 'learning_rate': 1.927299311800532e-05, 'epoch': 6.15}
{'loss': 0.2594, 'grad_norm': 12.510220527648926, 'learning_rate': 1.9218025109386336e-05, 'epoch': 6.16}
{'loss': 0.2573, 'grad_norm': 32.71046829223633, 'learning_rate': 1.9163057100767354e-05, 'epoch': 6.17}
{'loss': 0.2494, 'grad_norm': 13.37217903137207, 'learning_rate': 1.910808909214837e-05, 'epoch': 6.18}
{'loss': 0.267, 'grad_norm': 0.21316416561603546, 'learning_rate': 1.9053121083529388e-05, 'epoch': 6.19}
{'loss': 0.2783, 'grad_norm': 1.720728874206543, 'learning_rate': 1.8998153074910403e-05, 'epoch': 6.2}
{'loss': 0.2892, 'grad_norm': 10.208795547485352, 'learning_rate': 1.8943185066291418e-05, 'epoch': 6.21}
{'loss': 0.2564, 'grad_norm': 7.02426815032959, 'learning_rate': 1.8888217057672437e-05, 'epoch': 6.22}
{'loss': 0.2736, 'grad_norm': 13.644546508789062, 'learning_rate': 1.8833249049053452e-05, 'epoch': 6.23}
{'loss': 0.2404, 'grad_norm': 7.088092803955078, 'learning_rate': 1.8778281040434467e-05, 'epoch': 6.24}
{'loss': 0.2774, 'grad_norm': 0.44788858294487, 'learning_rate': 1.8723313031815486e-05, 'epoch': 6.26}
{'loss': 0.2516, 'grad_norm': 0.12719903886318207, 'learning_rate': 1.86683450231965e-05, 'epoch': 6.27}
{'loss': 0.2524, 'grad_norm': 11.777623176574707, 'learning_rate': 1.8613377014577516e-05, 'epoch': 6.28}
{'loss': 0.2695, 'grad_norm': 10.677752494812012, 'learning_rate': 1.855840900595853e-05, 'epoch': 6.29}
{'loss': 0.2863, 'grad_norm': 12.083273887634277, 'learning_rate': 1.850344099733955e-05, 'epoch': 6.3}
{'loss': 0.2567, 'grad_norm': 13.183741569519043, 'learning_rate': 1.8448472988720568e-05, 'epoch': 6.31}
{'loss': 0.2629, 'grad_norm': 25.343124389648438, 'learning_rate': 1.839350498010158e-05, 'epoch': 6.32}
{'loss': 0.2641, 'grad_norm': 4.699884414672852, 'learning_rate': 1.8338536971482598e-05, 'epoch': 6.33}
{'loss': 0.2776, 'grad_norm': 14.194457054138184, 'learning_rate': 1.8283568962863613e-05, 'epoch': 6.34}
{'loss': 0.2634, 'grad_norm': 1.4368342161178589, 'learning_rate': 1.8228600954244632e-05, 'epoch': 6.35}
{'loss': 0.2689, 'grad_norm': 11.70663833618164, 'learning_rate': 1.8173632945625647e-05, 'epoch': 6.37}
{'loss': 0.2716, 'grad_norm': 11.453720092773438, 'learning_rate': 1.8118664937006662e-05, 'epoch': 6.38}
{'loss': 0.2677, 'grad_norm': 0.25347796082496643, 'learning_rate': 1.806369692838768e-05, 'epoch': 6.39}
{'loss': 0.279, 'grad_norm': 1.2699402570724487, 'learning_rate': 1.8008728919768696e-05, 'epoch': 6.4}
{'loss': 0.2788, 'grad_norm': 13.40225887298584, 'learning_rate': 1.795376091114971e-05, 'epoch': 6.41}
{'loss': 0.2703, 'grad_norm': 7.943157196044922, 'learning_rate': 1.789879290253073e-05, 'epoch': 6.42}
{'loss': 0.2605, 'grad_norm': 1.4397212266921997, 'learning_rate': 1.7843824893911744e-05, 'epoch': 6.43}
{'loss': 0.2888, 'grad_norm': 23.88913345336914, 'learning_rate': 1.778885688529276e-05, 'epoch': 6.44}
{'loss': 0.2685, 'grad_norm': 14.224853515625, 'learning_rate': 1.7733888876673778e-05, 'epoch': 6.45}
{'loss': 0.2589, 'grad_norm': 2.399991512298584, 'learning_rate': 1.7678920868054793e-05, 'epoch': 6.46}
{'loss': 0.2807, 'grad_norm': 1.3966000080108643, 'learning_rate': 1.762395285943581e-05, 'epoch': 6.48}
{'loss': 0.2675, 'grad_norm': 1.0332376956939697, 'learning_rate': 1.7568984850816823e-05, 'epoch': 6.49}
{'loss': 0.2508, 'grad_norm': 11.71692180633545, 'learning_rate': 1.7514016842197842e-05, 'epoch': 6.5}
{'loss': 0.2726, 'grad_norm': 0.29394227266311646, 'learning_rate': 1.745904883357886e-05, 'epoch': 6.51}
{'loss': 0.2725, 'grad_norm': 12.305815696716309, 'learning_rate': 1.7404080824959872e-05, 'epoch': 6.52}
{'loss': 0.2631, 'grad_norm': 1.9142589569091797, 'learning_rate': 1.734911281634089e-05, 'epoch': 6.53}
{'loss': 0.2725, 'grad_norm': 9.228385925292969, 'learning_rate': 1.7294144807721906e-05, 'epoch': 6.54}
{'loss': 0.2743, 'grad_norm': 10.469792366027832, 'learning_rate': 1.7239176799102924e-05, 'epoch': 6.55}
{'loss': 0.2968, 'grad_norm': 8.856887817382812, 'learning_rate': 1.718420879048394e-05, 'epoch': 6.56}
{'loss': 0.2657, 'grad_norm': 0.42467254400253296, 'learning_rate': 1.7129240781864954e-05, 'epoch': 6.57}
{'loss': 0.2643, 'grad_norm': 0.040815047919750214, 'learning_rate': 1.7074272773245973e-05, 'epoch': 6.59}
{'loss': 0.2682, 'grad_norm': 0.7177983522415161, 'learning_rate': 1.7019304764626988e-05, 'epoch': 6.6}
{'loss': 0.2855, 'grad_norm': 2.8395352363586426, 'learning_rate': 1.6964336756008003e-05, 'epoch': 6.61}
{'loss': 0.2538, 'grad_norm': 7.50841760635376, 'learning_rate': 1.690936874738902e-05, 'epoch': 6.62}
{'loss': 0.2891, 'grad_norm': 34.11650466918945, 'learning_rate': 1.6854400738770037e-05, 'epoch': 6.63}
{'loss': 0.2775, 'grad_norm': 6.562036514282227, 'learning_rate': 1.6799432730151052e-05, 'epoch': 6.64}
{'loss': 0.2786, 'grad_norm': 21.881845474243164, 'learning_rate': 1.674446472153207e-05, 'epoch': 6.65}
{'loss': 0.2578, 'grad_norm': 3.174856185913086, 'learning_rate': 1.6689496712913085e-05, 'epoch': 6.66}
{'loss': 0.2654, 'grad_norm': 24.4919376373291, 'learning_rate': 1.6634528704294104e-05, 'epoch': 6.67}
{'loss': 0.2817, 'grad_norm': 0.3773067891597748, 'learning_rate': 1.6579560695675116e-05, 'epoch': 6.68}
{'loss': 0.267, 'grad_norm': 0.7594506740570068, 'learning_rate': 1.6524592687056134e-05, 'epoch': 6.7}
{'loss': 0.2947, 'grad_norm': 13.220117568969727, 'learning_rate': 1.6469624678437153e-05, 'epoch': 6.71}
{'loss': 0.2716, 'grad_norm': 0.8806545734405518, 'learning_rate': 1.6414656669818164e-05, 'epoch': 6.72}
{'loss': 0.2749, 'grad_norm': 7.150729656219482, 'learning_rate': 1.6359688661199183e-05, 'epoch': 6.73}
{'loss': 0.2641, 'grad_norm': 0.6124107837677002, 'learning_rate': 1.6304720652580198e-05, 'epoch': 6.74}
{'loss': 0.2436, 'grad_norm': 0.3848426938056946, 'learning_rate': 1.6249752643961216e-05, 'epoch': 6.75}
{'loss': 0.2792, 'grad_norm': 0.823664128780365, 'learning_rate': 1.619478463534223e-05, 'epoch': 6.76}
{'loss': 0.2684, 'grad_norm': 6.355714797973633, 'learning_rate': 1.6139816626723247e-05, 'epoch': 6.77}
{'loss': 0.2705, 'grad_norm': 6.7547993659973145, 'learning_rate': 1.6084848618104265e-05, 'epoch': 6.78}
{'loss': 0.2711, 'grad_norm': 0.5571535229682922, 'learning_rate': 1.602988060948528e-05, 'epoch': 6.79}
{'loss': 0.2955, 'grad_norm': 0.37588396668434143, 'learning_rate': 1.5974912600866295e-05, 'epoch': 6.81}
{'loss': 0.2733, 'grad_norm': 13.03355884552002, 'learning_rate': 1.5919944592247314e-05, 'epoch': 6.82}
{'loss': 0.2641, 'grad_norm': 1.6009459495544434, 'learning_rate': 1.586497658362833e-05, 'epoch': 6.83}
{'loss': 0.2725, 'grad_norm': 10.681873321533203, 'learning_rate': 1.5810008575009344e-05, 'epoch': 6.84}
{'loss': 0.2775, 'grad_norm': 16.470001220703125, 'learning_rate': 1.5755040566390363e-05, 'epoch': 6.85}
{'loss': 0.2669, 'grad_norm': 1.5064518451690674, 'learning_rate': 1.5700072557771378e-05, 'epoch': 6.86}
{'loss': 0.2653, 'grad_norm': 17.275392532348633, 'learning_rate': 1.5645104549152396e-05, 'epoch': 6.87}
{'loss': 0.2734, 'grad_norm': 0.47955748438835144, 'learning_rate': 1.5590136540533408e-05, 'epoch': 6.88}
{'loss': 0.2736, 'grad_norm': 0.6859388947486877, 'learning_rate': 1.5535168531914427e-05, 'epoch': 6.89}
{'loss': 0.2775, 'grad_norm': 0.5017831921577454, 'learning_rate': 1.5480200523295445e-05, 'epoch': 6.9}
{'loss': 0.2897, 'grad_norm': 0.5704687833786011, 'learning_rate': 1.542523251467646e-05, 'epoch': 6.91}
{'loss': 0.2619, 'grad_norm': 1.3905911445617676, 'learning_rate': 1.5370264506057475e-05, 'epoch': 6.93}
{'loss': 0.2765, 'grad_norm': 1.8278248310089111, 'learning_rate': 1.531529649743849e-05, 'epoch': 6.94}
{'loss': 0.2518, 'grad_norm': 8.460119247436523, 'learning_rate': 1.526032848881951e-05, 'epoch': 6.95}
{'loss': 0.2829, 'grad_norm': 0.4912320673465729, 'learning_rate': 1.5205360480200522e-05, 'epoch': 6.96}
{'loss': 0.2674, 'grad_norm': 6.315787315368652, 'learning_rate': 1.5150392471581539e-05, 'epoch': 6.97}
{'loss': 0.2647, 'grad_norm': 13.065736770629883, 'learning_rate': 1.5095424462962558e-05, 'epoch': 6.98}
{'loss': 0.2707, 'grad_norm': 0.720180332660675, 'learning_rate': 1.5040456454343574e-05, 'epoch': 6.99}
{'loss': 0.2771, 'grad_norm': 6.9167799949646, 'learning_rate': 1.4985488445724588e-05, 'epoch': 7.0}
{'loss': 0.2596, 'grad_norm': 19.348661422729492, 'learning_rate': 1.4930520437105605e-05, 'epoch': 7.01}
{'loss': 0.2475, 'grad_norm': 6.928661346435547, 'learning_rate': 1.4875552428486621e-05, 'epoch': 7.02}
{'loss': 0.2486, 'grad_norm': 0.3622629940509796, 'learning_rate': 1.482058441986764e-05, 'epoch': 7.04}
{'loss': 0.296, 'grad_norm': 3.805826187133789, 'learning_rate': 1.4765616411248653e-05, 'epoch': 7.05}
{'loss': 0.258, 'grad_norm': 6.417112350463867, 'learning_rate': 1.471064840262967e-05, 'epoch': 7.06}
{'loss': 0.2824, 'grad_norm': 0.8873195052146912, 'learning_rate': 1.4655680394010687e-05, 'epoch': 7.07}
{'loss': 0.2672, 'grad_norm': 0.37695103883743286, 'learning_rate': 1.4600712385391702e-05, 'epoch': 7.08}
{'loss': 0.2535, 'grad_norm': 22.449119567871094, 'learning_rate': 1.4545744376772719e-05, 'epoch': 7.09}
{'loss': 0.2719, 'grad_norm': 13.605504989624023, 'learning_rate': 1.4490776368153736e-05, 'epoch': 7.1}
{'loss': 0.2607, 'grad_norm': 0.6208437085151672, 'learning_rate': 1.4435808359534753e-05, 'epoch': 7.11}
{'loss': 0.2692, 'grad_norm': 0.6695338487625122, 'learning_rate': 1.4380840350915768e-05, 'epoch': 7.12}
{'loss': 0.2673, 'grad_norm': 24.85114097595215, 'learning_rate': 1.4325872342296784e-05, 'epoch': 7.13}
{'loss': 0.2745, 'grad_norm': 13.725542068481445, 'learning_rate': 1.4270904333677801e-05, 'epoch': 7.15}
{'loss': 0.2446, 'grad_norm': 1.2299749851226807, 'learning_rate': 1.4215936325058815e-05, 'epoch': 7.16}
{'loss': 0.2507, 'grad_norm': 43.543792724609375, 'learning_rate': 1.4160968316439831e-05, 'epoch': 7.17}
{'loss': 0.2675, 'grad_norm': 2.7117557525634766, 'learning_rate': 1.410600030782085e-05, 'epoch': 7.18}
{'loss': 0.2848, 'grad_norm': 14.741411209106445, 'learning_rate': 1.4051032299201867e-05, 'epoch': 7.19}
{'loss': 0.2547, 'grad_norm': 7.433108806610107, 'learning_rate': 1.399606429058288e-05, 'epoch': 7.2}
{'loss': 0.2638, 'grad_norm': 30.521902084350586, 'learning_rate': 1.3941096281963897e-05, 'epoch': 7.21}
{'loss': 0.259, 'grad_norm': 7.367488384246826, 'learning_rate': 1.3886128273344914e-05, 'epoch': 7.22}
{'loss': 0.2814, 'grad_norm': 3.63354229927063, 'learning_rate': 1.383116026472593e-05, 'epoch': 7.23}
{'loss': 0.268, 'grad_norm': 0.2974664866924286, 'learning_rate': 1.3776192256106946e-05, 'epoch': 7.24}
{'loss': 0.2508, 'grad_norm': 8.44840145111084, 'learning_rate': 1.3721224247487963e-05, 'epoch': 7.26}
{'loss': 0.254, 'grad_norm': 7.657398223876953, 'learning_rate': 1.366625623886898e-05, 'epoch': 7.27}
{'loss': 0.2502, 'grad_norm': 12.107443809509277, 'learning_rate': 1.3611288230249994e-05, 'epoch': 7.28}
{'loss': 0.2543, 'grad_norm': 3.6219642162323, 'learning_rate': 1.3556320221631011e-05, 'epoch': 7.29}
{'loss': 0.2715, 'grad_norm': 14.24657154083252, 'learning_rate': 1.3501352213012028e-05, 'epoch': 7.3}
{'loss': 0.2478, 'grad_norm': 5.7803544998168945, 'learning_rate': 1.3446384204393045e-05, 'epoch': 7.31}
{'loss': 0.2538, 'grad_norm': 26.815235137939453, 'learning_rate': 1.3391416195774058e-05, 'epoch': 7.32}
{'loss': 0.2699, 'grad_norm': 1.3733162879943848, 'learning_rate': 1.3336448187155077e-05, 'epoch': 7.33}
{'loss': 0.2684, 'grad_norm': 0.8834508657455444, 'learning_rate': 1.3281480178536094e-05, 'epoch': 7.34}
{'loss': 0.2842, 'grad_norm': 0.312654584646225, 'learning_rate': 1.322651216991711e-05, 'epoch': 7.35}
{'loss': 0.2531, 'grad_norm': 1.465052843093872, 'learning_rate': 1.3171544161298124e-05, 'epoch': 7.37}
{'loss': 0.2662, 'grad_norm': 20.769939422607422, 'learning_rate': 1.311657615267914e-05, 'epoch': 7.38}
{'loss': 0.2528, 'grad_norm': 14.01921272277832, 'learning_rate': 1.306160814406016e-05, 'epoch': 7.39}
{'loss': 0.2615, 'grad_norm': 5.324960708618164, 'learning_rate': 1.3006640135441173e-05, 'epoch': 7.4}
{'loss': 0.2593, 'grad_norm': 16.46138572692871, 'learning_rate': 1.295167212682219e-05, 'epoch': 7.41}
{'loss': 0.2767, 'grad_norm': 0.47619229555130005, 'learning_rate': 1.2896704118203206e-05, 'epoch': 7.42}
{'loss': 0.2282, 'grad_norm': 0.23515154421329498, 'learning_rate': 1.2841736109584223e-05, 'epoch': 7.43}
{'loss': 0.265, 'grad_norm': 21.702959060668945, 'learning_rate': 1.2786768100965238e-05, 'epoch': 7.44}
{'loss': 0.2912, 'grad_norm': 5.511950969696045, 'learning_rate': 1.2731800092346255e-05, 'epoch': 7.45}
{'loss': 0.2688, 'grad_norm': 7.291085720062256, 'learning_rate': 1.2676832083727272e-05, 'epoch': 7.46}
{'loss': 0.2446, 'grad_norm': 0.3622892200946808, 'learning_rate': 1.2621864075108289e-05, 'epoch': 7.48}
{'loss': 0.2583, 'grad_norm': 24.785545349121094, 'learning_rate': 1.2566896066489304e-05, 'epoch': 7.49}
{'loss': 0.2948, 'grad_norm': 18.24456787109375, 'learning_rate': 1.251192805787032e-05, 'epoch': 7.5}
{'loss': 0.2646, 'grad_norm': 0.3474753499031067, 'learning_rate': 1.2456960049251336e-05, 'epoch': 7.51}
{'loss': 0.273, 'grad_norm': 0.9631456136703491, 'learning_rate': 1.2401992040632352e-05, 'epoch': 7.52}
{'loss': 0.2828, 'grad_norm': 0.8138507604598999, 'learning_rate': 1.234702403201337e-05, 'epoch': 7.53}
{'loss': 0.2741, 'grad_norm': 0.2399323284626007, 'learning_rate': 1.2292056023394386e-05, 'epoch': 7.54}
{'loss': 0.2504, 'grad_norm': 0.4775421619415283, 'learning_rate': 1.2237088014775401e-05, 'epoch': 7.55}
{'loss': 0.2629, 'grad_norm': 32.190757751464844, 'learning_rate': 1.2182120006156418e-05, 'epoch': 7.56}
{'loss': 0.2895, 'grad_norm': 1.213343858718872, 'learning_rate': 1.2127151997537433e-05, 'epoch': 7.57}
{'loss': 0.2758, 'grad_norm': 8.925688743591309, 'learning_rate': 1.2072183988918452e-05, 'epoch': 7.59}
{'loss': 0.2673, 'grad_norm': 19.883668899536133, 'learning_rate': 1.2017215980299467e-05, 'epoch': 7.6}
{'loss': 0.2745, 'grad_norm': 6.212285041809082, 'learning_rate': 1.1962247971680482e-05, 'epoch': 7.61}
{'loss': 0.2475, 'grad_norm': 7.97428035736084, 'learning_rate': 1.1907279963061499e-05, 'epoch': 7.62}
{'loss': 0.2803, 'grad_norm': 0.835823118686676, 'learning_rate': 1.1852311954442515e-05, 'epoch': 7.63}
{'loss': 0.254, 'grad_norm': 0.12898573279380798, 'learning_rate': 1.1797343945823532e-05, 'epoch': 7.64}
{'loss': 0.2578, 'grad_norm': 2.5905539989471436, 'learning_rate': 1.1742375937204547e-05, 'epoch': 7.65}
{'loss': 0.2769, 'grad_norm': 9.952960014343262, 'learning_rate': 1.1687407928585564e-05, 'epoch': 7.66}
{'loss': 0.2542, 'grad_norm': 14.621337890625, 'learning_rate': 1.163243991996658e-05, 'epoch': 7.67}
{'loss': 0.2913, 'grad_norm': 16.269363403320312, 'learning_rate': 1.1577471911347596e-05, 'epoch': 7.68}
{'loss': 0.2741, 'grad_norm': 0.4451834559440613, 'learning_rate': 1.1522503902728613e-05, 'epoch': 7.7}
{'loss': 0.2619, 'grad_norm': 29.35198402404785, 'learning_rate': 1.1467535894109628e-05, 'epoch': 7.71}
{'loss': 0.2697, 'grad_norm': 33.43767166137695, 'learning_rate': 1.1412567885490645e-05, 'epoch': 7.72}
{'loss': 0.2515, 'grad_norm': 0.38866299390792847, 'learning_rate': 1.135759987687166e-05, 'epoch': 7.73}
{'loss': 0.2688, 'grad_norm': 0.3432430624961853, 'learning_rate': 1.1302631868252678e-05, 'epoch': 7.74}
{'loss': 0.2539, 'grad_norm': 9.588069915771484, 'learning_rate': 1.1247663859633693e-05, 'epoch': 7.75}
{'loss': 0.2489, 'grad_norm': 0.9656268954277039, 'learning_rate': 1.119269585101471e-05, 'epoch': 7.76}
{'loss': 0.2796, 'grad_norm': 25.718908309936523, 'learning_rate': 1.1137727842395725e-05, 'epoch': 7.77}
{'loss': 0.2636, 'grad_norm': 0.2751670777797699, 'learning_rate': 1.1082759833776742e-05, 'epoch': 7.78}
{'loss': 0.2702, 'grad_norm': 5.706303596496582, 'learning_rate': 1.1027791825157759e-05, 'epoch': 7.79}
{'loss': 0.2681, 'grad_norm': 13.396392822265625, 'learning_rate': 1.0972823816538776e-05, 'epoch': 7.81}
{'loss': 0.2382, 'grad_norm': 32.353607177734375, 'learning_rate': 1.0917855807919791e-05, 'epoch': 7.82}
{'loss': 0.2728, 'grad_norm': 0.2581191956996918, 'learning_rate': 1.0862887799300806e-05, 'epoch': 7.83}
{'loss': 0.2624, 'grad_norm': 24.561582565307617, 'learning_rate': 1.0807919790681825e-05, 'epoch': 7.84}
{'loss': 0.2636, 'grad_norm': 13.9099702835083, 'learning_rate': 1.075295178206284e-05, 'epoch': 7.85}
{'loss': 0.2711, 'grad_norm': 9.4712553024292, 'learning_rate': 1.0697983773443856e-05, 'epoch': 7.86}
{'loss': 0.2554, 'grad_norm': 1.6488934755325317, 'learning_rate': 1.0643015764824872e-05, 'epoch': 7.87}
{'loss': 0.2977, 'grad_norm': 2.1579911708831787, 'learning_rate': 1.0588047756205888e-05, 'epoch': 7.88}
{'loss': 0.2791, 'grad_norm': 35.49015426635742, 'learning_rate': 1.0533079747586905e-05, 'epoch': 7.89}
{'loss': 0.2786, 'grad_norm': 7.2873711585998535, 'learning_rate': 1.0478111738967922e-05, 'epoch': 7.9}
{'loss': 0.2599, 'grad_norm': 0.6143662929534912, 'learning_rate': 1.0423143730348937e-05, 'epoch': 7.92}
{'loss': 0.2536, 'grad_norm': 0.6351032257080078, 'learning_rate': 1.0368175721729952e-05, 'epoch': 7.93}
{'loss': 0.2599, 'grad_norm': 1.9005131721496582, 'learning_rate': 1.031320771311097e-05, 'epoch': 7.94}
{'loss': 0.2746, 'grad_norm': 7.923094272613525, 'learning_rate': 1.0258239704491986e-05, 'epoch': 7.95}
{'loss': 0.2726, 'grad_norm': 1.2769962549209595, 'learning_rate': 1.0203271695873003e-05, 'epoch': 7.96}
{'loss': 0.2608, 'grad_norm': 0.8133516907691956, 'learning_rate': 1.0148303687254018e-05, 'epoch': 7.97}
{'loss': 0.2665, 'grad_norm': 10.378576278686523, 'learning_rate': 1.0093335678635035e-05, 'epoch': 7.98}
{'loss': 0.2781, 'grad_norm': 18.358715057373047, 'learning_rate': 1.0038367670016051e-05, 'epoch': 7.99}
{'loss': 0.261, 'grad_norm': 0.6664692759513855, 'learning_rate': 9.983399661397068e-06, 'epoch': 8.0}
{'loss': 0.2559, 'grad_norm': 0.5799651741981506, 'learning_rate': 9.928431652778083e-06, 'epoch': 8.01}
{'loss': 0.2587, 'grad_norm': 11.784241676330566, 'learning_rate': 9.8734636441591e-06, 'epoch': 8.03}
{'loss': 0.2624, 'grad_norm': 0.11405061930418015, 'learning_rate': 9.818495635540117e-06, 'epoch': 8.04}
{'loss': 0.2649, 'grad_norm': 9.08200454711914, 'learning_rate': 9.763527626921132e-06, 'epoch': 8.05}
{'loss': 0.2711, 'grad_norm': 8.54967212677002, 'learning_rate': 9.708559618302149e-06, 'epoch': 8.06}
{'loss': 0.2406, 'grad_norm': 1.8095698356628418, 'learning_rate': 9.653591609683164e-06, 'epoch': 8.07}
{'loss': 0.2431, 'grad_norm': 24.99897003173828, 'learning_rate': 9.59862360106418e-06, 'epoch': 8.08}
{'loss': 0.2671, 'grad_norm': 51.13410186767578, 'learning_rate': 9.543655592445198e-06, 'epoch': 8.09}
{'loss': 0.2577, 'grad_norm': 10.574066162109375, 'learning_rate': 9.488687583826214e-06, 'epoch': 8.1}
{'loss': 0.2362, 'grad_norm': 0.45105910301208496, 'learning_rate': 9.43371957520723e-06, 'epoch': 8.11}
{'loss': 0.2505, 'grad_norm': 12.547565460205078, 'learning_rate': 9.378751566588246e-06, 'epoch': 8.12}
{'loss': 0.2656, 'grad_norm': 1.4920982122421265, 'learning_rate': 9.323783557969261e-06, 'epoch': 8.14}
{'loss': 0.2776, 'grad_norm': 0.5405572056770325, 'learning_rate': 9.268815549350278e-06, 'epoch': 8.15}
{'loss': 0.263, 'grad_norm': 0.6006206274032593, 'learning_rate': 9.213847540731295e-06, 'epoch': 8.16}
{'loss': 0.282, 'grad_norm': 15.397306442260742, 'learning_rate': 9.15887953211231e-06, 'epoch': 8.17}
{'loss': 0.2558, 'grad_norm': 3.9856138229370117, 'learning_rate': 9.103911523493327e-06, 'epoch': 8.18}
{'loss': 0.2585, 'grad_norm': 16.448223114013672, 'learning_rate': 9.048943514874344e-06, 'epoch': 8.19}
{'loss': 0.2568, 'grad_norm': 9.710247039794922, 'learning_rate': 8.99397550625536e-06, 'epoch': 8.2}
{'loss': 0.2474, 'grad_norm': 21.155141830444336, 'learning_rate': 8.939007497636376e-06, 'epoch': 8.21}
{'loss': 0.2593, 'grad_norm': 15.547738075256348, 'learning_rate': 8.884039489017393e-06, 'epoch': 8.22}
{'loss': 0.2582, 'grad_norm': 18.229917526245117, 'learning_rate': 8.829071480398408e-06, 'epoch': 8.23}
{'loss': 0.2855, 'grad_norm': 5.083061218261719, 'learning_rate': 8.774103471779426e-06, 'epoch': 8.25}
{'loss': 0.2506, 'grad_norm': 0.3040788173675537, 'learning_rate': 8.719135463160441e-06, 'epoch': 8.26}
{'loss': 0.2447, 'grad_norm': 17.079639434814453, 'learning_rate': 8.664167454541456e-06, 'epoch': 8.27}
{'loss': 0.2702, 'grad_norm': 34.01074981689453, 'learning_rate': 8.609199445922473e-06, 'epoch': 8.28}
{'loss': 0.2634, 'grad_norm': 0.8367383480072021, 'learning_rate': 8.55423143730349e-06, 'epoch': 8.29}
{'loss': 0.2589, 'grad_norm': 8.205109596252441, 'learning_rate': 8.499263428684507e-06, 'epoch': 8.3}
{'loss': 0.2521, 'grad_norm': 10.698573112487793, 'learning_rate': 8.444295420065522e-06, 'epoch': 8.31}
{'loss': 0.2569, 'grad_norm': 7.001713275909424, 'learning_rate': 8.389327411446539e-06, 'epoch': 8.32}
{'loss': 0.2593, 'grad_norm': 12.257295608520508, 'learning_rate': 8.334359402827554e-06, 'epoch': 8.33}
{'loss': 0.2493, 'grad_norm': 5.782690048217773, 'learning_rate': 8.279391394208572e-06, 'epoch': 8.34}
{'loss': 0.2862, 'grad_norm': 22.938623428344727, 'learning_rate': 8.224423385589587e-06, 'epoch': 8.36}
{'loss': 0.2582, 'grad_norm': 22.593664169311523, 'learning_rate': 8.169455376970603e-06, 'epoch': 8.37}
{'loss': 0.2619, 'grad_norm': 17.651029586791992, 'learning_rate': 8.11448736835162e-06, 'epoch': 8.38}
{'loss': 0.2743, 'grad_norm': 0.4676258862018585, 'learning_rate': 8.059519359732636e-06, 'epoch': 8.39}
{'loss': 0.2509, 'grad_norm': 1.1082463264465332, 'learning_rate': 8.004551351113653e-06, 'epoch': 8.4}
{'loss': 0.2547, 'grad_norm': 15.62587833404541, 'learning_rate': 7.949583342494668e-06, 'epoch': 8.41}
{'loss': 0.2638, 'grad_norm': 0.4446337819099426, 'learning_rate': 7.894615333875685e-06, 'epoch': 8.42}
{'loss': 0.2577, 'grad_norm': 10.209952354431152, 'learning_rate': 7.8396473252567e-06, 'epoch': 8.43}
{'loss': 0.2526, 'grad_norm': 0.292096346616745, 'learning_rate': 7.784679316637719e-06, 'epoch': 8.44}
{'loss': 0.2812, 'grad_norm': 13.498376846313477, 'learning_rate': 7.729711308018734e-06, 'epoch': 8.45}
{'loss': 0.2446, 'grad_norm': 22.636734008789062, 'learning_rate': 7.67474329939975e-06, 'epoch': 8.47}
{'loss': 0.2638, 'grad_norm': 0.6988667845726013, 'learning_rate': 7.6197752907807656e-06, 'epoch': 8.48}
{'loss': 0.2769, 'grad_norm': 1.8448106050491333, 'learning_rate': 7.5648072821617815e-06, 'epoch': 8.49}
{'loss': 0.2611, 'grad_norm': 10.17341136932373, 'learning_rate': 7.509839273542798e-06, 'epoch': 8.5}
{'loss': 0.2689, 'grad_norm': 0.09391575306653976, 'learning_rate': 7.454871264923814e-06, 'epoch': 8.51}
{'loss': 0.2477, 'grad_norm': 12.588973045349121, 'learning_rate': 7.399903256304831e-06, 'epoch': 8.52}
{'loss': 0.2572, 'grad_norm': 0.3182179927825928, 'learning_rate': 7.344935247685847e-06, 'epoch': 8.53}
{'loss': 0.2665, 'grad_norm': 11.058145523071289, 'learning_rate': 7.289967239066864e-06, 'epoch': 8.54}
{'loss': 0.2889, 'grad_norm': 0.515005886554718, 'learning_rate': 7.23499923044788e-06, 'epoch': 8.55}
{'loss': 0.254, 'grad_norm': 5.291982650756836, 'learning_rate': 7.180031221828897e-06, 'epoch': 8.56}
{'loss': 0.2542, 'grad_norm': 21.996017456054688, 'learning_rate': 7.125063213209912e-06, 'epoch': 8.58}
{'loss': 0.2485, 'grad_norm': 0.10849342495203018, 'learning_rate': 7.070095204590929e-06, 'epoch': 8.59}
{'loss': 0.2828, 'grad_norm': 0.7772354483604431, 'learning_rate': 7.0151271959719445e-06, 'epoch': 8.6}
{'loss': 0.2545, 'grad_norm': 0.4593776762485504, 'learning_rate': 6.9601591873529605e-06, 'epoch': 8.61}
{'loss': 0.2642, 'grad_norm': 0.6990107893943787, 'learning_rate': 6.905191178733977e-06, 'epoch': 8.62}
{'loss': 0.2794, 'grad_norm': 0.6846628785133362, 'learning_rate': 6.850223170114993e-06, 'epoch': 8.63}
{'loss': 0.2654, 'grad_norm': 1.8367207050323486, 'learning_rate': 6.79525516149601e-06, 'epoch': 8.64}
{'loss': 0.2535, 'grad_norm': 6.812720775604248, 'learning_rate': 6.740287152877026e-06, 'epoch': 8.65}
{'loss': 0.2605, 'grad_norm': 0.42749279737472534, 'learning_rate': 6.685319144258043e-06, 'epoch': 8.66}
{'loss': 0.2605, 'grad_norm': 0.4507158100605011, 'learning_rate': 6.630351135639058e-06, 'epoch': 8.67}
{'loss': 0.2742, 'grad_norm': 30.011442184448242, 'learning_rate': 6.575383127020076e-06, 'epoch': 8.68}
{'loss': 0.2577, 'grad_norm': 7.4460062980651855, 'learning_rate': 6.520415118401091e-06, 'epoch': 8.7}
{'loss': 0.2779, 'grad_norm': 18.759145736694336, 'learning_rate': 6.465447109782107e-06, 'epoch': 8.71}
{'loss': 0.2618, 'grad_norm': 20.737743377685547, 'learning_rate': 6.4104791011631235e-06, 'epoch': 8.72}
{'loss': 0.2645, 'grad_norm': 0.2285478711128235, 'learning_rate': 6.3555110925441394e-06, 'epoch': 8.73}
{'loss': 0.2597, 'grad_norm': 20.223119735717773, 'learning_rate': 6.300543083925156e-06, 'epoch': 8.74}
{'loss': 0.2632, 'grad_norm': 6.411953449249268, 'learning_rate': 6.245575075306172e-06, 'epoch': 8.75}
{'loss': 0.2716, 'grad_norm': 15.867339134216309, 'learning_rate': 6.190607066687188e-06, 'epoch': 8.76}
{'loss': 0.2544, 'grad_norm': 5.882462978363037, 'learning_rate': 6.135639058068204e-06, 'epoch': 8.77}
{'loss': 0.2842, 'grad_norm': 4.823578834533691, 'learning_rate': 6.080671049449221e-06, 'epoch': 8.78}
{'loss': 0.2472, 'grad_norm': 0.9170792698860168, 'learning_rate': 6.025703040830237e-06, 'epoch': 8.79}
{'loss': 0.2616, 'grad_norm': 7.7260308265686035, 'learning_rate': 5.970735032211254e-06, 'epoch': 8.81}
{'loss': 0.2567, 'grad_norm': 10.257424354553223, 'learning_rate': 5.91576702359227e-06, 'epoch': 8.82}
{'loss': 0.2796, 'grad_norm': 8.020028114318848, 'learning_rate': 5.860799014973286e-06, 'epoch': 8.83}
{'loss': 0.2596, 'grad_norm': 12.336654663085938, 'learning_rate': 5.8058310063543024e-06, 'epoch': 8.84}
{'loss': 0.2502, 'grad_norm': 13.539714813232422, 'learning_rate': 5.750862997735318e-06, 'epoch': 8.85}
{'loss': 0.2709, 'grad_norm': 0.7127130031585693, 'learning_rate': 5.695894989116335e-06, 'epoch': 8.86}
{'loss': 0.2568, 'grad_norm': 0.20561730861663818, 'learning_rate': 5.64092698049735e-06, 'epoch': 8.87}
{'loss': 0.2506, 'grad_norm': 0.4776766002178192, 'learning_rate': 5.585958971878367e-06, 'epoch': 8.88}
{'loss': 0.2706, 'grad_norm': 20.48691749572754, 'learning_rate': 5.530990963259383e-06, 'epoch': 8.89}
{'loss': 0.2486, 'grad_norm': 11.717845916748047, 'learning_rate': 5.476022954640399e-06, 'epoch': 8.9}
{'loss': 0.2795, 'grad_norm': 13.339228630065918, 'learning_rate': 5.421054946021416e-06, 'epoch': 8.92}
{'loss': 0.245, 'grad_norm': 0.6927555799484253, 'learning_rate': 5.366086937402432e-06, 'epoch': 8.93}
{'loss': 0.2423, 'grad_norm': 31.68856430053711, 'learning_rate': 5.311118928783449e-06, 'epoch': 8.94}
{'loss': 0.2516, 'grad_norm': 0.3357219398021698, 'learning_rate': 5.256150920164465e-06, 'epoch': 8.95}
{'loss': 0.2482, 'grad_norm': 15.466933250427246, 'learning_rate': 5.201182911545481e-06, 'epoch': 8.96}
{'loss': 0.2797, 'grad_norm': 24.34349822998047, 'learning_rate': 5.146214902926497e-06, 'epoch': 8.97}
{'loss': 0.2541, 'grad_norm': 0.42251700162887573, 'learning_rate': 5.091246894307513e-06, 'epoch': 8.98}
{'loss': 0.2752, 'grad_norm': 17.595285415649414, 'learning_rate': 5.036278885688529e-06, 'epoch': 8.99}
{'loss': 0.2862, 'grad_norm': 33.853939056396484, 'learning_rate': 4.981310877069545e-06, 'epoch': 9.0}
{'loss': 0.2535, 'grad_norm': 8.003698348999023, 'learning_rate': 4.926342868450562e-06, 'epoch': 9.01}
{'loss': 0.2489, 'grad_norm': 0.16239456832408905, 'learning_rate': 4.871374859831578e-06, 'epoch': 9.03}
{'loss': 0.2681, 'grad_norm': 24.668867111206055, 'learning_rate': 4.816406851212595e-06, 'epoch': 9.04}
{'loss': 0.2531, 'grad_norm': 19.58768081665039, 'learning_rate': 4.761438842593611e-06, 'epoch': 9.05}
{'loss': 0.2296, 'grad_norm': 15.512588500976562, 'learning_rate': 4.706470833974628e-06, 'epoch': 9.06}
{'loss': 0.2399, 'grad_norm': 14.990845680236816, 'learning_rate': 4.6515028253556436e-06, 'epoch': 9.07}
{'loss': 0.2446, 'grad_norm': 0.33715370297431946, 'learning_rate': 4.5965348167366595e-06, 'epoch': 9.08}
{'loss': 0.2779, 'grad_norm': 5.429749965667725, 'learning_rate': 4.5415668081176755e-06, 'epoch': 9.09}
{'loss': 0.2545, 'grad_norm': 0.28419026732444763, 'learning_rate': 4.4865987994986914e-06, 'epoch': 9.1}
{'loss': 0.2344, 'grad_norm': 0.5488486289978027, 'learning_rate': 4.431630790879708e-06, 'epoch': 9.11}
{'loss': 0.2632, 'grad_norm': 0.2870948612689972, 'learning_rate': 4.376662782260724e-06, 'epoch': 9.12}
{'loss': 0.2718, 'grad_norm': 1.2778656482696533, 'learning_rate': 4.321694773641741e-06, 'epoch': 9.14}
{'loss': 0.2445, 'grad_norm': 0.7827711701393127, 'learning_rate': 4.266726765022757e-06, 'epoch': 9.15}
{'loss': 0.2481, 'grad_norm': 4.5229268074035645, 'learning_rate': 4.211758756403773e-06, 'epoch': 9.16}
{'loss': 0.2528, 'grad_norm': 7.380736827850342, 'learning_rate': 4.15679074778479e-06, 'epoch': 9.17}
{'loss': 0.2581, 'grad_norm': 3.2762579917907715, 'learning_rate': 4.101822739165806e-06, 'epoch': 9.18}
{'loss': 0.2763, 'grad_norm': 5.5503106117248535, 'learning_rate': 4.0468547305468225e-06, 'epoch': 9.19}
{'loss': 0.2601, 'grad_norm': 22.056472778320312, 'learning_rate': 3.991886721927838e-06, 'epoch': 9.2}
{'loss': 0.2485, 'grad_norm': 0.2935006618499756, 'learning_rate': 3.9369187133088544e-06, 'epoch': 9.21}
{'loss': 0.2568, 'grad_norm': 16.43678855895996, 'learning_rate': 3.88195070468987e-06, 'epoch': 9.22}
{'loss': 0.2763, 'grad_norm': 2.782071352005005, 'learning_rate': 3.826982696070887e-06, 'epoch': 9.23}
{'loss': 0.2638, 'grad_norm': 12.970808029174805, 'learning_rate': 3.772014687451903e-06, 'epoch': 9.25}
{'loss': 0.284, 'grad_norm': 13.580662727355957, 'learning_rate': 3.7170466788329195e-06, 'epoch': 9.26}
{'loss': 0.2421, 'grad_norm': 0.16665053367614746, 'learning_rate': 3.662078670213936e-06, 'epoch': 9.27}
{'loss': 0.2441, 'grad_norm': 9.936975479125977, 'learning_rate': 3.607110661594952e-06, 'epoch': 9.28}
{'loss': 0.2323, 'grad_norm': 0.7904689311981201, 'learning_rate': 3.5521426529759683e-06, 'epoch': 9.29}
{'loss': 0.2663, 'grad_norm': 6.64162015914917, 'learning_rate': 3.4971746443569847e-06, 'epoch': 9.3}
{'loss': 0.2739, 'grad_norm': 0.4328213036060333, 'learning_rate': 3.442206635738e-06, 'epoch': 9.31}
{'loss': 0.2403, 'grad_norm': 10.342379570007324, 'learning_rate': 3.3872386271190166e-06, 'epoch': 9.32}
{'loss': 0.264, 'grad_norm': 9.556550979614258, 'learning_rate': 3.332270618500033e-06, 'epoch': 9.33}
{'loss': 0.2585, 'grad_norm': 14.406665802001953, 'learning_rate': 3.2773026098810494e-06, 'epoch': 9.34}
{'loss': 0.2645, 'grad_norm': 16.582326889038086, 'learning_rate': 3.2223346012620657e-06, 'epoch': 9.36}
{'loss': 0.2511, 'grad_norm': 13.73993968963623, 'learning_rate': 3.167366592643082e-06, 'epoch': 9.37}
{'loss': 0.2719, 'grad_norm': 11.94059944152832, 'learning_rate': 3.112398584024098e-06, 'epoch': 9.38}
{'loss': 0.2521, 'grad_norm': 0.5527501702308655, 'learning_rate': 3.057430575405114e-06, 'epoch': 9.39}
{'loss': 0.2468, 'grad_norm': 21.968013763427734, 'learning_rate': 3.0024625667861304e-06, 'epoch': 9.4}
{'loss': 0.2576, 'grad_norm': 16.56879234313965, 'learning_rate': 2.947494558167147e-06, 'epoch': 9.41}
{'loss': 0.2503, 'grad_norm': 0.2280309796333313, 'learning_rate': 2.892526549548163e-06, 'epoch': 9.42}
{'loss': 0.2804, 'grad_norm': 29.146259307861328, 'learning_rate': 2.8375585409291796e-06, 'epoch': 9.43}
{'loss': 0.2578, 'grad_norm': 33.32585144042969, 'learning_rate': 2.782590532310196e-06, 'epoch': 9.44}
{'loss': 0.2658, 'grad_norm': 0.5161885023117065, 'learning_rate': 2.727622523691212e-06, 'epoch': 9.45}
{'loss': 0.2587, 'grad_norm': 9.948553085327148, 'learning_rate': 2.672654515072228e-06, 'epoch': 9.47}
{'loss': 0.2586, 'grad_norm': 14.141880989074707, 'learning_rate': 2.6176865064532443e-06, 'epoch': 9.48}
{'loss': 0.2576, 'grad_norm': 1.5758737325668335, 'learning_rate': 2.5627184978342607e-06, 'epoch': 9.49}
{'loss': 0.2728, 'grad_norm': 0.8606505990028381, 'learning_rate': 2.507750489215277e-06, 'epoch': 9.5}
{'loss': 0.255, 'grad_norm': 0.3146405518054962, 'learning_rate': 2.452782480596293e-06, 'epoch': 9.51}
{'loss': 0.2618, 'grad_norm': 8.267414093017578, 'learning_rate': 2.3978144719773094e-06, 'epoch': 9.52}
{'loss': 0.279, 'grad_norm': 0.39820247888565063, 'learning_rate': 2.3428464633583258e-06, 'epoch': 9.53}
{'loss': 0.2645, 'grad_norm': 0.5973173975944519, 'learning_rate': 2.2878784547393417e-06, 'epoch': 9.54}
{'loss': 0.2535, 'grad_norm': 7.833223819732666, 'learning_rate': 2.232910446120358e-06, 'epoch': 9.55}
{'loss': 0.2589, 'grad_norm': 1.1278529167175293, 'learning_rate': 2.177942437501374e-06, 'epoch': 9.56}
{'loss': 0.254, 'grad_norm': 0.5806137323379517, 'learning_rate': 2.1229744288823905e-06, 'epoch': 9.58}
{'loss': 0.2491, 'grad_norm': 0.5677410960197449, 'learning_rate': 2.068006420263407e-06, 'epoch': 9.59}
{'loss': 0.2367, 'grad_norm': 10.168159484863281, 'learning_rate': 2.0130384116444232e-06, 'epoch': 9.6}
{'loss': 0.2628, 'grad_norm': 0.5643631219863892, 'learning_rate': 1.9580704030254396e-06, 'epoch': 9.61}
{'loss': 0.2491, 'grad_norm': 6.0933685302734375, 'learning_rate': 1.9031023944064554e-06, 'epoch': 9.62}
{'loss': 0.2625, 'grad_norm': 1.0765403509140015, 'learning_rate': 1.8481343857874718e-06, 'epoch': 9.63}
{'loss': 0.237, 'grad_norm': 50.986915588378906, 'learning_rate': 1.7931663771684881e-06, 'epoch': 9.64}
{'loss': 0.2419, 'grad_norm': 1.058186411857605, 'learning_rate': 1.7381983685495043e-06, 'epoch': 9.65}
{'loss': 0.2553, 'grad_norm': 8.999154090881348, 'learning_rate': 1.6832303599305207e-06, 'epoch': 9.66}
{'loss': 0.2457, 'grad_norm': 0.4857161045074463, 'learning_rate': 1.6282623513115367e-06, 'epoch': 9.67}
{'loss': 0.2435, 'grad_norm': 16.875837326049805, 'learning_rate': 1.573294342692553e-06, 'epoch': 9.69}
{'loss': 0.2507, 'grad_norm': 9.241517066955566, 'learning_rate': 1.5183263340735692e-06, 'epoch': 9.7}
{'loss': 0.2446, 'grad_norm': 0.3739914894104004, 'learning_rate': 1.4633583254545854e-06, 'epoch': 9.71}
{'loss': 0.2496, 'grad_norm': 14.115691184997559, 'learning_rate': 1.4083903168356018e-06, 'epoch': 9.72}
{'loss': 0.2786, 'grad_norm': 0.2773579955101013, 'learning_rate': 1.3534223082166182e-06, 'epoch': 9.73}
{'loss': 0.2559, 'grad_norm': 16.069761276245117, 'learning_rate': 1.2984542995976341e-06, 'epoch': 9.74}
{'loss': 0.26, 'grad_norm': 22.988222122192383, 'learning_rate': 1.2434862909786505e-06, 'epoch': 9.75}
{'loss': 0.2735, 'grad_norm': 16.46109962463379, 'learning_rate': 1.1885182823596667e-06, 'epoch': 9.76}
{'loss': 0.261, 'grad_norm': 8.947617530822754, 'learning_rate': 1.133550273740683e-06, 'epoch': 9.77}
{'loss': 0.2791, 'grad_norm': 14.851780891418457, 'learning_rate': 1.0785822651216992e-06, 'epoch': 9.78}
{'loss': 0.2705, 'grad_norm': 12.917631149291992, 'learning_rate': 1.0236142565027154e-06, 'epoch': 9.8}
{'loss': 0.2545, 'grad_norm': 16.865314483642578, 'learning_rate': 9.686462478837318e-07, 'epoch': 9.81}
{'loss': 0.2917, 'grad_norm': 0.3257238566875458, 'learning_rate': 9.136782392647479e-07, 'epoch': 9.82}
{'loss': 0.2526, 'grad_norm': 2.3616271018981934, 'learning_rate': 8.587102306457642e-07, 'epoch': 9.83}
{'loss': 0.2756, 'grad_norm': 1.4025428295135498, 'learning_rate': 8.037422220267805e-07, 'epoch': 9.84}
{'loss': 0.2723, 'grad_norm': 14.239948272705078, 'learning_rate': 7.487742134077967e-07, 'epoch': 9.85}
{'loss': 0.2567, 'grad_norm': 0.6069947481155396, 'learning_rate': 6.93806204788813e-07, 'epoch': 9.86}
{'loss': 0.2525, 'grad_norm': 0.5954636931419373, 'learning_rate': 6.388381961698291e-07, 'epoch': 9.87}
{'loss': 0.2325, 'grad_norm': 9.15565299987793, 'learning_rate': 5.838701875508454e-07, 'epoch': 9.88}
{'loss': 0.2414, 'grad_norm': 5.892383098602295, 'learning_rate': 5.289021789318616e-07, 'epoch': 9.89}
{'loss': 0.247, 'grad_norm': 6.890552043914795, 'learning_rate': 4.73934170312878e-07, 'epoch': 9.91}
{'loss': 0.2507, 'grad_norm': 0.23768125474452972, 'learning_rate': 4.189661616938942e-07, 'epoch': 9.92}
{'loss': 0.2599, 'grad_norm': 3.531796455383301, 'learning_rate': 3.6399815307491043e-07, 'epoch': 9.93}
{'loss': 0.2439, 'grad_norm': 0.5906288623809814, 'learning_rate': 3.0903014445592666e-07, 'epoch': 9.94}
{'loss': 0.2654, 'grad_norm': 0.7303103804588318, 'learning_rate': 2.5406213583694293e-07, 'epoch': 9.95}
{'loss': 0.2388, 'grad_norm': 1.5228626728057861, 'learning_rate': 1.9909412721795913e-07, 'epoch': 9.96}
{'loss': 0.2446, 'grad_norm': 15.961101531982422, 'learning_rate': 1.4412611859897539e-07, 'epoch': 9.97}
{'loss': 0.2522, 'grad_norm': 0.3052166700363159, 'learning_rate': 8.915810997999165e-08, 'epoch': 9.98}
{'loss': 0.2519, 'grad_norm': 9.619818687438965, 'learning_rate': 3.419010136100789e-08, 'epoch': 9.99}
{'train_runtime': 69786.2745, 'train_samples_per_second': 52.137, 'train_steps_per_second': 6.517, 'train_loss': 0.2890971097658687, 'epoch': 10.0}
***** train metrics *****
  epoch                    =        10.0
  total_flos               = 791021289GF
  train_loss               =      0.2891
  train_runtime            = 19:23:06.27
  train_samples            =      363846
  train_samples_per_second =      52.137
  train_steps_per_second   =       6.517
08/07/2025 04:37:20 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =       10.0
  eval_accuracy           =     0.8966
  eval_combined_score     =     0.8792
  eval_f1                 =     0.8618
  eval_loss               =     0.3507
  eval_runtime            = 0:05:51.73
  eval_samples            =      40430
  eval_samples_per_second =    114.943
  eval_steps_per_second   =     14.369
08/07/2025 04:43:23 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
08/07/2025 04:43:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=output_final/BERT_large/QQP/InA10/runs/Aug07_04-43-23_n27,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=output_final/BERT_large/QQP/InA10/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=output_final/BERT_large/QQP/InA10/,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
08/07/2025 04:43:25 - INFO - datasets.builder - Found cached dataset glue (/home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c)
The task type of PEFT is not proper!
LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='bert-large-cased', revision=None, task_type=<TaskType.SEQ_CLS: 'SEQ_CLS'>, inference_mode=False, r=4, target_modules={'query', 'value', 'key'}, lora_inhibition=0.1, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
###############
PeftModelForSequenceClassification(
  (base_model): LoraModel(
    (model): BertForSequenceClassification(
      (bert): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 1024, padding_idx=0)
          (position_embeddings): Embedding(512, 1024)
          (token_type_embeddings): Embedding(2, 1024)
          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0-23): 24 x BertLayer(
              (attention): BertAttention(
                (self): BertSdpaSelfAttention(
                  (query): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (key): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (value): lora.Linear(
                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.1, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=1024, out_features=4, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=4, out_features=1024, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): ModulesToSaveWrapper(
        (original_module): Linear(in_features=1024, out_features=2, bias=True)
        (modules_to_save): ModuleDict(
          (default): Linear(in_features=1024, out_features=2, bias=True)
        )
      )
    )
  )
)
08/07/2025 04:43:30 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-67caa5d6ed8c4c99_*_of_00001.arrow
08/07/2025 04:43:31 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-13f2778241a4cc09.arrow
08/07/2025 04:43:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/kangchen/.cache/huggingface/datasets/nyu-mll___glue/qqp/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c/cache-3f2b69d8f7ead7aa_*_of_00001.arrow
08/07/2025 04:43:40 - INFO - __main__ - Class distribution in train set:
08/07/2025 04:43:40 - INFO - __main__ -   Label 0: 229468 (63.07%)
08/07/2025 04:43:40 - INFO - __main__ -   Label 1: 134378 (36.93%)
08/07/2025 04:43:40 - INFO - __main__ - Class distribution in validation set:
08/07/2025 04:43:40 - INFO - __main__ -   Label 0: 25545 (63.18%)
08/07/2025 04:43:40 - INFO - __main__ -   Label 1: 14885 (36.82%)
08/07/2025 04:43:45 - INFO - __main__ - Class distribution in test set:
08/07/2025 04:43:45 - INFO - __main__ -   Label -1: 390965 (100.00%)
08/07/2025 04:43:45 - INFO - __main__ - Sample 335243 of the training set: {'question1': 'How do I crack JEE in a month?', 'question2': 'How do I crack JEE in 4-5 months?', 'label': 0, 'idx': 335243, 'input_ids': [101, 1731, 1202, 146, 8672, 147, 27073, 1107, 170, 2370, 136, 102, 1731, 1202, 146, 8672, 147, 27073, 1107, 125, 118, 126, 1808, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/07/2025 04:43:45 - INFO - __main__ - Sample 58369 of the training set: {'question1': 'Who are the greatest people in the world?', 'question2': 'Can you name some people who have really saved the world?', 'label': 0, 'idx': 58369, 'input_ids': [101, 2627, 1132, 1103, 4459, 1234, 1107, 1103, 1362, 136, 102, 2825, 1128, 1271, 1199, 1234, 1150, 1138, 1541, 4987, 1103, 1362, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/07/2025 04:43:45 - INFO - __main__ - Sample 13112 of the training set: {'question1': 'What is inside a Camel Crush cigarette?', 'question2': 'Are Camel Crush cigarettes designed to attract teen smokers?', 'label': 0, 'idx': 13112, 'input_ids': [101, 1327, 1110, 1656, 170, 23878, 1233, 140, 15432, 9983, 136, 102, 2372, 23878, 1233, 140, 15432, 16595, 2011, 1106, 9781, 13964, 5427, 1733, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
08/07/2025 04:43:45 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
