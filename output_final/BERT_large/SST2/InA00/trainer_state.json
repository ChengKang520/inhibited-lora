{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 84190,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05938947618482005,
      "grad_norm": 10.391578674316406,
      "learning_rate": 4.970364651383775e-05,
      "loss": 0.5896,
      "step": 500
    },
    {
      "epoch": 0.1187789523696401,
      "grad_norm": 12.817737579345703,
      "learning_rate": 4.9406699132913645e-05,
      "loss": 0.354,
      "step": 1000
    },
    {
      "epoch": 0.17816842855446016,
      "grad_norm": 0.9118339419364929,
      "learning_rate": 4.910975175198955e-05,
      "loss": 0.3118,
      "step": 1500
    },
    {
      "epoch": 0.2375579047392802,
      "grad_norm": 14.448917388916016,
      "learning_rate": 4.8812804371065455e-05,
      "loss": 0.301,
      "step": 2000
    },
    {
      "epoch": 0.2969473809241002,
      "grad_norm": 10.65022087097168,
      "learning_rate": 4.851585699014135e-05,
      "loss": 0.2985,
      "step": 2500
    },
    {
      "epoch": 0.3563368571089203,
      "grad_norm": 0.4153135120868683,
      "learning_rate": 4.821890960921725e-05,
      "loss": 0.2672,
      "step": 3000
    },
    {
      "epoch": 0.41572633329374037,
      "grad_norm": 1.621666669845581,
      "learning_rate": 4.792196222829315e-05,
      "loss": 0.2584,
      "step": 3500
    },
    {
      "epoch": 0.4751158094785604,
      "grad_norm": 14.504989624023438,
      "learning_rate": 4.762501484736905e-05,
      "loss": 0.2711,
      "step": 4000
    },
    {
      "epoch": 0.5345052856633804,
      "grad_norm": 0.4006720781326294,
      "learning_rate": 4.7328067466444945e-05,
      "loss": 0.2646,
      "step": 4500
    },
    {
      "epoch": 0.5938947618482004,
      "grad_norm": 0.45063161849975586,
      "learning_rate": 4.703112008552085e-05,
      "loss": 0.2571,
      "step": 5000
    },
    {
      "epoch": 0.6532842380330206,
      "grad_norm": 6.604195594787598,
      "learning_rate": 4.673417270459675e-05,
      "loss": 0.2698,
      "step": 5500
    },
    {
      "epoch": 0.7126737142178406,
      "grad_norm": 0.22163258492946625,
      "learning_rate": 4.6437225323672646e-05,
      "loss": 0.2612,
      "step": 6000
    },
    {
      "epoch": 0.7720631904026607,
      "grad_norm": 5.7416911125183105,
      "learning_rate": 4.614027794274855e-05,
      "loss": 0.247,
      "step": 6500
    },
    {
      "epoch": 0.8314526665874807,
      "grad_norm": 8.917417526245117,
      "learning_rate": 4.584333056182445e-05,
      "loss": 0.2622,
      "step": 7000
    },
    {
      "epoch": 0.8908421427723008,
      "grad_norm": 9.075450897216797,
      "learning_rate": 4.554638318090035e-05,
      "loss": 0.246,
      "step": 7500
    },
    {
      "epoch": 0.9502316189571208,
      "grad_norm": 28.690658569335938,
      "learning_rate": 4.5249435799976245e-05,
      "loss": 0.2297,
      "step": 8000
    },
    {
      "epoch": 1.0096210951419409,
      "grad_norm": 9.556715965270996,
      "learning_rate": 4.495248841905215e-05,
      "loss": 0.2353,
      "step": 8500
    },
    {
      "epoch": 1.0690105713267608,
      "grad_norm": 12.607998847961426,
      "learning_rate": 4.465554103812805e-05,
      "loss": 0.2438,
      "step": 9000
    },
    {
      "epoch": 1.128400047511581,
      "grad_norm": 0.12577813863754272,
      "learning_rate": 4.4358593657203946e-05,
      "loss": 0.2319,
      "step": 9500
    },
    {
      "epoch": 1.187789523696401,
      "grad_norm": 6.051407337188721,
      "learning_rate": 4.4061646276279844e-05,
      "loss": 0.2368,
      "step": 10000
    },
    {
      "epoch": 1.247178999881221,
      "grad_norm": 8.264164924621582,
      "learning_rate": 4.376469889535574e-05,
      "loss": 0.2425,
      "step": 10500
    },
    {
      "epoch": 1.3065684760660412,
      "grad_norm": 10.109269142150879,
      "learning_rate": 4.346775151443164e-05,
      "loss": 0.2246,
      "step": 11000
    },
    {
      "epoch": 1.3659579522508611,
      "grad_norm": 0.8366259336471558,
      "learning_rate": 4.3170804133507545e-05,
      "loss": 0.2177,
      "step": 11500
    },
    {
      "epoch": 1.425347428435681,
      "grad_norm": 5.7555694580078125,
      "learning_rate": 4.287385675258344e-05,
      "loss": 0.2225,
      "step": 12000
    },
    {
      "epoch": 1.4847369046205012,
      "grad_norm": 10.898826599121094,
      "learning_rate": 4.257690937165935e-05,
      "loss": 0.2287,
      "step": 12500
    },
    {
      "epoch": 1.5441263808053214,
      "grad_norm": 10.799642562866211,
      "learning_rate": 4.2279961990735246e-05,
      "loss": 0.2473,
      "step": 13000
    },
    {
      "epoch": 1.6035158569901413,
      "grad_norm": 9.866903305053711,
      "learning_rate": 4.1983014609811144e-05,
      "loss": 0.2151,
      "step": 13500
    },
    {
      "epoch": 1.6629053331749613,
      "grad_norm": 1.3733906745910645,
      "learning_rate": 4.168606722888704e-05,
      "loss": 0.2315,
      "step": 14000
    },
    {
      "epoch": 1.7222948093597814,
      "grad_norm": 1.558939814567566,
      "learning_rate": 4.138911984796294e-05,
      "loss": 0.2123,
      "step": 14500
    },
    {
      "epoch": 1.7816842855446016,
      "grad_norm": 16.588489532470703,
      "learning_rate": 4.1092172467038845e-05,
      "loss": 0.2253,
      "step": 15000
    },
    {
      "epoch": 1.8410737617294215,
      "grad_norm": 9.111014366149902,
      "learning_rate": 4.079522508611474e-05,
      "loss": 0.2323,
      "step": 15500
    },
    {
      "epoch": 1.9004632379142414,
      "grad_norm": 7.653107166290283,
      "learning_rate": 4.049827770519064e-05,
      "loss": 0.2266,
      "step": 16000
    },
    {
      "epoch": 1.9598527140990618,
      "grad_norm": 23.024078369140625,
      "learning_rate": 4.020133032426654e-05,
      "loss": 0.2172,
      "step": 16500
    },
    {
      "epoch": 2.0192421902838817,
      "grad_norm": 0.0772283598780632,
      "learning_rate": 3.9904382943342444e-05,
      "loss": 0.2169,
      "step": 17000
    },
    {
      "epoch": 2.0786316664687017,
      "grad_norm": 0.10925929993391037,
      "learning_rate": 3.960743556241834e-05,
      "loss": 0.2143,
      "step": 17500
    },
    {
      "epoch": 2.1380211426535216,
      "grad_norm": 4.223936557769775,
      "learning_rate": 3.931048818149424e-05,
      "loss": 0.2131,
      "step": 18000
    },
    {
      "epoch": 2.197410618838342,
      "grad_norm": 1.5227794647216797,
      "learning_rate": 3.901354080057014e-05,
      "loss": 0.2033,
      "step": 18500
    },
    {
      "epoch": 2.256800095023162,
      "grad_norm": 0.19151480495929718,
      "learning_rate": 3.8716593419646043e-05,
      "loss": 0.1937,
      "step": 19000
    },
    {
      "epoch": 2.316189571207982,
      "grad_norm": 28.964284896850586,
      "learning_rate": 3.841964603872194e-05,
      "loss": 0.2033,
      "step": 19500
    },
    {
      "epoch": 2.375579047392802,
      "grad_norm": 0.41175055503845215,
      "learning_rate": 3.812269865779784e-05,
      "loss": 0.2047,
      "step": 20000
    },
    {
      "epoch": 2.434968523577622,
      "grad_norm": 0.2671777009963989,
      "learning_rate": 3.782575127687374e-05,
      "loss": 0.225,
      "step": 20500
    },
    {
      "epoch": 2.494357999762442,
      "grad_norm": 8.392420768737793,
      "learning_rate": 3.7528803895949636e-05,
      "loss": 0.206,
      "step": 21000
    },
    {
      "epoch": 2.553747475947262,
      "grad_norm": 0.3630807399749756,
      "learning_rate": 3.7231856515025534e-05,
      "loss": 0.1927,
      "step": 21500
    },
    {
      "epoch": 2.6131369521320824,
      "grad_norm": 0.06776441633701324,
      "learning_rate": 3.693490913410144e-05,
      "loss": 0.2014,
      "step": 22000
    },
    {
      "epoch": 2.6725264283169023,
      "grad_norm": 0.14619643986225128,
      "learning_rate": 3.6637961753177343e-05,
      "loss": 0.213,
      "step": 22500
    },
    {
      "epoch": 2.7319159045017223,
      "grad_norm": 13.257560729980469,
      "learning_rate": 3.634101437225324e-05,
      "loss": 0.1977,
      "step": 23000
    },
    {
      "epoch": 2.791305380686542,
      "grad_norm": 5.4073309898376465,
      "learning_rate": 3.604406699132914e-05,
      "loss": 0.1913,
      "step": 23500
    },
    {
      "epoch": 2.850694856871362,
      "grad_norm": 6.7171125411987305,
      "learning_rate": 3.574711961040504e-05,
      "loss": 0.1901,
      "step": 24000
    },
    {
      "epoch": 2.9100843330561825,
      "grad_norm": 0.18087075650691986,
      "learning_rate": 3.5450172229480936e-05,
      "loss": 0.1979,
      "step": 24500
    },
    {
      "epoch": 2.9694738092410025,
      "grad_norm": 4.366325378417969,
      "learning_rate": 3.5153224848556834e-05,
      "loss": 0.1925,
      "step": 25000
    },
    {
      "epoch": 3.0288632854258224,
      "grad_norm": 0.47251859307289124,
      "learning_rate": 3.485627746763274e-05,
      "loss": 0.1985,
      "step": 25500
    },
    {
      "epoch": 3.0882527616106428,
      "grad_norm": 6.353679180145264,
      "learning_rate": 3.455933008670864e-05,
      "loss": 0.1615,
      "step": 26000
    },
    {
      "epoch": 3.1476422377954627,
      "grad_norm": 24.227922439575195,
      "learning_rate": 3.4262382705784535e-05,
      "loss": 0.1791,
      "step": 26500
    },
    {
      "epoch": 3.2070317139802826,
      "grad_norm": 2.9719808101654053,
      "learning_rate": 3.396543532486043e-05,
      "loss": 0.185,
      "step": 27000
    },
    {
      "epoch": 3.2664211901651026,
      "grad_norm": 0.3076241612434387,
      "learning_rate": 3.366848794393634e-05,
      "loss": 0.1945,
      "step": 27500
    },
    {
      "epoch": 3.325810666349923,
      "grad_norm": 0.29812321066856384,
      "learning_rate": 3.3371540563012236e-05,
      "loss": 0.1903,
      "step": 28000
    },
    {
      "epoch": 3.385200142534743,
      "grad_norm": 0.21716852486133575,
      "learning_rate": 3.3074593182088134e-05,
      "loss": 0.1893,
      "step": 28500
    },
    {
      "epoch": 3.444589618719563,
      "grad_norm": 0.0979541540145874,
      "learning_rate": 3.277764580116404e-05,
      "loss": 0.1841,
      "step": 29000
    },
    {
      "epoch": 3.503979094904383,
      "grad_norm": 0.2355257123708725,
      "learning_rate": 3.248069842023994e-05,
      "loss": 0.191,
      "step": 29500
    },
    {
      "epoch": 3.563368571089203,
      "grad_norm": 0.20571547746658325,
      "learning_rate": 3.2183751039315835e-05,
      "loss": 0.2059,
      "step": 30000
    },
    {
      "epoch": 3.622758047274023,
      "grad_norm": 0.9727370738983154,
      "learning_rate": 3.188680365839173e-05,
      "loss": 0.1731,
      "step": 30500
    },
    {
      "epoch": 3.682147523458843,
      "grad_norm": 0.5073900818824768,
      "learning_rate": 3.158985627746763e-05,
      "loss": 0.1795,
      "step": 31000
    },
    {
      "epoch": 3.741536999643663,
      "grad_norm": 0.2971954047679901,
      "learning_rate": 3.129290889654353e-05,
      "loss": 0.191,
      "step": 31500
    },
    {
      "epoch": 3.8009264758284833,
      "grad_norm": 0.332730770111084,
      "learning_rate": 3.0995961515619434e-05,
      "loss": 0.1967,
      "step": 32000
    },
    {
      "epoch": 3.8603159520133032,
      "grad_norm": 12.922599792480469,
      "learning_rate": 3.069901413469533e-05,
      "loss": 0.1734,
      "step": 32500
    },
    {
      "epoch": 3.919705428198123,
      "grad_norm": 0.31632712483406067,
      "learning_rate": 3.0402066753771237e-05,
      "loss": 0.1889,
      "step": 33000
    },
    {
      "epoch": 3.9790949043829436,
      "grad_norm": 0.02060091495513916,
      "learning_rate": 3.0105119372847135e-05,
      "loss": 0.1803,
      "step": 33500
    },
    {
      "epoch": 4.0384843805677635,
      "grad_norm": 18.263212203979492,
      "learning_rate": 2.9808171991923033e-05,
      "loss": 0.1879,
      "step": 34000
    },
    {
      "epoch": 4.097873856752583,
      "grad_norm": 11.451932907104492,
      "learning_rate": 2.9511224610998934e-05,
      "loss": 0.1691,
      "step": 34500
    },
    {
      "epoch": 4.157263332937403,
      "grad_norm": 6.704498767852783,
      "learning_rate": 2.9214277230074833e-05,
      "loss": 0.1709,
      "step": 35000
    },
    {
      "epoch": 4.216652809122223,
      "grad_norm": 0.25919944047927856,
      "learning_rate": 2.891732984915073e-05,
      "loss": 0.1826,
      "step": 35500
    },
    {
      "epoch": 4.276042285307043,
      "grad_norm": 0.09541169553995132,
      "learning_rate": 2.8620382468226632e-05,
      "loss": 0.166,
      "step": 36000
    },
    {
      "epoch": 4.335431761491864,
      "grad_norm": 8.544774055480957,
      "learning_rate": 2.832343508730253e-05,
      "loss": 0.1825,
      "step": 36500
    },
    {
      "epoch": 4.394821237676684,
      "grad_norm": 15.38333511352539,
      "learning_rate": 2.8026487706378428e-05,
      "loss": 0.1534,
      "step": 37000
    },
    {
      "epoch": 4.454210713861504,
      "grad_norm": 8.953414916992188,
      "learning_rate": 2.772954032545433e-05,
      "loss": 0.1878,
      "step": 37500
    },
    {
      "epoch": 4.513600190046324,
      "grad_norm": 0.03060070611536503,
      "learning_rate": 2.7432592944530235e-05,
      "loss": 0.1643,
      "step": 38000
    },
    {
      "epoch": 4.572989666231144,
      "grad_norm": 0.04084856063127518,
      "learning_rate": 2.7135645563606133e-05,
      "loss": 0.1784,
      "step": 38500
    },
    {
      "epoch": 4.632379142415964,
      "grad_norm": 0.23794719576835632,
      "learning_rate": 2.683869818268203e-05,
      "loss": 0.1777,
      "step": 39000
    },
    {
      "epoch": 4.691768618600784,
      "grad_norm": 0.24588674306869507,
      "learning_rate": 2.6541750801757932e-05,
      "loss": 0.1631,
      "step": 39500
    },
    {
      "epoch": 4.751158094785604,
      "grad_norm": 12.796346664428711,
      "learning_rate": 2.624480342083383e-05,
      "loss": 0.1712,
      "step": 40000
    },
    {
      "epoch": 4.810547570970424,
      "grad_norm": 0.25567305088043213,
      "learning_rate": 2.5947856039909728e-05,
      "loss": 0.1623,
      "step": 40500
    },
    {
      "epoch": 4.869937047155244,
      "grad_norm": 24.82249641418457,
      "learning_rate": 2.565090865898563e-05,
      "loss": 0.1819,
      "step": 41000
    },
    {
      "epoch": 4.929326523340064,
      "grad_norm": 0.33815765380859375,
      "learning_rate": 2.5353961278061528e-05,
      "loss": 0.1769,
      "step": 41500
    },
    {
      "epoch": 4.988715999524884,
      "grad_norm": 19.48419189453125,
      "learning_rate": 2.5057013897137426e-05,
      "loss": 0.1691,
      "step": 42000
    },
    {
      "epoch": 5.048105475709704,
      "grad_norm": 0.10277662426233292,
      "learning_rate": 2.4760066516213327e-05,
      "loss": 0.159,
      "step": 42500
    },
    {
      "epoch": 5.107494951894524,
      "grad_norm": 0.07582861930131912,
      "learning_rate": 2.446311913528923e-05,
      "loss": 0.1632,
      "step": 43000
    },
    {
      "epoch": 5.166884428079344,
      "grad_norm": 6.859798431396484,
      "learning_rate": 2.4166171754365127e-05,
      "loss": 0.1691,
      "step": 43500
    },
    {
      "epoch": 5.226273904264165,
      "grad_norm": 0.0676768496632576,
      "learning_rate": 2.3869224373441025e-05,
      "loss": 0.1671,
      "step": 44000
    },
    {
      "epoch": 5.285663380448985,
      "grad_norm": 0.2769675552845001,
      "learning_rate": 2.357227699251693e-05,
      "loss": 0.1626,
      "step": 44500
    },
    {
      "epoch": 5.345052856633805,
      "grad_norm": 0.844231367111206,
      "learning_rate": 2.3275329611592828e-05,
      "loss": 0.1735,
      "step": 45000
    },
    {
      "epoch": 5.404442332818625,
      "grad_norm": 11.187796592712402,
      "learning_rate": 2.2978382230668726e-05,
      "loss": 0.1514,
      "step": 45500
    },
    {
      "epoch": 5.463831809003445,
      "grad_norm": 0.16498920321464539,
      "learning_rate": 2.2681434849744627e-05,
      "loss": 0.1721,
      "step": 46000
    },
    {
      "epoch": 5.5232212851882645,
      "grad_norm": 0.14823481440544128,
      "learning_rate": 2.2384487468820525e-05,
      "loss": 0.1632,
      "step": 46500
    },
    {
      "epoch": 5.582610761373084,
      "grad_norm": 5.7764153480529785,
      "learning_rate": 2.2087540087896424e-05,
      "loss": 0.1667,
      "step": 47000
    },
    {
      "epoch": 5.642000237557904,
      "grad_norm": 0.13841676712036133,
      "learning_rate": 2.1790592706972325e-05,
      "loss": 0.1594,
      "step": 47500
    },
    {
      "epoch": 5.701389713742724,
      "grad_norm": 0.11066289991140366,
      "learning_rate": 2.1493645326048226e-05,
      "loss": 0.1658,
      "step": 48000
    },
    {
      "epoch": 5.760779189927545,
      "grad_norm": 0.17536525428295135,
      "learning_rate": 2.1196697945124125e-05,
      "loss": 0.1647,
      "step": 48500
    },
    {
      "epoch": 5.820168666112365,
      "grad_norm": 0.08958137035369873,
      "learning_rate": 2.0899750564200023e-05,
      "loss": 0.1531,
      "step": 49000
    },
    {
      "epoch": 5.879558142297185,
      "grad_norm": 1.6341581344604492,
      "learning_rate": 2.0602803183275924e-05,
      "loss": 0.1518,
      "step": 49500
    },
    {
      "epoch": 5.938947618482005,
      "grad_norm": 0.2994910478591919,
      "learning_rate": 2.0305855802351826e-05,
      "loss": 0.1664,
      "step": 50000
    },
    {
      "epoch": 5.998337094666825,
      "grad_norm": 6.93218994140625,
      "learning_rate": 2.0008908421427724e-05,
      "loss": 0.1632,
      "step": 50500
    },
    {
      "epoch": 6.057726570851645,
      "grad_norm": 0.1903718262910843,
      "learning_rate": 1.9711961040503625e-05,
      "loss": 0.1665,
      "step": 51000
    },
    {
      "epoch": 6.117116047036465,
      "grad_norm": 0.16496378183364868,
      "learning_rate": 1.9415013659579523e-05,
      "loss": 0.1594,
      "step": 51500
    },
    {
      "epoch": 6.1765055232212855,
      "grad_norm": 19.784996032714844,
      "learning_rate": 1.911806627865542e-05,
      "loss": 0.1425,
      "step": 52000
    },
    {
      "epoch": 6.2358949994061055,
      "grad_norm": 0.28819382190704346,
      "learning_rate": 1.8821118897731323e-05,
      "loss": 0.1541,
      "step": 52500
    },
    {
      "epoch": 6.295284475590925,
      "grad_norm": 0.36563143134117126,
      "learning_rate": 1.8524171516807224e-05,
      "loss": 0.1607,
      "step": 53000
    },
    {
      "epoch": 6.354673951775745,
      "grad_norm": 0.18228819966316223,
      "learning_rate": 1.8227224135883122e-05,
      "loss": 0.1551,
      "step": 53500
    },
    {
      "epoch": 6.414063427960565,
      "grad_norm": 24.632482528686523,
      "learning_rate": 1.793027675495902e-05,
      "loss": 0.1562,
      "step": 54000
    },
    {
      "epoch": 6.473452904145385,
      "grad_norm": 0.13062338531017303,
      "learning_rate": 1.7633329374034922e-05,
      "loss": 0.142,
      "step": 54500
    },
    {
      "epoch": 6.532842380330205,
      "grad_norm": 1.39262855052948,
      "learning_rate": 1.7336381993110823e-05,
      "loss": 0.136,
      "step": 55000
    },
    {
      "epoch": 6.592231856515026,
      "grad_norm": 5.2294769287109375,
      "learning_rate": 1.703943461218672e-05,
      "loss": 0.1599,
      "step": 55500
    },
    {
      "epoch": 6.651621332699846,
      "grad_norm": 0.2081950455904007,
      "learning_rate": 1.6742487231262623e-05,
      "loss": 0.1498,
      "step": 56000
    },
    {
      "epoch": 6.711010808884666,
      "grad_norm": 0.12377062439918518,
      "learning_rate": 1.644553985033852e-05,
      "loss": 0.1553,
      "step": 56500
    },
    {
      "epoch": 6.770400285069486,
      "grad_norm": 0.06544248014688492,
      "learning_rate": 1.614859246941442e-05,
      "loss": 0.1425,
      "step": 57000
    },
    {
      "epoch": 6.829789761254306,
      "grad_norm": 8.200968742370605,
      "learning_rate": 1.585164508849032e-05,
      "loss": 0.1553,
      "step": 57500
    },
    {
      "epoch": 6.889179237439126,
      "grad_norm": 52.62939453125,
      "learning_rate": 1.5554697707566222e-05,
      "loss": 0.1549,
      "step": 58000
    },
    {
      "epoch": 6.948568713623946,
      "grad_norm": 14.197378158569336,
      "learning_rate": 1.525775032664212e-05,
      "loss": 0.1685,
      "step": 58500
    },
    {
      "epoch": 7.0079581898087655,
      "grad_norm": 31.429182052612305,
      "learning_rate": 1.496080294571802e-05,
      "loss": 0.1571,
      "step": 59000
    },
    {
      "epoch": 7.067347665993586,
      "grad_norm": 0.07577197253704071,
      "learning_rate": 1.4663855564793918e-05,
      "loss": 0.1407,
      "step": 59500
    },
    {
      "epoch": 7.126737142178406,
      "grad_norm": 19.13991928100586,
      "learning_rate": 1.4366908183869817e-05,
      "loss": 0.1461,
      "step": 60000
    },
    {
      "epoch": 7.186126618363226,
      "grad_norm": 0.0770149901509285,
      "learning_rate": 1.4069960802945719e-05,
      "loss": 0.1445,
      "step": 60500
    },
    {
      "epoch": 7.245516094548046,
      "grad_norm": 0.20668630301952362,
      "learning_rate": 1.3773013422021619e-05,
      "loss": 0.145,
      "step": 61000
    },
    {
      "epoch": 7.304905570732866,
      "grad_norm": 0.10938815772533417,
      "learning_rate": 1.3476066041097518e-05,
      "loss": 0.1493,
      "step": 61500
    },
    {
      "epoch": 7.364295046917686,
      "grad_norm": 0.13908502459526062,
      "learning_rate": 1.3179118660173417e-05,
      "loss": 0.1404,
      "step": 62000
    },
    {
      "epoch": 7.423684523102506,
      "grad_norm": 11.388174057006836,
      "learning_rate": 1.2882171279249316e-05,
      "loss": 0.1452,
      "step": 62500
    },
    {
      "epoch": 7.483073999287326,
      "grad_norm": 0.06860164552927017,
      "learning_rate": 1.2585223898325218e-05,
      "loss": 0.1321,
      "step": 63000
    },
    {
      "epoch": 7.542463475472147,
      "grad_norm": 0.2839682102203369,
      "learning_rate": 1.2288276517401118e-05,
      "loss": 0.1491,
      "step": 63500
    },
    {
      "epoch": 7.601852951656967,
      "grad_norm": 0.42279040813446045,
      "learning_rate": 1.1991329136477017e-05,
      "loss": 0.1526,
      "step": 64000
    },
    {
      "epoch": 7.6612424278417866,
      "grad_norm": 35.09528350830078,
      "learning_rate": 1.1694381755552915e-05,
      "loss": 0.1305,
      "step": 64500
    },
    {
      "epoch": 7.7206319040266065,
      "grad_norm": 0.929916501045227,
      "learning_rate": 1.1397434374628817e-05,
      "loss": 0.1601,
      "step": 65000
    },
    {
      "epoch": 7.780021380211426,
      "grad_norm": 0.09136802703142166,
      "learning_rate": 1.1100486993704717e-05,
      "loss": 0.1582,
      "step": 65500
    },
    {
      "epoch": 7.839410856396246,
      "grad_norm": 0.03596659004688263,
      "learning_rate": 1.0803539612780615e-05,
      "loss": 0.128,
      "step": 66000
    },
    {
      "epoch": 7.898800332581066,
      "grad_norm": 0.62319016456604,
      "learning_rate": 1.0506592231856516e-05,
      "loss": 0.1509,
      "step": 66500
    },
    {
      "epoch": 7.958189808765887,
      "grad_norm": 0.04399503022432327,
      "learning_rate": 1.0209644850932414e-05,
      "loss": 0.145,
      "step": 67000
    },
    {
      "epoch": 8.017579284950706,
      "grad_norm": 0.09871377795934677,
      "learning_rate": 9.912697470008316e-06,
      "loss": 0.1493,
      "step": 67500
    },
    {
      "epoch": 8.076968761135527,
      "grad_norm": 0.25522691011428833,
      "learning_rate": 9.615750089084215e-06,
      "loss": 0.1514,
      "step": 68000
    },
    {
      "epoch": 8.136358237320346,
      "grad_norm": 0.26851561665534973,
      "learning_rate": 9.318802708160113e-06,
      "loss": 0.1556,
      "step": 68500
    },
    {
      "epoch": 8.195747713505167,
      "grad_norm": 1.0546542406082153,
      "learning_rate": 9.021855327236015e-06,
      "loss": 0.1414,
      "step": 69000
    },
    {
      "epoch": 8.255137189689988,
      "grad_norm": 11.862990379333496,
      "learning_rate": 8.724907946311913e-06,
      "loss": 0.1289,
      "step": 69500
    },
    {
      "epoch": 8.314526665874807,
      "grad_norm": 22.332212448120117,
      "learning_rate": 8.427960565387814e-06,
      "loss": 0.1449,
      "step": 70000
    },
    {
      "epoch": 8.373916142059628,
      "grad_norm": 0.1329144388437271,
      "learning_rate": 8.131013184463714e-06,
      "loss": 0.1423,
      "step": 70500
    },
    {
      "epoch": 8.433305618244447,
      "grad_norm": 0.051064327359199524,
      "learning_rate": 7.834065803539612e-06,
      "loss": 0.1338,
      "step": 71000
    },
    {
      "epoch": 8.492695094429267,
      "grad_norm": 0.06994777172803879,
      "learning_rate": 7.537118422615514e-06,
      "loss": 0.1455,
      "step": 71500
    },
    {
      "epoch": 8.552084570614086,
      "grad_norm": 0.07129469513893127,
      "learning_rate": 7.240171041691413e-06,
      "loss": 0.1225,
      "step": 72000
    },
    {
      "epoch": 8.611474046798907,
      "grad_norm": 22.212778091430664,
      "learning_rate": 6.943223660767312e-06,
      "loss": 0.1599,
      "step": 72500
    },
    {
      "epoch": 8.670863522983728,
      "grad_norm": 0.09974833577871323,
      "learning_rate": 6.646276279843212e-06,
      "loss": 0.1464,
      "step": 73000
    },
    {
      "epoch": 8.730252999168547,
      "grad_norm": 1.2353929281234741,
      "learning_rate": 6.349328898919112e-06,
      "loss": 0.1407,
      "step": 73500
    },
    {
      "epoch": 8.789642475353368,
      "grad_norm": 0.32411137223243713,
      "learning_rate": 6.052381517995012e-06,
      "loss": 0.1298,
      "step": 74000
    },
    {
      "epoch": 8.849031951538187,
      "grad_norm": 15.917370796203613,
      "learning_rate": 5.7554341370709115e-06,
      "loss": 0.1468,
      "step": 74500
    },
    {
      "epoch": 8.908421427723008,
      "grad_norm": 0.2949158549308777,
      "learning_rate": 5.458486756146811e-06,
      "loss": 0.1359,
      "step": 75000
    },
    {
      "epoch": 8.967810903907827,
      "grad_norm": 0.16972658038139343,
      "learning_rate": 5.16153937522271e-06,
      "loss": 0.1424,
      "step": 75500
    },
    {
      "epoch": 9.027200380092648,
      "grad_norm": 1.1061956882476807,
      "learning_rate": 4.86459199429861e-06,
      "loss": 0.1506,
      "step": 76000
    },
    {
      "epoch": 9.086589856277469,
      "grad_norm": 0.5140438675880432,
      "learning_rate": 4.567644613374511e-06,
      "loss": 0.1259,
      "step": 76500
    },
    {
      "epoch": 9.145979332462288,
      "grad_norm": 17.401338577270508,
      "learning_rate": 4.27069723245041e-06,
      "loss": 0.1519,
      "step": 77000
    },
    {
      "epoch": 9.205368808647108,
      "grad_norm": 0.411146342754364,
      "learning_rate": 3.973749851526309e-06,
      "loss": 0.1305,
      "step": 77500
    },
    {
      "epoch": 9.264758284831927,
      "grad_norm": 1.3693511486053467,
      "learning_rate": 3.6768024706022095e-06,
      "loss": 0.1349,
      "step": 78000
    },
    {
      "epoch": 9.324147761016748,
      "grad_norm": 6.513916492462158,
      "learning_rate": 3.3798550896781092e-06,
      "loss": 0.1467,
      "step": 78500
    },
    {
      "epoch": 9.383537237201567,
      "grad_norm": 1.6404757499694824,
      "learning_rate": 3.082907708754009e-06,
      "loss": 0.1431,
      "step": 79000
    },
    {
      "epoch": 9.442926713386388,
      "grad_norm": 0.10332290828227997,
      "learning_rate": 2.7859603278299088e-06,
      "loss": 0.1334,
      "step": 79500
    },
    {
      "epoch": 9.502316189571207,
      "grad_norm": 0.11285821348428726,
      "learning_rate": 2.4890129469058085e-06,
      "loss": 0.1351,
      "step": 80000
    },
    {
      "epoch": 9.561705665756028,
      "grad_norm": 0.031063271686434746,
      "learning_rate": 2.1920655659817083e-06,
      "loss": 0.131,
      "step": 80500
    },
    {
      "epoch": 9.621095141940849,
      "grad_norm": 0.20503491163253784,
      "learning_rate": 1.895118185057608e-06,
      "loss": 0.1363,
      "step": 81000
    },
    {
      "epoch": 9.680484618125668,
      "grad_norm": 26.537641525268555,
      "learning_rate": 1.5981708041335076e-06,
      "loss": 0.1607,
      "step": 81500
    },
    {
      "epoch": 9.739874094310489,
      "grad_norm": 5.699361324310303,
      "learning_rate": 1.3012234232094074e-06,
      "loss": 0.1609,
      "step": 82000
    },
    {
      "epoch": 9.799263570495308,
      "grad_norm": 0.2827502191066742,
      "learning_rate": 1.004276042285307e-06,
      "loss": 0.1368,
      "step": 82500
    },
    {
      "epoch": 9.858653046680129,
      "grad_norm": 12.368637084960938,
      "learning_rate": 7.073286613612068e-07,
      "loss": 0.1121,
      "step": 83000
    },
    {
      "epoch": 9.918042522864948,
      "grad_norm": 9.496063232421875,
      "learning_rate": 4.1038128043710657e-07,
      "loss": 0.1231,
      "step": 83500
    },
    {
      "epoch": 9.977431999049768,
      "grad_norm": 0.1429750621318817,
      "learning_rate": 1.134338995130063e-07,
      "loss": 0.1303,
      "step": 84000
    },
    {
      "epoch": 10.0,
      "step": 84190,
      "total_flos": 1.5721775456910336e+17,
      "train_loss": 0.18214260864348433,
      "train_runtime": 13183.9722,
      "train_samples_per_second": 51.084,
      "train_steps_per_second": 6.386
    }
  ],
  "logging_steps": 500,
  "max_steps": 84190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5721775456910336e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
