{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 84190,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05938947618482005,
      "grad_norm": 7.453210830688477,
      "learning_rate": 4.970364651383775e-05,
      "loss": 0.6815,
      "step": 500
    },
    {
      "epoch": 0.1187789523696401,
      "grad_norm": 8.632540702819824,
      "learning_rate": 4.9406699132913645e-05,
      "loss": 0.4066,
      "step": 1000
    },
    {
      "epoch": 0.17816842855446016,
      "grad_norm": 2.415982723236084,
      "learning_rate": 4.910975175198955e-05,
      "loss": 0.3375,
      "step": 1500
    },
    {
      "epoch": 0.2375579047392802,
      "grad_norm": 3.0686235427856445,
      "learning_rate": 4.8812804371065455e-05,
      "loss": 0.3243,
      "step": 2000
    },
    {
      "epoch": 0.2969473809241002,
      "grad_norm": 9.143190383911133,
      "learning_rate": 4.851585699014135e-05,
      "loss": 0.3006,
      "step": 2500
    },
    {
      "epoch": 0.3563368571089203,
      "grad_norm": 0.7508859634399414,
      "learning_rate": 4.821890960921725e-05,
      "loss": 0.2876,
      "step": 3000
    },
    {
      "epoch": 0.41572633329374037,
      "grad_norm": 5.06959342956543,
      "learning_rate": 4.792196222829315e-05,
      "loss": 0.2823,
      "step": 3500
    },
    {
      "epoch": 0.4751158094785604,
      "grad_norm": 14.893431663513184,
      "learning_rate": 4.762501484736905e-05,
      "loss": 0.2736,
      "step": 4000
    },
    {
      "epoch": 0.5345052856633804,
      "grad_norm": 0.46618732810020447,
      "learning_rate": 4.7328067466444945e-05,
      "loss": 0.2757,
      "step": 4500
    },
    {
      "epoch": 0.5938947618482004,
      "grad_norm": 11.615038871765137,
      "learning_rate": 4.703112008552085e-05,
      "loss": 0.252,
      "step": 5000
    },
    {
      "epoch": 0.6532842380330206,
      "grad_norm": 0.9692739248275757,
      "learning_rate": 4.673417270459675e-05,
      "loss": 0.2748,
      "step": 5500
    },
    {
      "epoch": 0.7126737142178406,
      "grad_norm": 1.620157241821289,
      "learning_rate": 4.6437225323672646e-05,
      "loss": 0.2636,
      "step": 6000
    },
    {
      "epoch": 0.7720631904026607,
      "grad_norm": 5.332100868225098,
      "learning_rate": 4.614027794274855e-05,
      "loss": 0.2525,
      "step": 6500
    },
    {
      "epoch": 0.8314526665874807,
      "grad_norm": 1.9929797649383545,
      "learning_rate": 4.584333056182445e-05,
      "loss": 0.2629,
      "step": 7000
    },
    {
      "epoch": 0.8908421427723008,
      "grad_norm": 14.69895076751709,
      "learning_rate": 4.554638318090035e-05,
      "loss": 0.2532,
      "step": 7500
    },
    {
      "epoch": 0.9502316189571208,
      "grad_norm": 14.506464004516602,
      "learning_rate": 4.5249435799976245e-05,
      "loss": 0.2297,
      "step": 8000
    },
    {
      "epoch": 1.0096210951419409,
      "grad_norm": 8.14688777923584,
      "learning_rate": 4.495248841905215e-05,
      "loss": 0.2459,
      "step": 8500
    },
    {
      "epoch": 1.0690105713267608,
      "grad_norm": 5.929331302642822,
      "learning_rate": 4.465554103812805e-05,
      "loss": 0.2468,
      "step": 9000
    },
    {
      "epoch": 1.128400047511581,
      "grad_norm": 0.2680804431438446,
      "learning_rate": 4.4358593657203946e-05,
      "loss": 0.2322,
      "step": 9500
    },
    {
      "epoch": 1.187789523696401,
      "grad_norm": 5.784522533416748,
      "learning_rate": 4.4061646276279844e-05,
      "loss": 0.234,
      "step": 10000
    },
    {
      "epoch": 1.247178999881221,
      "grad_norm": 10.251727104187012,
      "learning_rate": 4.376469889535574e-05,
      "loss": 0.2533,
      "step": 10500
    },
    {
      "epoch": 1.3065684760660412,
      "grad_norm": 0.9265382289886475,
      "learning_rate": 4.346775151443164e-05,
      "loss": 0.2359,
      "step": 11000
    },
    {
      "epoch": 1.3659579522508611,
      "grad_norm": 2.749413251876831,
      "learning_rate": 4.3170804133507545e-05,
      "loss": 0.2212,
      "step": 11500
    },
    {
      "epoch": 1.425347428435681,
      "grad_norm": 0.27972719073295593,
      "learning_rate": 4.287385675258344e-05,
      "loss": 0.2236,
      "step": 12000
    },
    {
      "epoch": 1.4847369046205012,
      "grad_norm": 1.0514403581619263,
      "learning_rate": 4.257690937165935e-05,
      "loss": 0.2273,
      "step": 12500
    },
    {
      "epoch": 1.5441263808053214,
      "grad_norm": 13.434139251708984,
      "learning_rate": 4.2279961990735246e-05,
      "loss": 0.2413,
      "step": 13000
    },
    {
      "epoch": 1.6035158569901413,
      "grad_norm": 20.656465530395508,
      "learning_rate": 4.1983014609811144e-05,
      "loss": 0.2179,
      "step": 13500
    },
    {
      "epoch": 1.6629053331749613,
      "grad_norm": 1.1301565170288086,
      "learning_rate": 4.168606722888704e-05,
      "loss": 0.2275,
      "step": 14000
    },
    {
      "epoch": 1.7222948093597814,
      "grad_norm": 1.4128234386444092,
      "learning_rate": 4.138911984796294e-05,
      "loss": 0.224,
      "step": 14500
    },
    {
      "epoch": 1.7816842855446016,
      "grad_norm": 0.24846592545509338,
      "learning_rate": 4.1092172467038845e-05,
      "loss": 0.227,
      "step": 15000
    },
    {
      "epoch": 1.8410737617294215,
      "grad_norm": 8.43178653717041,
      "learning_rate": 4.079522508611474e-05,
      "loss": 0.2343,
      "step": 15500
    },
    {
      "epoch": 1.9004632379142414,
      "grad_norm": 8.134703636169434,
      "learning_rate": 4.049827770519064e-05,
      "loss": 0.2311,
      "step": 16000
    },
    {
      "epoch": 1.9598527140990618,
      "grad_norm": 18.40303611755371,
      "learning_rate": 4.020133032426654e-05,
      "loss": 0.2188,
      "step": 16500
    },
    {
      "epoch": 2.0192421902838817,
      "grad_norm": 0.31152334809303284,
      "learning_rate": 3.9904382943342444e-05,
      "loss": 0.2277,
      "step": 17000
    },
    {
      "epoch": 2.0786316664687017,
      "grad_norm": 0.19241392612457275,
      "learning_rate": 3.960743556241834e-05,
      "loss": 0.2251,
      "step": 17500
    },
    {
      "epoch": 2.1380211426535216,
      "grad_norm": 5.037104606628418,
      "learning_rate": 3.931048818149424e-05,
      "loss": 0.2114,
      "step": 18000
    },
    {
      "epoch": 2.197410618838342,
      "grad_norm": 0.30331140756607056,
      "learning_rate": 3.901354080057014e-05,
      "loss": 0.215,
      "step": 18500
    },
    {
      "epoch": 2.256800095023162,
      "grad_norm": 0.3307431638240814,
      "learning_rate": 3.8716593419646043e-05,
      "loss": 0.2019,
      "step": 19000
    },
    {
      "epoch": 2.316189571207982,
      "grad_norm": 1.3715684413909912,
      "learning_rate": 3.841964603872194e-05,
      "loss": 0.1957,
      "step": 19500
    },
    {
      "epoch": 2.375579047392802,
      "grad_norm": 23.81972885131836,
      "learning_rate": 3.812269865779784e-05,
      "loss": 0.2101,
      "step": 20000
    },
    {
      "epoch": 2.434968523577622,
      "grad_norm": 0.30954709649086,
      "learning_rate": 3.782575127687374e-05,
      "loss": 0.2224,
      "step": 20500
    },
    {
      "epoch": 2.494357999762442,
      "grad_norm": 16.653453826904297,
      "learning_rate": 3.7528803895949636e-05,
      "loss": 0.2129,
      "step": 21000
    },
    {
      "epoch": 2.553747475947262,
      "grad_norm": 0.338351309299469,
      "learning_rate": 3.7231856515025534e-05,
      "loss": 0.2006,
      "step": 21500
    },
    {
      "epoch": 2.6131369521320824,
      "grad_norm": 0.08617065846920013,
      "learning_rate": 3.693490913410144e-05,
      "loss": 0.2002,
      "step": 22000
    },
    {
      "epoch": 2.6725264283169023,
      "grad_norm": 0.24093377590179443,
      "learning_rate": 3.6637961753177343e-05,
      "loss": 0.2231,
      "step": 22500
    },
    {
      "epoch": 2.7319159045017223,
      "grad_norm": 20.82309913635254,
      "learning_rate": 3.634101437225324e-05,
      "loss": 0.1934,
      "step": 23000
    },
    {
      "epoch": 2.791305380686542,
      "grad_norm": 4.280924320220947,
      "learning_rate": 3.604406699132914e-05,
      "loss": 0.1906,
      "step": 23500
    },
    {
      "epoch": 2.850694856871362,
      "grad_norm": 11.364401817321777,
      "learning_rate": 3.574711961040504e-05,
      "loss": 0.1985,
      "step": 24000
    },
    {
      "epoch": 2.9100843330561825,
      "grad_norm": 0.3265427052974701,
      "learning_rate": 3.5450172229480936e-05,
      "loss": 0.2012,
      "step": 24500
    },
    {
      "epoch": 2.9694738092410025,
      "grad_norm": 0.22536543011665344,
      "learning_rate": 3.5153224848556834e-05,
      "loss": 0.2018,
      "step": 25000
    },
    {
      "epoch": 3.0288632854258224,
      "grad_norm": 0.7812514305114746,
      "learning_rate": 3.485627746763274e-05,
      "loss": 0.2089,
      "step": 25500
    },
    {
      "epoch": 3.0882527616106428,
      "grad_norm": 6.1567864418029785,
      "learning_rate": 3.455933008670864e-05,
      "loss": 0.1711,
      "step": 26000
    },
    {
      "epoch": 3.1476422377954627,
      "grad_norm": 2.6247036457061768,
      "learning_rate": 3.4262382705784535e-05,
      "loss": 0.1755,
      "step": 26500
    },
    {
      "epoch": 3.2070317139802826,
      "grad_norm": 4.344082355499268,
      "learning_rate": 3.396543532486043e-05,
      "loss": 0.1993,
      "step": 27000
    },
    {
      "epoch": 3.2664211901651026,
      "grad_norm": 7.436882972717285,
      "learning_rate": 3.366848794393634e-05,
      "loss": 0.1918,
      "step": 27500
    },
    {
      "epoch": 3.325810666349923,
      "grad_norm": 1.2578027248382568,
      "learning_rate": 3.3371540563012236e-05,
      "loss": 0.1958,
      "step": 28000
    },
    {
      "epoch": 3.385200142534743,
      "grad_norm": 0.22115859389305115,
      "learning_rate": 3.3074593182088134e-05,
      "loss": 0.1984,
      "step": 28500
    },
    {
      "epoch": 3.444589618719563,
      "grad_norm": 0.06916921585798264,
      "learning_rate": 3.277764580116404e-05,
      "loss": 0.1903,
      "step": 29000
    },
    {
      "epoch": 3.503979094904383,
      "grad_norm": 1.5581700801849365,
      "learning_rate": 3.248069842023994e-05,
      "loss": 0.1951,
      "step": 29500
    },
    {
      "epoch": 3.563368571089203,
      "grad_norm": 0.32446008920669556,
      "learning_rate": 3.2183751039315835e-05,
      "loss": 0.2014,
      "step": 30000
    },
    {
      "epoch": 3.622758047274023,
      "grad_norm": 1.2092958688735962,
      "learning_rate": 3.188680365839173e-05,
      "loss": 0.1868,
      "step": 30500
    },
    {
      "epoch": 3.682147523458843,
      "grad_norm": 5.526541233062744,
      "learning_rate": 3.158985627746763e-05,
      "loss": 0.1989,
      "step": 31000
    },
    {
      "epoch": 3.741536999643663,
      "grad_norm": 0.5485577583312988,
      "learning_rate": 3.129290889654353e-05,
      "loss": 0.1953,
      "step": 31500
    },
    {
      "epoch": 3.8009264758284833,
      "grad_norm": 0.5479140877723694,
      "learning_rate": 3.0995961515619434e-05,
      "loss": 0.2008,
      "step": 32000
    },
    {
      "epoch": 3.8603159520133032,
      "grad_norm": 0.7083186507225037,
      "learning_rate": 3.069901413469533e-05,
      "loss": 0.1849,
      "step": 32500
    },
    {
      "epoch": 3.919705428198123,
      "grad_norm": 0.32936057448387146,
      "learning_rate": 3.0402066753771237e-05,
      "loss": 0.1979,
      "step": 33000
    },
    {
      "epoch": 3.9790949043829436,
      "grad_norm": 0.021274901926517487,
      "learning_rate": 3.0105119372847135e-05,
      "loss": 0.1812,
      "step": 33500
    },
    {
      "epoch": 4.0384843805677635,
      "grad_norm": 16.92535400390625,
      "learning_rate": 2.9808171991923033e-05,
      "loss": 0.1901,
      "step": 34000
    },
    {
      "epoch": 4.097873856752583,
      "grad_norm": 6.1847147941589355,
      "learning_rate": 2.9511224610998934e-05,
      "loss": 0.1669,
      "step": 34500
    },
    {
      "epoch": 4.157263332937403,
      "grad_norm": 11.60693645477295,
      "learning_rate": 2.9214277230074833e-05,
      "loss": 0.1799,
      "step": 35000
    },
    {
      "epoch": 4.216652809122223,
      "grad_norm": 0.20586372911930084,
      "learning_rate": 2.891732984915073e-05,
      "loss": 0.1773,
      "step": 35500
    },
    {
      "epoch": 4.276042285307043,
      "grad_norm": 0.15744079649448395,
      "learning_rate": 2.8620382468226632e-05,
      "loss": 0.1786,
      "step": 36000
    },
    {
      "epoch": 4.335431761491864,
      "grad_norm": 5.887382507324219,
      "learning_rate": 2.832343508730253e-05,
      "loss": 0.1841,
      "step": 36500
    },
    {
      "epoch": 4.394821237676684,
      "grad_norm": 20.06334114074707,
      "learning_rate": 2.8026487706378428e-05,
      "loss": 0.1688,
      "step": 37000
    },
    {
      "epoch": 4.454210713861504,
      "grad_norm": 19.137357711791992,
      "learning_rate": 2.772954032545433e-05,
      "loss": 0.1815,
      "step": 37500
    },
    {
      "epoch": 4.513600190046324,
      "grad_norm": 0.02815619669854641,
      "learning_rate": 2.7432592944530235e-05,
      "loss": 0.1683,
      "step": 38000
    },
    {
      "epoch": 4.572989666231144,
      "grad_norm": 0.20688499510288239,
      "learning_rate": 2.7135645563606133e-05,
      "loss": 0.1619,
      "step": 38500
    },
    {
      "epoch": 4.632379142415964,
      "grad_norm": 15.209527969360352,
      "learning_rate": 2.683869818268203e-05,
      "loss": 0.1809,
      "step": 39000
    },
    {
      "epoch": 4.691768618600784,
      "grad_norm": 7.333098888397217,
      "learning_rate": 2.6541750801757932e-05,
      "loss": 0.1662,
      "step": 39500
    },
    {
      "epoch": 4.751158094785604,
      "grad_norm": 23.26601219177246,
      "learning_rate": 2.624480342083383e-05,
      "loss": 0.1745,
      "step": 40000
    },
    {
      "epoch": 4.810547570970424,
      "grad_norm": 11.644222259521484,
      "learning_rate": 2.5947856039909728e-05,
      "loss": 0.1735,
      "step": 40500
    },
    {
      "epoch": 4.869937047155244,
      "grad_norm": 17.69607162475586,
      "learning_rate": 2.565090865898563e-05,
      "loss": 0.1771,
      "step": 41000
    },
    {
      "epoch": 4.929326523340064,
      "grad_norm": 0.9040339589118958,
      "learning_rate": 2.5353961278061528e-05,
      "loss": 0.1763,
      "step": 41500
    },
    {
      "epoch": 4.988715999524884,
      "grad_norm": 8.345616340637207,
      "learning_rate": 2.5057013897137426e-05,
      "loss": 0.1787,
      "step": 42000
    },
    {
      "epoch": 5.048105475709704,
      "grad_norm": 0.15832652151584625,
      "learning_rate": 2.4760066516213327e-05,
      "loss": 0.1629,
      "step": 42500
    },
    {
      "epoch": 5.107494951894524,
      "grad_norm": 0.5168269276618958,
      "learning_rate": 2.446311913528923e-05,
      "loss": 0.1685,
      "step": 43000
    },
    {
      "epoch": 5.166884428079344,
      "grad_norm": 7.0191240310668945,
      "learning_rate": 2.4166171754365127e-05,
      "loss": 0.178,
      "step": 43500
    },
    {
      "epoch": 5.226273904264165,
      "grad_norm": 0.10171803086996078,
      "learning_rate": 2.3869224373441025e-05,
      "loss": 0.1702,
      "step": 44000
    },
    {
      "epoch": 5.285663380448985,
      "grad_norm": 0.35016104578971863,
      "learning_rate": 2.357227699251693e-05,
      "loss": 0.1604,
      "step": 44500
    },
    {
      "epoch": 5.345052856633805,
      "grad_norm": 0.2594131827354431,
      "learning_rate": 2.3275329611592828e-05,
      "loss": 0.1735,
      "step": 45000
    },
    {
      "epoch": 5.404442332818625,
      "grad_norm": 8.186439514160156,
      "learning_rate": 2.2978382230668726e-05,
      "loss": 0.1636,
      "step": 45500
    },
    {
      "epoch": 5.463831809003445,
      "grad_norm": 0.20494186878204346,
      "learning_rate": 2.2681434849744627e-05,
      "loss": 0.1739,
      "step": 46000
    },
    {
      "epoch": 5.5232212851882645,
      "grad_norm": 0.37399163842201233,
      "learning_rate": 2.2384487468820525e-05,
      "loss": 0.1561,
      "step": 46500
    },
    {
      "epoch": 5.582610761373084,
      "grad_norm": 0.32763877511024475,
      "learning_rate": 2.2087540087896424e-05,
      "loss": 0.177,
      "step": 47000
    },
    {
      "epoch": 5.642000237557904,
      "grad_norm": 0.16263774037361145,
      "learning_rate": 2.1790592706972325e-05,
      "loss": 0.1676,
      "step": 47500
    },
    {
      "epoch": 5.701389713742724,
      "grad_norm": 0.0798044502735138,
      "learning_rate": 2.1493645326048226e-05,
      "loss": 0.1601,
      "step": 48000
    },
    {
      "epoch": 5.760779189927545,
      "grad_norm": 2.632420063018799,
      "learning_rate": 2.1196697945124125e-05,
      "loss": 0.1635,
      "step": 48500
    },
    {
      "epoch": 5.820168666112365,
      "grad_norm": 0.13392877578735352,
      "learning_rate": 2.0899750564200023e-05,
      "loss": 0.163,
      "step": 49000
    },
    {
      "epoch": 5.879558142297185,
      "grad_norm": 21.770835876464844,
      "learning_rate": 2.0602803183275924e-05,
      "loss": 0.1658,
      "step": 49500
    },
    {
      "epoch": 5.938947618482005,
      "grad_norm": 6.490817546844482,
      "learning_rate": 2.0305855802351826e-05,
      "loss": 0.1819,
      "step": 50000
    },
    {
      "epoch": 5.998337094666825,
      "grad_norm": 27.291458129882812,
      "learning_rate": 2.0008908421427724e-05,
      "loss": 0.1643,
      "step": 50500
    },
    {
      "epoch": 6.057726570851645,
      "grad_norm": 0.17166829109191895,
      "learning_rate": 1.9711961040503625e-05,
      "loss": 0.1702,
      "step": 51000
    },
    {
      "epoch": 6.117116047036465,
      "grad_norm": 0.13452021777629852,
      "learning_rate": 1.9415013659579523e-05,
      "loss": 0.1582,
      "step": 51500
    },
    {
      "epoch": 6.1765055232212855,
      "grad_norm": 0.6364989280700684,
      "learning_rate": 1.911806627865542e-05,
      "loss": 0.1586,
      "step": 52000
    },
    {
      "epoch": 6.2358949994061055,
      "grad_norm": 0.2777552902698517,
      "learning_rate": 1.8821118897731323e-05,
      "loss": 0.1475,
      "step": 52500
    },
    {
      "epoch": 6.295284475590925,
      "grad_norm": 17.54488754272461,
      "learning_rate": 1.8524171516807224e-05,
      "loss": 0.1684,
      "step": 53000
    },
    {
      "epoch": 6.354673951775745,
      "grad_norm": 3.512369155883789,
      "learning_rate": 1.8227224135883122e-05,
      "loss": 0.1396,
      "step": 53500
    },
    {
      "epoch": 6.414063427960565,
      "grad_norm": 8.887513160705566,
      "learning_rate": 1.793027675495902e-05,
      "loss": 0.1547,
      "step": 54000
    },
    {
      "epoch": 6.473452904145385,
      "grad_norm": 0.06671774387359619,
      "learning_rate": 1.7633329374034922e-05,
      "loss": 0.1507,
      "step": 54500
    },
    {
      "epoch": 6.532842380330205,
      "grad_norm": 41.120094299316406,
      "learning_rate": 1.7336381993110823e-05,
      "loss": 0.1398,
      "step": 55000
    },
    {
      "epoch": 6.592231856515026,
      "grad_norm": 5.557764530181885,
      "learning_rate": 1.703943461218672e-05,
      "loss": 0.1583,
      "step": 55500
    },
    {
      "epoch": 6.651621332699846,
      "grad_norm": 0.11901478469371796,
      "learning_rate": 1.6742487231262623e-05,
      "loss": 0.1654,
      "step": 56000
    },
    {
      "epoch": 6.711010808884666,
      "grad_norm": 0.18906505405902863,
      "learning_rate": 1.644553985033852e-05,
      "loss": 0.161,
      "step": 56500
    },
    {
      "epoch": 6.770400285069486,
      "grad_norm": 0.08919266611337662,
      "learning_rate": 1.614859246941442e-05,
      "loss": 0.1505,
      "step": 57000
    },
    {
      "epoch": 6.829789761254306,
      "grad_norm": 0.20505285263061523,
      "learning_rate": 1.585164508849032e-05,
      "loss": 0.1606,
      "step": 57500
    },
    {
      "epoch": 6.889179237439126,
      "grad_norm": 0.33759811520576477,
      "learning_rate": 1.5554697707566222e-05,
      "loss": 0.1622,
      "step": 58000
    },
    {
      "epoch": 6.948568713623946,
      "grad_norm": 7.680994510650635,
      "learning_rate": 1.525775032664212e-05,
      "loss": 0.1663,
      "step": 58500
    },
    {
      "epoch": 7.0079581898087655,
      "grad_norm": 0.7544856667518616,
      "learning_rate": 1.496080294571802e-05,
      "loss": 0.1628,
      "step": 59000
    },
    {
      "epoch": 7.067347665993586,
      "grad_norm": 0.17629460990428925,
      "learning_rate": 1.4663855564793918e-05,
      "loss": 0.1474,
      "step": 59500
    },
    {
      "epoch": 7.126737142178406,
      "grad_norm": 9.423174858093262,
      "learning_rate": 1.4366908183869817e-05,
      "loss": 0.166,
      "step": 60000
    },
    {
      "epoch": 7.186126618363226,
      "grad_norm": 0.24504733085632324,
      "learning_rate": 1.4069960802945719e-05,
      "loss": 0.1345,
      "step": 60500
    },
    {
      "epoch": 7.245516094548046,
      "grad_norm": 0.1363755315542221,
      "learning_rate": 1.3773013422021619e-05,
      "loss": 0.1578,
      "step": 61000
    },
    {
      "epoch": 7.304905570732866,
      "grad_norm": 0.11070318520069122,
      "learning_rate": 1.3476066041097518e-05,
      "loss": 0.1477,
      "step": 61500
    },
    {
      "epoch": 7.364295046917686,
      "grad_norm": 0.14499056339263916,
      "learning_rate": 1.3179118660173417e-05,
      "loss": 0.1421,
      "step": 62000
    },
    {
      "epoch": 7.423684523102506,
      "grad_norm": 9.861416816711426,
      "learning_rate": 1.2882171279249316e-05,
      "loss": 0.1416,
      "step": 62500
    },
    {
      "epoch": 7.483073999287326,
      "grad_norm": 0.08719926327466965,
      "learning_rate": 1.2585223898325218e-05,
      "loss": 0.141,
      "step": 63000
    },
    {
      "epoch": 7.542463475472147,
      "grad_norm": 0.4110477864742279,
      "learning_rate": 1.2288276517401118e-05,
      "loss": 0.1524,
      "step": 63500
    },
    {
      "epoch": 7.601852951656967,
      "grad_norm": 1.0484750270843506,
      "learning_rate": 1.1991329136477017e-05,
      "loss": 0.1691,
      "step": 64000
    },
    {
      "epoch": 7.6612424278417866,
      "grad_norm": 0.1535668969154358,
      "learning_rate": 1.1694381755552915e-05,
      "loss": 0.1374,
      "step": 64500
    },
    {
      "epoch": 7.7206319040266065,
      "grad_norm": 6.887147903442383,
      "learning_rate": 1.1397434374628817e-05,
      "loss": 0.1669,
      "step": 65000
    },
    {
      "epoch": 7.780021380211426,
      "grad_norm": 0.34009987115859985,
      "learning_rate": 1.1100486993704717e-05,
      "loss": 0.1591,
      "step": 65500
    },
    {
      "epoch": 7.839410856396246,
      "grad_norm": 0.09154504537582397,
      "learning_rate": 1.0803539612780615e-05,
      "loss": 0.1477,
      "step": 66000
    },
    {
      "epoch": 7.898800332581066,
      "grad_norm": 1.4431325197219849,
      "learning_rate": 1.0506592231856516e-05,
      "loss": 0.1506,
      "step": 66500
    },
    {
      "epoch": 7.958189808765887,
      "grad_norm": 0.0860704705119133,
      "learning_rate": 1.0209644850932414e-05,
      "loss": 0.1581,
      "step": 67000
    },
    {
      "epoch": 8.017579284950706,
      "grad_norm": 0.09863139688968658,
      "learning_rate": 9.912697470008316e-06,
      "loss": 0.1471,
      "step": 67500
    },
    {
      "epoch": 8.076968761135527,
      "grad_norm": 0.13495109975337982,
      "learning_rate": 9.615750089084215e-06,
      "loss": 0.1564,
      "step": 68000
    },
    {
      "epoch": 8.136358237320346,
      "grad_norm": 0.16774491965770721,
      "learning_rate": 9.318802708160113e-06,
      "loss": 0.1603,
      "step": 68500
    },
    {
      "epoch": 8.195747713505167,
      "grad_norm": 0.5438252687454224,
      "learning_rate": 9.021855327236015e-06,
      "loss": 0.1434,
      "step": 69000
    },
    {
      "epoch": 8.255137189689988,
      "grad_norm": 0.6550549268722534,
      "learning_rate": 8.724907946311913e-06,
      "loss": 0.1261,
      "step": 69500
    },
    {
      "epoch": 8.314526665874807,
      "grad_norm": 0.3260275721549988,
      "learning_rate": 8.427960565387814e-06,
      "loss": 0.1587,
      "step": 70000
    },
    {
      "epoch": 8.373916142059628,
      "grad_norm": 0.39203590154647827,
      "learning_rate": 8.131013184463714e-06,
      "loss": 0.1582,
      "step": 70500
    },
    {
      "epoch": 8.433305618244447,
      "grad_norm": 0.08928068727254868,
      "learning_rate": 7.834065803539612e-06,
      "loss": 0.1424,
      "step": 71000
    },
    {
      "epoch": 8.492695094429267,
      "grad_norm": 0.11519965529441833,
      "learning_rate": 7.537118422615514e-06,
      "loss": 0.1459,
      "step": 71500
    },
    {
      "epoch": 8.552084570614086,
      "grad_norm": 0.15413910150527954,
      "learning_rate": 7.240171041691413e-06,
      "loss": 0.1286,
      "step": 72000
    },
    {
      "epoch": 8.611474046798907,
      "grad_norm": 0.2277156114578247,
      "learning_rate": 6.943223660767312e-06,
      "loss": 0.1762,
      "step": 72500
    },
    {
      "epoch": 8.670863522983728,
      "grad_norm": 0.1654644012451172,
      "learning_rate": 6.646276279843212e-06,
      "loss": 0.152,
      "step": 73000
    },
    {
      "epoch": 8.730252999168547,
      "grad_norm": 0.22504575550556183,
      "learning_rate": 6.349328898919112e-06,
      "loss": 0.13,
      "step": 73500
    },
    {
      "epoch": 8.789642475353368,
      "grad_norm": 0.21949931979179382,
      "learning_rate": 6.052381517995012e-06,
      "loss": 0.1373,
      "step": 74000
    },
    {
      "epoch": 8.849031951538187,
      "grad_norm": 12.159904479980469,
      "learning_rate": 5.7554341370709115e-06,
      "loss": 0.1469,
      "step": 74500
    },
    {
      "epoch": 8.908421427723008,
      "grad_norm": 0.7984012365341187,
      "learning_rate": 5.458486756146811e-06,
      "loss": 0.125,
      "step": 75000
    },
    {
      "epoch": 8.967810903907827,
      "grad_norm": 42.27485275268555,
      "learning_rate": 5.16153937522271e-06,
      "loss": 0.145,
      "step": 75500
    },
    {
      "epoch": 9.027200380092648,
      "grad_norm": 0.5228598713874817,
      "learning_rate": 4.86459199429861e-06,
      "loss": 0.1431,
      "step": 76000
    },
    {
      "epoch": 9.086589856277469,
      "grad_norm": 9.425222396850586,
      "learning_rate": 4.567644613374511e-06,
      "loss": 0.1302,
      "step": 76500
    },
    {
      "epoch": 9.145979332462288,
      "grad_norm": 8.582453727722168,
      "learning_rate": 4.27069723245041e-06,
      "loss": 0.1513,
      "step": 77000
    },
    {
      "epoch": 9.205368808647108,
      "grad_norm": 0.0816153809428215,
      "learning_rate": 3.973749851526309e-06,
      "loss": 0.1232,
      "step": 77500
    },
    {
      "epoch": 9.264758284831927,
      "grad_norm": 80.9566879272461,
      "learning_rate": 3.6768024706022095e-06,
      "loss": 0.1355,
      "step": 78000
    },
    {
      "epoch": 9.324147761016748,
      "grad_norm": 8.565396308898926,
      "learning_rate": 3.3798550896781092e-06,
      "loss": 0.1386,
      "step": 78500
    },
    {
      "epoch": 9.383537237201567,
      "grad_norm": 0.41635116934776306,
      "learning_rate": 3.082907708754009e-06,
      "loss": 0.1517,
      "step": 79000
    },
    {
      "epoch": 9.442926713386388,
      "grad_norm": 0.09874159842729568,
      "learning_rate": 2.7859603278299088e-06,
      "loss": 0.1371,
      "step": 79500
    },
    {
      "epoch": 9.502316189571207,
      "grad_norm": 0.4409312903881073,
      "learning_rate": 2.4890129469058085e-06,
      "loss": 0.14,
      "step": 80000
    },
    {
      "epoch": 9.561705665756028,
      "grad_norm": 0.03191612660884857,
      "learning_rate": 2.1920655659817083e-06,
      "loss": 0.1291,
      "step": 80500
    },
    {
      "epoch": 9.621095141940849,
      "grad_norm": 0.14620965719223022,
      "learning_rate": 1.895118185057608e-06,
      "loss": 0.1391,
      "step": 81000
    },
    {
      "epoch": 9.680484618125668,
      "grad_norm": 28.77794075012207,
      "learning_rate": 1.5981708041335076e-06,
      "loss": 0.1589,
      "step": 81500
    },
    {
      "epoch": 9.739874094310489,
      "grad_norm": 0.1490425169467926,
      "learning_rate": 1.3012234232094074e-06,
      "loss": 0.1653,
      "step": 82000
    },
    {
      "epoch": 9.799263570495308,
      "grad_norm": 0.19641783833503723,
      "learning_rate": 1.004276042285307e-06,
      "loss": 0.1425,
      "step": 82500
    },
    {
      "epoch": 9.858653046680129,
      "grad_norm": 0.9098644852638245,
      "learning_rate": 7.073286613612068e-07,
      "loss": 0.1246,
      "step": 83000
    },
    {
      "epoch": 9.918042522864948,
      "grad_norm": 0.12437153607606888,
      "learning_rate": 4.1038128043710657e-07,
      "loss": 0.135,
      "step": 83500
    },
    {
      "epoch": 9.977431999049768,
      "grad_norm": 7.629302978515625,
      "learning_rate": 1.134338995130063e-07,
      "loss": 0.1462,
      "step": 84000
    },
    {
      "epoch": 10.0,
      "step": 84190,
      "total_flos": 1.5721775456910336e+17,
      "train_loss": 0.18749008081293203,
      "train_runtime": 13243.8917,
      "train_samples_per_second": 50.853,
      "train_steps_per_second": 6.357
    }
  ],
  "logging_steps": 500,
  "max_steps": 84190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5721775456910336e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
