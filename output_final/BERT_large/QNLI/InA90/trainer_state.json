{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 130930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038188344917131294,
      "grad_norm": 9.949535369873047,
      "learning_rate": 4.980944015886352e-05,
      "loss": 0.663,
      "step": 500
    },
    {
      "epoch": 0.07637668983426259,
      "grad_norm": 2.516079902648926,
      "learning_rate": 4.961849843427786e-05,
      "loss": 0.6166,
      "step": 1000
    },
    {
      "epoch": 0.11456503475139387,
      "grad_norm": 3.8968822956085205,
      "learning_rate": 4.94275567096922e-05,
      "loss": 0.5696,
      "step": 1500
    },
    {
      "epoch": 0.15275337966852517,
      "grad_norm": 11.839781761169434,
      "learning_rate": 4.923661498510655e-05,
      "loss": 0.5182,
      "step": 2000
    },
    {
      "epoch": 0.19094172458565645,
      "grad_norm": 6.640523433685303,
      "learning_rate": 4.904567326052089e-05,
      "loss": 0.478,
      "step": 2500
    },
    {
      "epoch": 0.22913006950278775,
      "grad_norm": 6.885077476501465,
      "learning_rate": 4.885473153593523e-05,
      "loss": 0.4684,
      "step": 3000
    },
    {
      "epoch": 0.26731841441991905,
      "grad_norm": 1.1206886768341064,
      "learning_rate": 4.866378981134958e-05,
      "loss": 0.4463,
      "step": 3500
    },
    {
      "epoch": 0.30550675933705035,
      "grad_norm": 5.353808403015137,
      "learning_rate": 4.847284808676392e-05,
      "loss": 0.4404,
      "step": 4000
    },
    {
      "epoch": 0.34369510425418165,
      "grad_norm": 4.173153400421143,
      "learning_rate": 4.828190636217826e-05,
      "loss": 0.4272,
      "step": 4500
    },
    {
      "epoch": 0.3818834491713129,
      "grad_norm": 4.18876838684082,
      "learning_rate": 4.809096463759261e-05,
      "loss": 0.4231,
      "step": 5000
    },
    {
      "epoch": 0.4200717940884442,
      "grad_norm": 1.1701053380966187,
      "learning_rate": 4.790002291300695e-05,
      "loss": 0.4145,
      "step": 5500
    },
    {
      "epoch": 0.4582601390055755,
      "grad_norm": 4.161426544189453,
      "learning_rate": 4.7709081188421295e-05,
      "loss": 0.4282,
      "step": 6000
    },
    {
      "epoch": 0.4964484839227068,
      "grad_norm": 2.539112091064453,
      "learning_rate": 4.7518139463835637e-05,
      "loss": 0.413,
      "step": 6500
    },
    {
      "epoch": 0.5346368288398381,
      "grad_norm": 2.629514217376709,
      "learning_rate": 4.7327197739249985e-05,
      "loss": 0.4117,
      "step": 7000
    },
    {
      "epoch": 0.5728251737569694,
      "grad_norm": 3.740987539291382,
      "learning_rate": 4.713625601466433e-05,
      "loss": 0.4017,
      "step": 7500
    },
    {
      "epoch": 0.6110135186741007,
      "grad_norm": 5.879226207733154,
      "learning_rate": 4.694531429007867e-05,
      "loss": 0.4078,
      "step": 8000
    },
    {
      "epoch": 0.649201863591232,
      "grad_norm": 5.121507167816162,
      "learning_rate": 4.675437256549302e-05,
      "loss": 0.4131,
      "step": 8500
    },
    {
      "epoch": 0.6873902085083633,
      "grad_norm": 4.009472370147705,
      "learning_rate": 4.656343084090736e-05,
      "loss": 0.3976,
      "step": 9000
    },
    {
      "epoch": 0.7255785534254945,
      "grad_norm": 2.691352128982544,
      "learning_rate": 4.63724891163217e-05,
      "loss": 0.3858,
      "step": 9500
    },
    {
      "epoch": 0.7637668983426258,
      "grad_norm": 6.846001148223877,
      "learning_rate": 4.618154739173605e-05,
      "loss": 0.3877,
      "step": 10000
    },
    {
      "epoch": 0.8019552432597571,
      "grad_norm": 8.1541748046875,
      "learning_rate": 4.599060566715039e-05,
      "loss": 0.3873,
      "step": 10500
    },
    {
      "epoch": 0.8401435881768884,
      "grad_norm": 2.5346784591674805,
      "learning_rate": 4.579966394256473e-05,
      "loss": 0.3822,
      "step": 11000
    },
    {
      "epoch": 0.8783319330940197,
      "grad_norm": 12.674993515014648,
      "learning_rate": 4.560872221797908e-05,
      "loss": 0.3742,
      "step": 11500
    },
    {
      "epoch": 0.916520278011151,
      "grad_norm": 2.418828010559082,
      "learning_rate": 4.541778049339342e-05,
      "loss": 0.379,
      "step": 12000
    },
    {
      "epoch": 0.9547086229282823,
      "grad_norm": 4.13533353805542,
      "learning_rate": 4.522683876880776e-05,
      "loss": 0.3874,
      "step": 12500
    },
    {
      "epoch": 0.9928969678454136,
      "grad_norm": 0.8415079712867737,
      "learning_rate": 4.5035897044222105e-05,
      "loss": 0.3823,
      "step": 13000
    },
    {
      "epoch": 1.0310853127625448,
      "grad_norm": 4.321774005889893,
      "learning_rate": 4.484495531963645e-05,
      "loss": 0.3739,
      "step": 13500
    },
    {
      "epoch": 1.0692736576796762,
      "grad_norm": 5.012912273406982,
      "learning_rate": 4.4654013595050795e-05,
      "loss": 0.3809,
      "step": 14000
    },
    {
      "epoch": 1.1074620025968074,
      "grad_norm": 6.443814277648926,
      "learning_rate": 4.4463071870465137e-05,
      "loss": 0.3729,
      "step": 14500
    },
    {
      "epoch": 1.1456503475139388,
      "grad_norm": 6.755543231964111,
      "learning_rate": 4.427213014587948e-05,
      "loss": 0.3674,
      "step": 15000
    },
    {
      "epoch": 1.18383869243107,
      "grad_norm": 4.646345615386963,
      "learning_rate": 4.408118842129382e-05,
      "loss": 0.3689,
      "step": 15500
    },
    {
      "epoch": 1.2220270373482014,
      "grad_norm": 3.759371280670166,
      "learning_rate": 4.389024669670817e-05,
      "loss": 0.3474,
      "step": 16000
    },
    {
      "epoch": 1.2602153822653326,
      "grad_norm": 1.0179038047790527,
      "learning_rate": 4.369930497212251e-05,
      "loss": 0.354,
      "step": 16500
    },
    {
      "epoch": 1.298403727182464,
      "grad_norm": 4.706476211547852,
      "learning_rate": 4.350836324753685e-05,
      "loss": 0.3706,
      "step": 17000
    },
    {
      "epoch": 1.3365920720995952,
      "grad_norm": 5.905998706817627,
      "learning_rate": 4.331742152295119e-05,
      "loss": 0.3682,
      "step": 17500
    },
    {
      "epoch": 1.3747804170167264,
      "grad_norm": 1.1783790588378906,
      "learning_rate": 4.312647979836554e-05,
      "loss": 0.3634,
      "step": 18000
    },
    {
      "epoch": 1.4129687619338578,
      "grad_norm": 4.629815578460693,
      "learning_rate": 4.293553807377988e-05,
      "loss": 0.3539,
      "step": 18500
    },
    {
      "epoch": 1.4511571068509892,
      "grad_norm": 0.612770676612854,
      "learning_rate": 4.2744596349194225e-05,
      "loss": 0.3497,
      "step": 19000
    },
    {
      "epoch": 1.4893454517681204,
      "grad_norm": 4.745299339294434,
      "learning_rate": 4.2553654624608566e-05,
      "loss": 0.3403,
      "step": 19500
    },
    {
      "epoch": 1.5275337966852516,
      "grad_norm": 4.0224809646606445,
      "learning_rate": 4.2362712900022915e-05,
      "loss": 0.3599,
      "step": 20000
    },
    {
      "epoch": 1.565722141602383,
      "grad_norm": 2.1696994304656982,
      "learning_rate": 4.2171771175437256e-05,
      "loss": 0.3535,
      "step": 20500
    },
    {
      "epoch": 1.6039104865195144,
      "grad_norm": 5.241518974304199,
      "learning_rate": 4.19808294508516e-05,
      "loss": 0.3667,
      "step": 21000
    },
    {
      "epoch": 1.6420988314366456,
      "grad_norm": 5.956056118011475,
      "learning_rate": 4.1789887726265946e-05,
      "loss": 0.3463,
      "step": 21500
    },
    {
      "epoch": 1.6802871763537768,
      "grad_norm": 8.432271957397461,
      "learning_rate": 4.159894600168029e-05,
      "loss": 0.347,
      "step": 22000
    },
    {
      "epoch": 1.718475521270908,
      "grad_norm": 3.981483221054077,
      "learning_rate": 4.140800427709463e-05,
      "loss": 0.3533,
      "step": 22500
    },
    {
      "epoch": 1.7566638661880394,
      "grad_norm": 3.928776502609253,
      "learning_rate": 4.121706255250898e-05,
      "loss": 0.352,
      "step": 23000
    },
    {
      "epoch": 1.7948522111051708,
      "grad_norm": 1.6580673456192017,
      "learning_rate": 4.102612082792332e-05,
      "loss": 0.3472,
      "step": 23500
    },
    {
      "epoch": 1.833040556022302,
      "grad_norm": 16.058053970336914,
      "learning_rate": 4.083517910333766e-05,
      "loss": 0.3447,
      "step": 24000
    },
    {
      "epoch": 1.8712289009394332,
      "grad_norm": 5.435301780700684,
      "learning_rate": 4.064423737875201e-05,
      "loss": 0.3465,
      "step": 24500
    },
    {
      "epoch": 1.9094172458565646,
      "grad_norm": 12.630341529846191,
      "learning_rate": 4.045329565416635e-05,
      "loss": 0.3427,
      "step": 25000
    },
    {
      "epoch": 1.947605590773696,
      "grad_norm": 6.982361316680908,
      "learning_rate": 4.026235392958069e-05,
      "loss": 0.3404,
      "step": 25500
    },
    {
      "epoch": 1.9857939356908272,
      "grad_norm": 2.354762554168701,
      "learning_rate": 4.0071412204995035e-05,
      "loss": 0.3333,
      "step": 26000
    },
    {
      "epoch": 2.0239822806079584,
      "grad_norm": 4.29294490814209,
      "learning_rate": 3.988047048040938e-05,
      "loss": 0.3531,
      "step": 26500
    },
    {
      "epoch": 2.0621706255250896,
      "grad_norm": 11.352030754089355,
      "learning_rate": 3.9689528755823725e-05,
      "loss": 0.321,
      "step": 27000
    },
    {
      "epoch": 2.100358970442221,
      "grad_norm": 4.7919182777404785,
      "learning_rate": 3.9498587031238066e-05,
      "loss": 0.3397,
      "step": 27500
    },
    {
      "epoch": 2.1385473153593524,
      "grad_norm": 5.161870002746582,
      "learning_rate": 3.9307645306652415e-05,
      "loss": 0.3421,
      "step": 28000
    },
    {
      "epoch": 2.1767356602764836,
      "grad_norm": 12.826974868774414,
      "learning_rate": 3.9116703582066756e-05,
      "loss": 0.3405,
      "step": 28500
    },
    {
      "epoch": 2.2149240051936148,
      "grad_norm": 4.332046031951904,
      "learning_rate": 3.89257618574811e-05,
      "loss": 0.3302,
      "step": 29000
    },
    {
      "epoch": 2.2531123501107464,
      "grad_norm": 1.1299570798873901,
      "learning_rate": 3.8734820132895446e-05,
      "loss": 0.3291,
      "step": 29500
    },
    {
      "epoch": 2.2913006950278776,
      "grad_norm": 7.238608360290527,
      "learning_rate": 3.854387840830979e-05,
      "loss": 0.3123,
      "step": 30000
    },
    {
      "epoch": 2.3294890399450088,
      "grad_norm": 5.297704696655273,
      "learning_rate": 3.835293668372413e-05,
      "loss": 0.3403,
      "step": 30500
    },
    {
      "epoch": 2.36767738486214,
      "grad_norm": 3.9493842124938965,
      "learning_rate": 3.816199495913848e-05,
      "loss": 0.3202,
      "step": 31000
    },
    {
      "epoch": 2.405865729779271,
      "grad_norm": 2.371035099029541,
      "learning_rate": 3.797105323455282e-05,
      "loss": 0.3358,
      "step": 31500
    },
    {
      "epoch": 2.444054074696403,
      "grad_norm": 7.308608531951904,
      "learning_rate": 3.778011150996716e-05,
      "loss": 0.3533,
      "step": 32000
    },
    {
      "epoch": 2.482242419613534,
      "grad_norm": 4.075193405151367,
      "learning_rate": 3.75891697853815e-05,
      "loss": 0.3262,
      "step": 32500
    },
    {
      "epoch": 2.520430764530665,
      "grad_norm": 8.797531127929688,
      "learning_rate": 3.739822806079585e-05,
      "loss": 0.3383,
      "step": 33000
    },
    {
      "epoch": 2.558619109447797,
      "grad_norm": 1.5847524404525757,
      "learning_rate": 3.720728633621019e-05,
      "loss": 0.3122,
      "step": 33500
    },
    {
      "epoch": 2.596807454364928,
      "grad_norm": 8.510970115661621,
      "learning_rate": 3.7016344611624534e-05,
      "loss": 0.3445,
      "step": 34000
    },
    {
      "epoch": 2.634995799282059,
      "grad_norm": 4.826423645019531,
      "learning_rate": 3.6825402887038876e-05,
      "loss": 0.3381,
      "step": 34500
    },
    {
      "epoch": 2.6731841441991904,
      "grad_norm": 9.054593086242676,
      "learning_rate": 3.663446116245322e-05,
      "loss": 0.3273,
      "step": 35000
    },
    {
      "epoch": 2.7113724891163216,
      "grad_norm": 8.667019844055176,
      "learning_rate": 3.644351943786756e-05,
      "loss": 0.3334,
      "step": 35500
    },
    {
      "epoch": 2.7495608340334527,
      "grad_norm": 6.7379631996154785,
      "learning_rate": 3.625257771328191e-05,
      "loss": 0.3362,
      "step": 36000
    },
    {
      "epoch": 2.7877491789505844,
      "grad_norm": 6.624180316925049,
      "learning_rate": 3.606163598869625e-05,
      "loss": 0.3343,
      "step": 36500
    },
    {
      "epoch": 2.8259375238677156,
      "grad_norm": 11.94194221496582,
      "learning_rate": 3.587069426411059e-05,
      "loss": 0.3251,
      "step": 37000
    },
    {
      "epoch": 2.8641258687848468,
      "grad_norm": 3.102813482284546,
      "learning_rate": 3.567975253952494e-05,
      "loss": 0.3368,
      "step": 37500
    },
    {
      "epoch": 2.9023142137019784,
      "grad_norm": 10.842575073242188,
      "learning_rate": 3.548881081493928e-05,
      "loss": 0.3269,
      "step": 38000
    },
    {
      "epoch": 2.9405025586191096,
      "grad_norm": 8.727618217468262,
      "learning_rate": 3.529786909035362e-05,
      "loss": 0.3325,
      "step": 38500
    },
    {
      "epoch": 2.9786909035362408,
      "grad_norm": 3.3137190341949463,
      "learning_rate": 3.510692736576797e-05,
      "loss": 0.3255,
      "step": 39000
    },
    {
      "epoch": 3.016879248453372,
      "grad_norm": 1.5349363088607788,
      "learning_rate": 3.491598564118231e-05,
      "loss": 0.3424,
      "step": 39500
    },
    {
      "epoch": 3.055067593370503,
      "grad_norm": 1.6797438859939575,
      "learning_rate": 3.4725043916596654e-05,
      "loss": 0.3279,
      "step": 40000
    },
    {
      "epoch": 3.093255938287635,
      "grad_norm": 5.136842250823975,
      "learning_rate": 3.4534102192010996e-05,
      "loss": 0.3323,
      "step": 40500
    },
    {
      "epoch": 3.131444283204766,
      "grad_norm": 8.994490623474121,
      "learning_rate": 3.4343160467425344e-05,
      "loss": 0.3215,
      "step": 41000
    },
    {
      "epoch": 3.169632628121897,
      "grad_norm": 2.1333088874816895,
      "learning_rate": 3.4152218742839686e-05,
      "loss": 0.343,
      "step": 41500
    },
    {
      "epoch": 3.2078209730390284,
      "grad_norm": 0.8457027077674866,
      "learning_rate": 3.396127701825403e-05,
      "loss": 0.3131,
      "step": 42000
    },
    {
      "epoch": 3.24600931795616,
      "grad_norm": 8.931843757629395,
      "learning_rate": 3.3770335293668376e-05,
      "loss": 0.3137,
      "step": 42500
    },
    {
      "epoch": 3.284197662873291,
      "grad_norm": 9.17138957977295,
      "learning_rate": 3.357939356908272e-05,
      "loss": 0.3273,
      "step": 43000
    },
    {
      "epoch": 3.3223860077904224,
      "grad_norm": 14.429389953613281,
      "learning_rate": 3.338845184449706e-05,
      "loss": 0.3145,
      "step": 43500
    },
    {
      "epoch": 3.3605743527075536,
      "grad_norm": 4.151413440704346,
      "learning_rate": 3.319751011991141e-05,
      "loss": 0.3239,
      "step": 44000
    },
    {
      "epoch": 3.3987626976246847,
      "grad_norm": 8.100569725036621,
      "learning_rate": 3.300656839532575e-05,
      "loss": 0.3238,
      "step": 44500
    },
    {
      "epoch": 3.4369510425418164,
      "grad_norm": 5.404658317565918,
      "learning_rate": 3.281562667074009e-05,
      "loss": 0.3063,
      "step": 45000
    },
    {
      "epoch": 3.4751393874589476,
      "grad_norm": 0.944146454334259,
      "learning_rate": 3.262468494615444e-05,
      "loss": 0.3155,
      "step": 45500
    },
    {
      "epoch": 3.5133277323760788,
      "grad_norm": 7.272260665893555,
      "learning_rate": 3.243374322156878e-05,
      "loss": 0.3197,
      "step": 46000
    },
    {
      "epoch": 3.55151607729321,
      "grad_norm": 1.3460116386413574,
      "learning_rate": 3.224280149698312e-05,
      "loss": 0.3243,
      "step": 46500
    },
    {
      "epoch": 3.5897044222103416,
      "grad_norm": 6.68721866607666,
      "learning_rate": 3.2051859772397464e-05,
      "loss": 0.3288,
      "step": 47000
    },
    {
      "epoch": 3.6278927671274728,
      "grad_norm": 7.454747200012207,
      "learning_rate": 3.186091804781181e-05,
      "loss": 0.3311,
      "step": 47500
    },
    {
      "epoch": 3.666081112044604,
      "grad_norm": 1.0401543378829956,
      "learning_rate": 3.1669976323226154e-05,
      "loss": 0.3048,
      "step": 48000
    },
    {
      "epoch": 3.704269456961735,
      "grad_norm": 7.2841410636901855,
      "learning_rate": 3.1479034598640496e-05,
      "loss": 0.3203,
      "step": 48500
    },
    {
      "epoch": 3.7424578018788663,
      "grad_norm": 10.196657180786133,
      "learning_rate": 3.1288092874054844e-05,
      "loss": 0.3181,
      "step": 49000
    },
    {
      "epoch": 3.780646146795998,
      "grad_norm": 1.0446057319641113,
      "learning_rate": 3.1097151149469186e-05,
      "loss": 0.3207,
      "step": 49500
    },
    {
      "epoch": 3.818834491713129,
      "grad_norm": 5.6081438064575195,
      "learning_rate": 3.090620942488353e-05,
      "loss": 0.3239,
      "step": 50000
    },
    {
      "epoch": 3.8570228366302604,
      "grad_norm": 6.836927890777588,
      "learning_rate": 3.0715267700297876e-05,
      "loss": 0.3281,
      "step": 50500
    },
    {
      "epoch": 3.895211181547392,
      "grad_norm": 4.588394641876221,
      "learning_rate": 3.052432597571222e-05,
      "loss": 0.3352,
      "step": 51000
    },
    {
      "epoch": 3.933399526464523,
      "grad_norm": 5.530942916870117,
      "learning_rate": 3.0333384251126556e-05,
      "loss": 0.3007,
      "step": 51500
    },
    {
      "epoch": 3.9715878713816544,
      "grad_norm": 7.364265441894531,
      "learning_rate": 3.0142442526540904e-05,
      "loss": 0.3165,
      "step": 52000
    },
    {
      "epoch": 4.009776216298786,
      "grad_norm": 6.68869686126709,
      "learning_rate": 2.9951500801955246e-05,
      "loss": 0.2945,
      "step": 52500
    },
    {
      "epoch": 4.047964561215917,
      "grad_norm": 3.205108880996704,
      "learning_rate": 2.9760559077369587e-05,
      "loss": 0.313,
      "step": 53000
    },
    {
      "epoch": 4.086152906133048,
      "grad_norm": 8.344220161437988,
      "learning_rate": 2.956961735278393e-05,
      "loss": 0.3265,
      "step": 53500
    },
    {
      "epoch": 4.124341251050179,
      "grad_norm": 11.553081512451172,
      "learning_rate": 2.9378675628198277e-05,
      "loss": 0.3124,
      "step": 54000
    },
    {
      "epoch": 4.162529595967311,
      "grad_norm": 4.898372650146484,
      "learning_rate": 2.918773390361262e-05,
      "loss": 0.3272,
      "step": 54500
    },
    {
      "epoch": 4.200717940884442,
      "grad_norm": 10.123993873596191,
      "learning_rate": 2.899679217902696e-05,
      "loss": 0.291,
      "step": 55000
    },
    {
      "epoch": 4.238906285801574,
      "grad_norm": 3.197312355041504,
      "learning_rate": 2.880585045444131e-05,
      "loss": 0.331,
      "step": 55500
    },
    {
      "epoch": 4.277094630718705,
      "grad_norm": 4.677900314331055,
      "learning_rate": 2.861490872985565e-05,
      "loss": 0.3094,
      "step": 56000
    },
    {
      "epoch": 4.315282975635836,
      "grad_norm": 8.409811973571777,
      "learning_rate": 2.8423967005269992e-05,
      "loss": 0.3181,
      "step": 56500
    },
    {
      "epoch": 4.353471320552967,
      "grad_norm": 4.802584171295166,
      "learning_rate": 2.8233025280684337e-05,
      "loss": 0.3356,
      "step": 57000
    },
    {
      "epoch": 4.391659665470098,
      "grad_norm": 0.8703061938285828,
      "learning_rate": 2.804208355609868e-05,
      "loss": 0.3235,
      "step": 57500
    },
    {
      "epoch": 4.4298480103872295,
      "grad_norm": 5.27825927734375,
      "learning_rate": 2.7851141831513024e-05,
      "loss": 0.2979,
      "step": 58000
    },
    {
      "epoch": 4.468036355304361,
      "grad_norm": 5.501797676086426,
      "learning_rate": 2.766020010692737e-05,
      "loss": 0.2953,
      "step": 58500
    },
    {
      "epoch": 4.506224700221493,
      "grad_norm": 8.261566162109375,
      "learning_rate": 2.746925838234171e-05,
      "loss": 0.3103,
      "step": 59000
    },
    {
      "epoch": 4.544413045138624,
      "grad_norm": 13.326375007629395,
      "learning_rate": 2.7278316657756052e-05,
      "loss": 0.3231,
      "step": 59500
    },
    {
      "epoch": 4.582601390055755,
      "grad_norm": 4.1786298751831055,
      "learning_rate": 2.7087374933170394e-05,
      "loss": 0.3005,
      "step": 60000
    },
    {
      "epoch": 4.620789734972886,
      "grad_norm": 2.9035542011260986,
      "learning_rate": 2.6896433208584742e-05,
      "loss": 0.3059,
      "step": 60500
    },
    {
      "epoch": 4.6589780798900176,
      "grad_norm": 7.716691493988037,
      "learning_rate": 2.6705491483999084e-05,
      "loss": 0.3117,
      "step": 61000
    },
    {
      "epoch": 4.697166424807149,
      "grad_norm": 5.183434009552002,
      "learning_rate": 2.6514549759413426e-05,
      "loss": 0.3093,
      "step": 61500
    },
    {
      "epoch": 4.73535476972428,
      "grad_norm": 0.9080737829208374,
      "learning_rate": 2.6323608034827774e-05,
      "loss": 0.306,
      "step": 62000
    },
    {
      "epoch": 4.773543114641411,
      "grad_norm": 1.1182013750076294,
      "learning_rate": 2.6132666310242116e-05,
      "loss": 0.2957,
      "step": 62500
    },
    {
      "epoch": 4.811731459558542,
      "grad_norm": 4.169547080993652,
      "learning_rate": 2.5941724585656457e-05,
      "loss": 0.3001,
      "step": 63000
    },
    {
      "epoch": 4.849919804475674,
      "grad_norm": 1.3549491167068481,
      "learning_rate": 2.5750782861070806e-05,
      "loss": 0.3077,
      "step": 63500
    },
    {
      "epoch": 4.888108149392806,
      "grad_norm": 9.07935905456543,
      "learning_rate": 2.5559841136485147e-05,
      "loss": 0.2971,
      "step": 64000
    },
    {
      "epoch": 4.926296494309937,
      "grad_norm": 5.150195598602295,
      "learning_rate": 2.536889941189949e-05,
      "loss": 0.2919,
      "step": 64500
    },
    {
      "epoch": 4.964484839227068,
      "grad_norm": 6.598069667816162,
      "learning_rate": 2.5177957687313837e-05,
      "loss": 0.3122,
      "step": 65000
    },
    {
      "epoch": 5.002673184144199,
      "grad_norm": 7.93243932723999,
      "learning_rate": 2.498701596272818e-05,
      "loss": 0.2934,
      "step": 65500
    },
    {
      "epoch": 5.04086152906133,
      "grad_norm": 0.6917842030525208,
      "learning_rate": 2.479607423814252e-05,
      "loss": 0.3109,
      "step": 66000
    },
    {
      "epoch": 5.0790498739784615,
      "grad_norm": 11.39120864868164,
      "learning_rate": 2.4605132513556866e-05,
      "loss": 0.303,
      "step": 66500
    },
    {
      "epoch": 5.117238218895593,
      "grad_norm": 4.579926490783691,
      "learning_rate": 2.4414190788971207e-05,
      "loss": 0.3261,
      "step": 67000
    },
    {
      "epoch": 5.155426563812725,
      "grad_norm": 5.116159439086914,
      "learning_rate": 2.422324906438555e-05,
      "loss": 0.3085,
      "step": 67500
    },
    {
      "epoch": 5.193614908729856,
      "grad_norm": 3.877734661102295,
      "learning_rate": 2.4032307339799894e-05,
      "loss": 0.299,
      "step": 68000
    },
    {
      "epoch": 5.231803253646987,
      "grad_norm": 1.3029069900512695,
      "learning_rate": 2.3841365615214235e-05,
      "loss": 0.303,
      "step": 68500
    },
    {
      "epoch": 5.269991598564118,
      "grad_norm": 7.371504306793213,
      "learning_rate": 2.365042389062858e-05,
      "loss": 0.2968,
      "step": 69000
    },
    {
      "epoch": 5.3081799434812496,
      "grad_norm": 0.9687303304672241,
      "learning_rate": 2.3459482166042925e-05,
      "loss": 0.3088,
      "step": 69500
    },
    {
      "epoch": 5.346368288398381,
      "grad_norm": 6.211594104766846,
      "learning_rate": 2.3268540441457267e-05,
      "loss": 0.296,
      "step": 70000
    },
    {
      "epoch": 5.384556633315512,
      "grad_norm": 0.8960598707199097,
      "learning_rate": 2.3077598716871612e-05,
      "loss": 0.3131,
      "step": 70500
    },
    {
      "epoch": 5.422744978232643,
      "grad_norm": 5.5377302169799805,
      "learning_rate": 2.2886656992285954e-05,
      "loss": 0.313,
      "step": 71000
    },
    {
      "epoch": 5.460933323149774,
      "grad_norm": 4.843117713928223,
      "learning_rate": 2.26957152677003e-05,
      "loss": 0.2996,
      "step": 71500
    },
    {
      "epoch": 5.499121668066906,
      "grad_norm": 0.8328416347503662,
      "learning_rate": 2.2504773543114644e-05,
      "loss": 0.2947,
      "step": 72000
    },
    {
      "epoch": 5.537310012984038,
      "grad_norm": 7.357219219207764,
      "learning_rate": 2.2313831818528985e-05,
      "loss": 0.299,
      "step": 72500
    },
    {
      "epoch": 5.575498357901169,
      "grad_norm": 1.1003167629241943,
      "learning_rate": 2.212289009394333e-05,
      "loss": 0.2987,
      "step": 73000
    },
    {
      "epoch": 5.6136867028183,
      "grad_norm": 4.80298376083374,
      "learning_rate": 2.1931948369357675e-05,
      "loss": 0.3158,
      "step": 73500
    },
    {
      "epoch": 5.651875047735431,
      "grad_norm": 1.0065211057662964,
      "learning_rate": 2.1741006644772017e-05,
      "loss": 0.3159,
      "step": 74000
    },
    {
      "epoch": 5.690063392652562,
      "grad_norm": 3.5976459980010986,
      "learning_rate": 2.1550064920186362e-05,
      "loss": 0.3007,
      "step": 74500
    },
    {
      "epoch": 5.7282517375696935,
      "grad_norm": 9.15860366821289,
      "learning_rate": 2.1359123195600704e-05,
      "loss": 0.2823,
      "step": 75000
    },
    {
      "epoch": 5.766440082486825,
      "grad_norm": 8.92285442352295,
      "learning_rate": 2.116818147101505e-05,
      "loss": 0.3134,
      "step": 75500
    },
    {
      "epoch": 5.804628427403957,
      "grad_norm": 1.5882797241210938,
      "learning_rate": 2.097723974642939e-05,
      "loss": 0.311,
      "step": 76000
    },
    {
      "epoch": 5.842816772321088,
      "grad_norm": 6.396711826324463,
      "learning_rate": 2.0786298021843735e-05,
      "loss": 0.3001,
      "step": 76500
    },
    {
      "epoch": 5.881005117238219,
      "grad_norm": 4.903302192687988,
      "learning_rate": 2.0595356297258077e-05,
      "loss": 0.2871,
      "step": 77000
    },
    {
      "epoch": 5.91919346215535,
      "grad_norm": 13.866966247558594,
      "learning_rate": 2.040441457267242e-05,
      "loss": 0.3088,
      "step": 77500
    },
    {
      "epoch": 5.9573818070724815,
      "grad_norm": 6.376019477844238,
      "learning_rate": 2.0213472848086764e-05,
      "loss": 0.3144,
      "step": 78000
    },
    {
      "epoch": 5.995570151989613,
      "grad_norm": 12.099715232849121,
      "learning_rate": 2.002253112350111e-05,
      "loss": 0.2846,
      "step": 78500
    },
    {
      "epoch": 6.033758496906744,
      "grad_norm": 4.8461456298828125,
      "learning_rate": 1.983158939891545e-05,
      "loss": 0.315,
      "step": 79000
    },
    {
      "epoch": 6.071946841823875,
      "grad_norm": 6.220055103302002,
      "learning_rate": 1.9640647674329795e-05,
      "loss": 0.2944,
      "step": 79500
    },
    {
      "epoch": 6.110135186741006,
      "grad_norm": 12.4039306640625,
      "learning_rate": 1.944970594974414e-05,
      "loss": 0.2918,
      "step": 80000
    },
    {
      "epoch": 6.1483235316581375,
      "grad_norm": 3.0065455436706543,
      "learning_rate": 1.9258764225158482e-05,
      "loss": 0.3033,
      "step": 80500
    },
    {
      "epoch": 6.18651187657527,
      "grad_norm": 3.6589555740356445,
      "learning_rate": 1.9067822500572827e-05,
      "loss": 0.3114,
      "step": 81000
    },
    {
      "epoch": 6.224700221492401,
      "grad_norm": 2.1584672927856445,
      "learning_rate": 1.887688077598717e-05,
      "loss": 0.2748,
      "step": 81500
    },
    {
      "epoch": 6.262888566409532,
      "grad_norm": 6.067856311798096,
      "learning_rate": 1.8685939051401514e-05,
      "loss": 0.2993,
      "step": 82000
    },
    {
      "epoch": 6.301076911326663,
      "grad_norm": 5.400592803955078,
      "learning_rate": 1.849499732681586e-05,
      "loss": 0.2965,
      "step": 82500
    },
    {
      "epoch": 6.339265256243794,
      "grad_norm": 7.292181491851807,
      "learning_rate": 1.83040556022302e-05,
      "loss": 0.3063,
      "step": 83000
    },
    {
      "epoch": 6.3774536011609255,
      "grad_norm": 7.199634552001953,
      "learning_rate": 1.8113113877644545e-05,
      "loss": 0.3051,
      "step": 83500
    },
    {
      "epoch": 6.415641946078057,
      "grad_norm": 14.05126953125,
      "learning_rate": 1.7922172153058887e-05,
      "loss": 0.301,
      "step": 84000
    },
    {
      "epoch": 6.453830290995188,
      "grad_norm": 8.688016891479492,
      "learning_rate": 1.7731230428473232e-05,
      "loss": 0.2985,
      "step": 84500
    },
    {
      "epoch": 6.49201863591232,
      "grad_norm": 1.2778218984603882,
      "learning_rate": 1.7540288703887577e-05,
      "loss": 0.2868,
      "step": 85000
    },
    {
      "epoch": 6.530206980829451,
      "grad_norm": 6.270583152770996,
      "learning_rate": 1.734934697930192e-05,
      "loss": 0.3002,
      "step": 85500
    },
    {
      "epoch": 6.568395325746582,
      "grad_norm": 1.3351253271102905,
      "learning_rate": 1.715840525471626e-05,
      "loss": 0.3124,
      "step": 86000
    },
    {
      "epoch": 6.6065836706637135,
      "grad_norm": 0.7679943442344666,
      "learning_rate": 1.6967463530130605e-05,
      "loss": 0.282,
      "step": 86500
    },
    {
      "epoch": 6.644772015580845,
      "grad_norm": 0.9891488552093506,
      "learning_rate": 1.6776521805544947e-05,
      "loss": 0.296,
      "step": 87000
    },
    {
      "epoch": 6.682960360497976,
      "grad_norm": 5.792471408843994,
      "learning_rate": 1.6585580080959292e-05,
      "loss": 0.2964,
      "step": 87500
    },
    {
      "epoch": 6.721148705415107,
      "grad_norm": 8.692513465881348,
      "learning_rate": 1.6394638356373633e-05,
      "loss": 0.3041,
      "step": 88000
    },
    {
      "epoch": 6.759337050332238,
      "grad_norm": 16.01938247680664,
      "learning_rate": 1.620369663178798e-05,
      "loss": 0.301,
      "step": 88500
    },
    {
      "epoch": 6.7975253952493695,
      "grad_norm": 5.085179328918457,
      "learning_rate": 1.6012754907202323e-05,
      "loss": 0.2819,
      "step": 89000
    },
    {
      "epoch": 6.835713740166501,
      "grad_norm": 0.46184098720550537,
      "learning_rate": 1.5821813182616665e-05,
      "loss": 0.3013,
      "step": 89500
    },
    {
      "epoch": 6.873902085083633,
      "grad_norm": 5.778287410736084,
      "learning_rate": 1.563087145803101e-05,
      "loss": 0.3114,
      "step": 90000
    },
    {
      "epoch": 6.912090430000764,
      "grad_norm": 1.3193073272705078,
      "learning_rate": 1.543992973344535e-05,
      "loss": 0.3159,
      "step": 90500
    },
    {
      "epoch": 6.950278774917895,
      "grad_norm": 11.222740173339844,
      "learning_rate": 1.5248988008859697e-05,
      "loss": 0.3023,
      "step": 91000
    },
    {
      "epoch": 6.988467119835026,
      "grad_norm": 3.493286609649658,
      "learning_rate": 1.5058046284274042e-05,
      "loss": 0.2883,
      "step": 91500
    },
    {
      "epoch": 7.0266554647521575,
      "grad_norm": 0.867214024066925,
      "learning_rate": 1.4867104559688383e-05,
      "loss": 0.3017,
      "step": 92000
    },
    {
      "epoch": 7.064843809669289,
      "grad_norm": 3.15506649017334,
      "learning_rate": 1.4676162835102728e-05,
      "loss": 0.2934,
      "step": 92500
    },
    {
      "epoch": 7.10303215458642,
      "grad_norm": 4.025750637054443,
      "learning_rate": 1.4485221110517072e-05,
      "loss": 0.2946,
      "step": 93000
    },
    {
      "epoch": 7.141220499503551,
      "grad_norm": 12.331196784973145,
      "learning_rate": 1.4294279385931413e-05,
      "loss": 0.2919,
      "step": 93500
    },
    {
      "epoch": 7.179408844420683,
      "grad_norm": 8.935169219970703,
      "learning_rate": 1.4103337661345758e-05,
      "loss": 0.2834,
      "step": 94000
    },
    {
      "epoch": 7.217597189337814,
      "grad_norm": 0.7081635594367981,
      "learning_rate": 1.39123959367601e-05,
      "loss": 0.3027,
      "step": 94500
    },
    {
      "epoch": 7.2557855342549455,
      "grad_norm": 7.162354469299316,
      "learning_rate": 1.3721454212174445e-05,
      "loss": 0.2853,
      "step": 95000
    },
    {
      "epoch": 7.293973879172077,
      "grad_norm": 7.536683082580566,
      "learning_rate": 1.353051248758879e-05,
      "loss": 0.2947,
      "step": 95500
    },
    {
      "epoch": 7.332162224089208,
      "grad_norm": 0.9845448136329651,
      "learning_rate": 1.3339570763003132e-05,
      "loss": 0.2965,
      "step": 96000
    },
    {
      "epoch": 7.370350569006339,
      "grad_norm": 7.092708110809326,
      "learning_rate": 1.3148629038417477e-05,
      "loss": 0.2844,
      "step": 96500
    },
    {
      "epoch": 7.40853891392347,
      "grad_norm": 10.263493537902832,
      "learning_rate": 1.2957687313831818e-05,
      "loss": 0.2782,
      "step": 97000
    },
    {
      "epoch": 7.4467272588406015,
      "grad_norm": 1.3007735013961792,
      "learning_rate": 1.2766745589246163e-05,
      "loss": 0.3111,
      "step": 97500
    },
    {
      "epoch": 7.484915603757733,
      "grad_norm": 4.799861431121826,
      "learning_rate": 1.2575803864660507e-05,
      "loss": 0.2889,
      "step": 98000
    },
    {
      "epoch": 7.523103948674865,
      "grad_norm": 9.08496379852295,
      "learning_rate": 1.238486214007485e-05,
      "loss": 0.2813,
      "step": 98500
    },
    {
      "epoch": 7.561292293591996,
      "grad_norm": 0.5923462510108948,
      "learning_rate": 1.2193920415489193e-05,
      "loss": 0.3103,
      "step": 99000
    },
    {
      "epoch": 7.599480638509127,
      "grad_norm": 1.557008147239685,
      "learning_rate": 1.2002978690903536e-05,
      "loss": 0.3008,
      "step": 99500
    },
    {
      "epoch": 7.637668983426258,
      "grad_norm": 10.266047477722168,
      "learning_rate": 1.181203696631788e-05,
      "loss": 0.2899,
      "step": 100000
    },
    {
      "epoch": 7.6758573283433895,
      "grad_norm": 1.3031977415084839,
      "learning_rate": 1.1621095241732225e-05,
      "loss": 0.3192,
      "step": 100500
    },
    {
      "epoch": 7.714045673260521,
      "grad_norm": 1.0234571695327759,
      "learning_rate": 1.1430153517146568e-05,
      "loss": 0.2987,
      "step": 101000
    },
    {
      "epoch": 7.752234018177652,
      "grad_norm": 2.3600361347198486,
      "learning_rate": 1.1239211792560911e-05,
      "loss": 0.3056,
      "step": 101500
    },
    {
      "epoch": 7.790422363094783,
      "grad_norm": 0.7855092287063599,
      "learning_rate": 1.1048270067975255e-05,
      "loss": 0.3059,
      "step": 102000
    },
    {
      "epoch": 7.828610708011915,
      "grad_norm": 0.5287765860557556,
      "learning_rate": 1.0857328343389598e-05,
      "loss": 0.3159,
      "step": 102500
    },
    {
      "epoch": 7.866799052929046,
      "grad_norm": 2.6977882385253906,
      "learning_rate": 1.0666386618803941e-05,
      "loss": 0.2724,
      "step": 103000
    },
    {
      "epoch": 7.9049873978461775,
      "grad_norm": 9.427961349487305,
      "learning_rate": 1.0475444894218285e-05,
      "loss": 0.2892,
      "step": 103500
    },
    {
      "epoch": 7.943175742763309,
      "grad_norm": 5.831766605377197,
      "learning_rate": 1.0284503169632628e-05,
      "loss": 0.304,
      "step": 104000
    },
    {
      "epoch": 7.98136408768044,
      "grad_norm": 1.0361089706420898,
      "learning_rate": 1.0093561445046971e-05,
      "loss": 0.3,
      "step": 104500
    },
    {
      "epoch": 8.019552432597571,
      "grad_norm": 10.343498229980469,
      "learning_rate": 9.902619720461316e-06,
      "loss": 0.2996,
      "step": 105000
    },
    {
      "epoch": 8.057740777514702,
      "grad_norm": 9.656902313232422,
      "learning_rate": 9.71167799587566e-06,
      "loss": 0.2935,
      "step": 105500
    },
    {
      "epoch": 8.095929122431833,
      "grad_norm": 7.862234592437744,
      "learning_rate": 9.520736271290003e-06,
      "loss": 0.2884,
      "step": 106000
    },
    {
      "epoch": 8.134117467348965,
      "grad_norm": 19.05902099609375,
      "learning_rate": 9.329794546704346e-06,
      "loss": 0.2778,
      "step": 106500
    },
    {
      "epoch": 8.172305812266096,
      "grad_norm": 19.455942153930664,
      "learning_rate": 9.13885282211869e-06,
      "loss": 0.2956,
      "step": 107000
    },
    {
      "epoch": 8.210494157183227,
      "grad_norm": 10.747884750366211,
      "learning_rate": 8.947911097533033e-06,
      "loss": 0.2817,
      "step": 107500
    },
    {
      "epoch": 8.248682502100358,
      "grad_norm": 3.194430351257324,
      "learning_rate": 8.756969372947376e-06,
      "loss": 0.2926,
      "step": 108000
    },
    {
      "epoch": 8.28687084701749,
      "grad_norm": 5.501270771026611,
      "learning_rate": 8.56602764836172e-06,
      "loss": 0.2853,
      "step": 108500
    },
    {
      "epoch": 8.325059191934622,
      "grad_norm": 4.7704291343688965,
      "learning_rate": 8.375085923776065e-06,
      "loss": 0.2847,
      "step": 109000
    },
    {
      "epoch": 8.363247536851754,
      "grad_norm": 12.53687572479248,
      "learning_rate": 8.184144199190408e-06,
      "loss": 0.2952,
      "step": 109500
    },
    {
      "epoch": 8.401435881768885,
      "grad_norm": 6.735651016235352,
      "learning_rate": 7.993202474604751e-06,
      "loss": 0.2927,
      "step": 110000
    },
    {
      "epoch": 8.439624226686016,
      "grad_norm": 6.205052852630615,
      "learning_rate": 7.802260750019095e-06,
      "loss": 0.29,
      "step": 110500
    },
    {
      "epoch": 8.477812571603147,
      "grad_norm": 0.8268216848373413,
      "learning_rate": 7.611319025433437e-06,
      "loss": 0.2743,
      "step": 111000
    },
    {
      "epoch": 8.516000916520278,
      "grad_norm": 8.162919998168945,
      "learning_rate": 7.420377300847782e-06,
      "loss": 0.2931,
      "step": 111500
    },
    {
      "epoch": 8.55418926143741,
      "grad_norm": 0.5739408731460571,
      "learning_rate": 7.2294355762621254e-06,
      "loss": 0.2926,
      "step": 112000
    },
    {
      "epoch": 8.59237760635454,
      "grad_norm": 1.520267128944397,
      "learning_rate": 7.038493851676469e-06,
      "loss": 0.3196,
      "step": 112500
    },
    {
      "epoch": 8.630565951271672,
      "grad_norm": 0.7827140092849731,
      "learning_rate": 6.847552127090811e-06,
      "loss": 0.2782,
      "step": 113000
    },
    {
      "epoch": 8.668754296188803,
      "grad_norm": 10.384861946105957,
      "learning_rate": 6.656610402505156e-06,
      "loss": 0.2978,
      "step": 113500
    },
    {
      "epoch": 8.706942641105934,
      "grad_norm": 5.371720314025879,
      "learning_rate": 6.4656686779194996e-06,
      "loss": 0.308,
      "step": 114000
    },
    {
      "epoch": 8.745130986023065,
      "grad_norm": 4.0015058517456055,
      "learning_rate": 6.274726953333843e-06,
      "loss": 0.3007,
      "step": 114500
    },
    {
      "epoch": 8.783319330940197,
      "grad_norm": 9.170289039611816,
      "learning_rate": 6.083785228748186e-06,
      "loss": 0.2929,
      "step": 115000
    },
    {
      "epoch": 8.821507675857328,
      "grad_norm": 1.413697600364685,
      "learning_rate": 5.8928435041625295e-06,
      "loss": 0.2721,
      "step": 115500
    },
    {
      "epoch": 8.859696020774459,
      "grad_norm": 7.948320388793945,
      "learning_rate": 5.701901779576874e-06,
      "loss": 0.2758,
      "step": 116000
    },
    {
      "epoch": 8.89788436569159,
      "grad_norm": 6.068889141082764,
      "learning_rate": 5.510960054991217e-06,
      "loss": 0.2949,
      "step": 116500
    },
    {
      "epoch": 8.936072710608721,
      "grad_norm": 4.384580135345459,
      "learning_rate": 5.320018330405561e-06,
      "loss": 0.3022,
      "step": 117000
    },
    {
      "epoch": 8.974261055525854,
      "grad_norm": 4.915485858917236,
      "learning_rate": 5.129076605819904e-06,
      "loss": 0.2863,
      "step": 117500
    },
    {
      "epoch": 9.012449400442986,
      "grad_norm": 8.741601943969727,
      "learning_rate": 4.938134881234248e-06,
      "loss": 0.2886,
      "step": 118000
    },
    {
      "epoch": 9.050637745360117,
      "grad_norm": 0.9410789608955383,
      "learning_rate": 4.747193156648591e-06,
      "loss": 0.2776,
      "step": 118500
    },
    {
      "epoch": 9.088826090277248,
      "grad_norm": 8.582465171813965,
      "learning_rate": 4.5562514320629344e-06,
      "loss": 0.3053,
      "step": 119000
    },
    {
      "epoch": 9.12701443519438,
      "grad_norm": 6.61831521987915,
      "learning_rate": 4.365309707477279e-06,
      "loss": 0.287,
      "step": 119500
    },
    {
      "epoch": 9.16520278011151,
      "grad_norm": 0.880193293094635,
      "learning_rate": 4.174367982891621e-06,
      "loss": 0.2951,
      "step": 120000
    },
    {
      "epoch": 9.203391125028642,
      "grad_norm": 9.84064769744873,
      "learning_rate": 3.983426258305965e-06,
      "loss": 0.2807,
      "step": 120500
    },
    {
      "epoch": 9.241579469945773,
      "grad_norm": 5.244017124176025,
      "learning_rate": 3.7924845337203086e-06,
      "loss": 0.2922,
      "step": 121000
    },
    {
      "epoch": 9.279767814862904,
      "grad_norm": 0.8293601274490356,
      "learning_rate": 3.6015428091346523e-06,
      "loss": 0.2892,
      "step": 121500
    },
    {
      "epoch": 9.317956159780035,
      "grad_norm": 0.4033152461051941,
      "learning_rate": 3.4106010845489956e-06,
      "loss": 0.2812,
      "step": 122000
    },
    {
      "epoch": 9.356144504697166,
      "grad_norm": 0.45363131165504456,
      "learning_rate": 3.2196593599633394e-06,
      "loss": 0.3055,
      "step": 122500
    },
    {
      "epoch": 9.394332849614297,
      "grad_norm": 6.099381923675537,
      "learning_rate": 3.0287176353776827e-06,
      "loss": 0.2807,
      "step": 123000
    },
    {
      "epoch": 9.432521194531429,
      "grad_norm": 7.0820112228393555,
      "learning_rate": 2.8377759107920264e-06,
      "loss": 0.3207,
      "step": 123500
    },
    {
      "epoch": 9.47070953944856,
      "grad_norm": 11.36723804473877,
      "learning_rate": 2.6468341862063698e-06,
      "loss": 0.2779,
      "step": 124000
    },
    {
      "epoch": 9.508897884365691,
      "grad_norm": 2.099149703979492,
      "learning_rate": 2.4558924616207135e-06,
      "loss": 0.2913,
      "step": 124500
    },
    {
      "epoch": 9.547086229282822,
      "grad_norm": 1.3303396701812744,
      "learning_rate": 2.264950737035057e-06,
      "loss": 0.3054,
      "step": 125000
    },
    {
      "epoch": 9.585274574199953,
      "grad_norm": 6.661375045776367,
      "learning_rate": 2.0740090124494006e-06,
      "loss": 0.3023,
      "step": 125500
    },
    {
      "epoch": 9.623462919117085,
      "grad_norm": 7.787227153778076,
      "learning_rate": 1.883067287863744e-06,
      "loss": 0.2896,
      "step": 126000
    },
    {
      "epoch": 9.661651264034216,
      "grad_norm": 1.0795390605926514,
      "learning_rate": 1.6921255632780876e-06,
      "loss": 0.2812,
      "step": 126500
    },
    {
      "epoch": 9.699839608951349,
      "grad_norm": 8.347513198852539,
      "learning_rate": 1.501183838692431e-06,
      "loss": 0.2728,
      "step": 127000
    },
    {
      "epoch": 9.73802795386848,
      "grad_norm": 5.8591790199279785,
      "learning_rate": 1.3102421141067747e-06,
      "loss": 0.2795,
      "step": 127500
    },
    {
      "epoch": 9.776216298785611,
      "grad_norm": 10.994630813598633,
      "learning_rate": 1.1193003895211182e-06,
      "loss": 0.2706,
      "step": 128000
    },
    {
      "epoch": 9.814404643702742,
      "grad_norm": 15.484472274780273,
      "learning_rate": 9.283586649354618e-07,
      "loss": 0.2952,
      "step": 128500
    },
    {
      "epoch": 9.852592988619874,
      "grad_norm": 10.064146041870117,
      "learning_rate": 7.374169403498053e-07,
      "loss": 0.3235,
      "step": 129000
    },
    {
      "epoch": 9.890781333537005,
      "grad_norm": 11.702432632446289,
      "learning_rate": 5.464752157641488e-07,
      "loss": 0.2677,
      "step": 129500
    },
    {
      "epoch": 9.928969678454136,
      "grad_norm": 6.6747965812683105,
      "learning_rate": 3.5553349117849236e-07,
      "loss": 0.3088,
      "step": 130000
    },
    {
      "epoch": 9.967158023371267,
      "grad_norm": 9.074546813964844,
      "learning_rate": 1.6459176659283587e-07,
      "loss": 0.2733,
      "step": 130500
    },
    {
      "epoch": 10.0,
      "step": 130930,
      "total_flos": 2.4450933594903552e+17,
      "train_loss": 0.3236683373453782,
      "train_runtime": 20028.5826,
      "train_samples_per_second": 52.297,
      "train_steps_per_second": 6.537
    }
  ],
  "logging_steps": 500,
  "max_steps": 130930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4450933594903552e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
