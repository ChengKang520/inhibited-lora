{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 130930,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038188344917131294,
      "grad_norm": 11.479917526245117,
      "learning_rate": 4.980944015886352e-05,
      "loss": 0.6255,
      "step": 500
    },
    {
      "epoch": 0.07637668983426259,
      "grad_norm": 4.063249111175537,
      "learning_rate": 4.961849843427786e-05,
      "loss": 0.47,
      "step": 1000
    },
    {
      "epoch": 0.11456503475139387,
      "grad_norm": 6.076443195343018,
      "learning_rate": 4.94275567096922e-05,
      "loss": 0.4186,
      "step": 1500
    },
    {
      "epoch": 0.15275337966852517,
      "grad_norm": 8.877880096435547,
      "learning_rate": 4.923661498510655e-05,
      "loss": 0.4069,
      "step": 2000
    },
    {
      "epoch": 0.19094172458565645,
      "grad_norm": 8.737967491149902,
      "learning_rate": 4.904567326052089e-05,
      "loss": 0.389,
      "step": 2500
    },
    {
      "epoch": 0.22913006950278775,
      "grad_norm": 14.011225700378418,
      "learning_rate": 4.885473153593523e-05,
      "loss": 0.3865,
      "step": 3000
    },
    {
      "epoch": 0.26731841441991905,
      "grad_norm": 5.005514621734619,
      "learning_rate": 4.866378981134958e-05,
      "loss": 0.3807,
      "step": 3500
    },
    {
      "epoch": 0.30550675933705035,
      "grad_norm": 8.090361595153809,
      "learning_rate": 4.847284808676392e-05,
      "loss": 0.3813,
      "step": 4000
    },
    {
      "epoch": 0.34369510425418165,
      "grad_norm": 6.055410385131836,
      "learning_rate": 4.828190636217826e-05,
      "loss": 0.3735,
      "step": 4500
    },
    {
      "epoch": 0.3818834491713129,
      "grad_norm": 7.088924884796143,
      "learning_rate": 4.809096463759261e-05,
      "loss": 0.3586,
      "step": 5000
    },
    {
      "epoch": 0.4200717940884442,
      "grad_norm": 2.07759952545166,
      "learning_rate": 4.790002291300695e-05,
      "loss": 0.3656,
      "step": 5500
    },
    {
      "epoch": 0.4582601390055755,
      "grad_norm": 3.7118706703186035,
      "learning_rate": 4.7709081188421295e-05,
      "loss": 0.3693,
      "step": 6000
    },
    {
      "epoch": 0.4964484839227068,
      "grad_norm": 5.794365406036377,
      "learning_rate": 4.7518139463835637e-05,
      "loss": 0.3639,
      "step": 6500
    },
    {
      "epoch": 0.5346368288398381,
      "grad_norm": 2.663973093032837,
      "learning_rate": 4.7327197739249985e-05,
      "loss": 0.3625,
      "step": 7000
    },
    {
      "epoch": 0.5728251737569694,
      "grad_norm": 18.439319610595703,
      "learning_rate": 4.713625601466433e-05,
      "loss": 0.3451,
      "step": 7500
    },
    {
      "epoch": 0.6110135186741007,
      "grad_norm": 12.853132247924805,
      "learning_rate": 4.694531429007867e-05,
      "loss": 0.3604,
      "step": 8000
    },
    {
      "epoch": 0.649201863591232,
      "grad_norm": 6.535250186920166,
      "learning_rate": 4.675437256549302e-05,
      "loss": 0.3608,
      "step": 8500
    },
    {
      "epoch": 0.6873902085083633,
      "grad_norm": 9.07868766784668,
      "learning_rate": 4.656343084090736e-05,
      "loss": 0.3411,
      "step": 9000
    },
    {
      "epoch": 0.7255785534254945,
      "grad_norm": 5.583614349365234,
      "learning_rate": 4.63724891163217e-05,
      "loss": 0.3299,
      "step": 9500
    },
    {
      "epoch": 0.7637668983426258,
      "grad_norm": 6.036375522613525,
      "learning_rate": 4.618154739173605e-05,
      "loss": 0.3443,
      "step": 10000
    },
    {
      "epoch": 0.8019552432597571,
      "grad_norm": 2.825648069381714,
      "learning_rate": 4.599060566715039e-05,
      "loss": 0.3242,
      "step": 10500
    },
    {
      "epoch": 0.8401435881768884,
      "grad_norm": 7.05299711227417,
      "learning_rate": 4.579966394256473e-05,
      "loss": 0.3448,
      "step": 11000
    },
    {
      "epoch": 0.8783319330940197,
      "grad_norm": 8.637062072753906,
      "learning_rate": 4.560872221797908e-05,
      "loss": 0.3361,
      "step": 11500
    },
    {
      "epoch": 0.916520278011151,
      "grad_norm": 0.5047008395195007,
      "learning_rate": 4.541778049339342e-05,
      "loss": 0.3281,
      "step": 12000
    },
    {
      "epoch": 0.9547086229282823,
      "grad_norm": 5.502310752868652,
      "learning_rate": 4.522683876880776e-05,
      "loss": 0.3476,
      "step": 12500
    },
    {
      "epoch": 0.9928969678454136,
      "grad_norm": 0.44944119453430176,
      "learning_rate": 4.5035897044222105e-05,
      "loss": 0.3273,
      "step": 13000
    },
    {
      "epoch": 1.0310853127625448,
      "grad_norm": 9.77472972869873,
      "learning_rate": 4.484495531963645e-05,
      "loss": 0.3263,
      "step": 13500
    },
    {
      "epoch": 1.0692736576796762,
      "grad_norm": 12.123292922973633,
      "learning_rate": 4.4654013595050795e-05,
      "loss": 0.3313,
      "step": 14000
    },
    {
      "epoch": 1.1074620025968074,
      "grad_norm": 3.7246716022491455,
      "learning_rate": 4.4463071870465137e-05,
      "loss": 0.3222,
      "step": 14500
    },
    {
      "epoch": 1.1456503475139388,
      "grad_norm": 5.716081619262695,
      "learning_rate": 4.427213014587948e-05,
      "loss": 0.332,
      "step": 15000
    },
    {
      "epoch": 1.18383869243107,
      "grad_norm": 12.554161071777344,
      "learning_rate": 4.408118842129382e-05,
      "loss": 0.3263,
      "step": 15500
    },
    {
      "epoch": 1.2220270373482014,
      "grad_norm": 2.247711181640625,
      "learning_rate": 4.389024669670817e-05,
      "loss": 0.3085,
      "step": 16000
    },
    {
      "epoch": 1.2602153822653326,
      "grad_norm": 1.0816915035247803,
      "learning_rate": 4.369930497212251e-05,
      "loss": 0.3117,
      "step": 16500
    },
    {
      "epoch": 1.298403727182464,
      "grad_norm": 14.901175498962402,
      "learning_rate": 4.350836324753685e-05,
      "loss": 0.3224,
      "step": 17000
    },
    {
      "epoch": 1.3365920720995952,
      "grad_norm": 3.456470251083374,
      "learning_rate": 4.331742152295119e-05,
      "loss": 0.3226,
      "step": 17500
    },
    {
      "epoch": 1.3747804170167264,
      "grad_norm": 0.8238729238510132,
      "learning_rate": 4.312647979836554e-05,
      "loss": 0.3218,
      "step": 18000
    },
    {
      "epoch": 1.4129687619338578,
      "grad_norm": 5.911967754364014,
      "learning_rate": 4.293553807377988e-05,
      "loss": 0.3244,
      "step": 18500
    },
    {
      "epoch": 1.4511571068509892,
      "grad_norm": 0.5300803780555725,
      "learning_rate": 4.2744596349194225e-05,
      "loss": 0.3032,
      "step": 19000
    },
    {
      "epoch": 1.4893454517681204,
      "grad_norm": 6.139369487762451,
      "learning_rate": 4.2553654624608566e-05,
      "loss": 0.3091,
      "step": 19500
    },
    {
      "epoch": 1.5275337966852516,
      "grad_norm": 6.21149206161499,
      "learning_rate": 4.2362712900022915e-05,
      "loss": 0.3087,
      "step": 20000
    },
    {
      "epoch": 1.565722141602383,
      "grad_norm": 6.8691511154174805,
      "learning_rate": 4.2171771175437256e-05,
      "loss": 0.3215,
      "step": 20500
    },
    {
      "epoch": 1.6039104865195144,
      "grad_norm": 7.8403143882751465,
      "learning_rate": 4.19808294508516e-05,
      "loss": 0.3322,
      "step": 21000
    },
    {
      "epoch": 1.6420988314366456,
      "grad_norm": 12.472674369812012,
      "learning_rate": 4.1789887726265946e-05,
      "loss": 0.315,
      "step": 21500
    },
    {
      "epoch": 1.6802871763537768,
      "grad_norm": 10.866687774658203,
      "learning_rate": 4.159894600168029e-05,
      "loss": 0.3114,
      "step": 22000
    },
    {
      "epoch": 1.718475521270908,
      "grad_norm": 10.108475685119629,
      "learning_rate": 4.140800427709463e-05,
      "loss": 0.3208,
      "step": 22500
    },
    {
      "epoch": 1.7566638661880394,
      "grad_norm": 2.7234880924224854,
      "learning_rate": 4.121706255250898e-05,
      "loss": 0.3096,
      "step": 23000
    },
    {
      "epoch": 1.7948522111051708,
      "grad_norm": 1.8477228879928589,
      "learning_rate": 4.102612082792332e-05,
      "loss": 0.3232,
      "step": 23500
    },
    {
      "epoch": 1.833040556022302,
      "grad_norm": 10.494180679321289,
      "learning_rate": 4.083517910333766e-05,
      "loss": 0.3134,
      "step": 24000
    },
    {
      "epoch": 1.8712289009394332,
      "grad_norm": 7.375835418701172,
      "learning_rate": 4.064423737875201e-05,
      "loss": 0.3125,
      "step": 24500
    },
    {
      "epoch": 1.9094172458565646,
      "grad_norm": 22.747434616088867,
      "learning_rate": 4.045329565416635e-05,
      "loss": 0.3037,
      "step": 25000
    },
    {
      "epoch": 1.947605590773696,
      "grad_norm": 4.493505954742432,
      "learning_rate": 4.026235392958069e-05,
      "loss": 0.3082,
      "step": 25500
    },
    {
      "epoch": 1.9857939356908272,
      "grad_norm": 6.316943168640137,
      "learning_rate": 4.0071412204995035e-05,
      "loss": 0.3036,
      "step": 26000
    },
    {
      "epoch": 2.0239822806079584,
      "grad_norm": 10.739480972290039,
      "learning_rate": 3.988047048040938e-05,
      "loss": 0.3178,
      "step": 26500
    },
    {
      "epoch": 2.0621706255250896,
      "grad_norm": 17.740543365478516,
      "learning_rate": 3.9689528755823725e-05,
      "loss": 0.2839,
      "step": 27000
    },
    {
      "epoch": 2.100358970442221,
      "grad_norm": 15.855250358581543,
      "learning_rate": 3.9498587031238066e-05,
      "loss": 0.3034,
      "step": 27500
    },
    {
      "epoch": 2.1385473153593524,
      "grad_norm": 6.197862148284912,
      "learning_rate": 3.9307645306652415e-05,
      "loss": 0.2962,
      "step": 28000
    },
    {
      "epoch": 2.1767356602764836,
      "grad_norm": 17.151241302490234,
      "learning_rate": 3.9116703582066756e-05,
      "loss": 0.3096,
      "step": 28500
    },
    {
      "epoch": 2.2149240051936148,
      "grad_norm": 1.1142467260360718,
      "learning_rate": 3.89257618574811e-05,
      "loss": 0.291,
      "step": 29000
    },
    {
      "epoch": 2.2531123501107464,
      "grad_norm": 2.7884130477905273,
      "learning_rate": 3.8734820132895446e-05,
      "loss": 0.2926,
      "step": 29500
    },
    {
      "epoch": 2.2913006950278776,
      "grad_norm": 10.039198875427246,
      "learning_rate": 3.854387840830979e-05,
      "loss": 0.2968,
      "step": 30000
    },
    {
      "epoch": 2.3294890399450088,
      "grad_norm": 20.058338165283203,
      "learning_rate": 3.835293668372413e-05,
      "loss": 0.2959,
      "step": 30500
    },
    {
      "epoch": 2.36767738486214,
      "grad_norm": 1.7427171468734741,
      "learning_rate": 3.816199495913848e-05,
      "loss": 0.2916,
      "step": 31000
    },
    {
      "epoch": 2.405865729779271,
      "grad_norm": 4.682043075561523,
      "learning_rate": 3.797105323455282e-05,
      "loss": 0.3074,
      "step": 31500
    },
    {
      "epoch": 2.444054074696403,
      "grad_norm": 10.980270385742188,
      "learning_rate": 3.778011150996716e-05,
      "loss": 0.3127,
      "step": 32000
    },
    {
      "epoch": 2.482242419613534,
      "grad_norm": 6.444638729095459,
      "learning_rate": 3.75891697853815e-05,
      "loss": 0.2847,
      "step": 32500
    },
    {
      "epoch": 2.520430764530665,
      "grad_norm": 1.4804614782333374,
      "learning_rate": 3.739822806079585e-05,
      "loss": 0.2987,
      "step": 33000
    },
    {
      "epoch": 2.558619109447797,
      "grad_norm": 0.42072612047195435,
      "learning_rate": 3.720728633621019e-05,
      "loss": 0.2936,
      "step": 33500
    },
    {
      "epoch": 2.596807454364928,
      "grad_norm": 12.760251998901367,
      "learning_rate": 3.7016344611624534e-05,
      "loss": 0.2972,
      "step": 34000
    },
    {
      "epoch": 2.634995799282059,
      "grad_norm": 17.141849517822266,
      "learning_rate": 3.6825402887038876e-05,
      "loss": 0.3051,
      "step": 34500
    },
    {
      "epoch": 2.6731841441991904,
      "grad_norm": 7.430707931518555,
      "learning_rate": 3.663446116245322e-05,
      "loss": 0.2991,
      "step": 35000
    },
    {
      "epoch": 2.7113724891163216,
      "grad_norm": 11.95800495147705,
      "learning_rate": 3.644351943786756e-05,
      "loss": 0.299,
      "step": 35500
    },
    {
      "epoch": 2.7495608340334527,
      "grad_norm": 19.31920051574707,
      "learning_rate": 3.625257771328191e-05,
      "loss": 0.298,
      "step": 36000
    },
    {
      "epoch": 2.7877491789505844,
      "grad_norm": 11.924211502075195,
      "learning_rate": 3.606163598869625e-05,
      "loss": 0.2956,
      "step": 36500
    },
    {
      "epoch": 2.8259375238677156,
      "grad_norm": 13.84641170501709,
      "learning_rate": 3.587069426411059e-05,
      "loss": 0.2933,
      "step": 37000
    },
    {
      "epoch": 2.8641258687848468,
      "grad_norm": 1.4324191808700562,
      "learning_rate": 3.567975253952494e-05,
      "loss": 0.2955,
      "step": 37500
    },
    {
      "epoch": 2.9023142137019784,
      "grad_norm": 16.496456146240234,
      "learning_rate": 3.548881081493928e-05,
      "loss": 0.2979,
      "step": 38000
    },
    {
      "epoch": 2.9405025586191096,
      "grad_norm": 11.092369079589844,
      "learning_rate": 3.529786909035362e-05,
      "loss": 0.3057,
      "step": 38500
    },
    {
      "epoch": 2.9786909035362408,
      "grad_norm": 7.267322063446045,
      "learning_rate": 3.510692736576797e-05,
      "loss": 0.3009,
      "step": 39000
    },
    {
      "epoch": 3.016879248453372,
      "grad_norm": 0.5357177257537842,
      "learning_rate": 3.491598564118231e-05,
      "loss": 0.2896,
      "step": 39500
    },
    {
      "epoch": 3.055067593370503,
      "grad_norm": 1.155114769935608,
      "learning_rate": 3.4725043916596654e-05,
      "loss": 0.2932,
      "step": 40000
    },
    {
      "epoch": 3.093255938287635,
      "grad_norm": 8.982892036437988,
      "learning_rate": 3.4534102192010996e-05,
      "loss": 0.285,
      "step": 40500
    },
    {
      "epoch": 3.131444283204766,
      "grad_norm": 12.096739768981934,
      "learning_rate": 3.4343160467425344e-05,
      "loss": 0.3005,
      "step": 41000
    },
    {
      "epoch": 3.169632628121897,
      "grad_norm": 0.784485399723053,
      "learning_rate": 3.4152218742839686e-05,
      "loss": 0.2924,
      "step": 41500
    },
    {
      "epoch": 3.2078209730390284,
      "grad_norm": 0.4195365309715271,
      "learning_rate": 3.396127701825403e-05,
      "loss": 0.2869,
      "step": 42000
    },
    {
      "epoch": 3.24600931795616,
      "grad_norm": 7.811360836029053,
      "learning_rate": 3.3770335293668376e-05,
      "loss": 0.2832,
      "step": 42500
    },
    {
      "epoch": 3.284197662873291,
      "grad_norm": 11.713638305664062,
      "learning_rate": 3.357939356908272e-05,
      "loss": 0.3067,
      "step": 43000
    },
    {
      "epoch": 3.3223860077904224,
      "grad_norm": 17.278959274291992,
      "learning_rate": 3.338845184449706e-05,
      "loss": 0.2745,
      "step": 43500
    },
    {
      "epoch": 3.3605743527075536,
      "grad_norm": 1.324584722518921,
      "learning_rate": 3.319751011991141e-05,
      "loss": 0.2786,
      "step": 44000
    },
    {
      "epoch": 3.3987626976246847,
      "grad_norm": 9.455523490905762,
      "learning_rate": 3.300656839532575e-05,
      "loss": 0.2822,
      "step": 44500
    },
    {
      "epoch": 3.4369510425418164,
      "grad_norm": 7.415541648864746,
      "learning_rate": 3.281562667074009e-05,
      "loss": 0.2723,
      "step": 45000
    },
    {
      "epoch": 3.4751393874589476,
      "grad_norm": 8.517974853515625,
      "learning_rate": 3.262468494615444e-05,
      "loss": 0.2762,
      "step": 45500
    },
    {
      "epoch": 3.5133277323760788,
      "grad_norm": 13.677776336669922,
      "learning_rate": 3.243374322156878e-05,
      "loss": 0.2864,
      "step": 46000
    },
    {
      "epoch": 3.55151607729321,
      "grad_norm": 0.65522700548172,
      "learning_rate": 3.224280149698312e-05,
      "loss": 0.2864,
      "step": 46500
    },
    {
      "epoch": 3.5897044222103416,
      "grad_norm": 10.037339210510254,
      "learning_rate": 3.2051859772397464e-05,
      "loss": 0.2923,
      "step": 47000
    },
    {
      "epoch": 3.6278927671274728,
      "grad_norm": 6.771048069000244,
      "learning_rate": 3.186091804781181e-05,
      "loss": 0.2945,
      "step": 47500
    },
    {
      "epoch": 3.666081112044604,
      "grad_norm": 3.607975959777832,
      "learning_rate": 3.1669976323226154e-05,
      "loss": 0.2801,
      "step": 48000
    },
    {
      "epoch": 3.704269456961735,
      "grad_norm": 15.881536483764648,
      "learning_rate": 3.1479034598640496e-05,
      "loss": 0.2878,
      "step": 48500
    },
    {
      "epoch": 3.7424578018788663,
      "grad_norm": 1.156734585762024,
      "learning_rate": 3.1288092874054844e-05,
      "loss": 0.2904,
      "step": 49000
    },
    {
      "epoch": 3.780646146795998,
      "grad_norm": 0.6118171811103821,
      "learning_rate": 3.1097151149469186e-05,
      "loss": 0.285,
      "step": 49500
    },
    {
      "epoch": 3.818834491713129,
      "grad_norm": 1.8113188743591309,
      "learning_rate": 3.090620942488353e-05,
      "loss": 0.2764,
      "step": 50000
    },
    {
      "epoch": 3.8570228366302604,
      "grad_norm": 11.482481956481934,
      "learning_rate": 3.0715267700297876e-05,
      "loss": 0.2979,
      "step": 50500
    },
    {
      "epoch": 3.895211181547392,
      "grad_norm": 9.721230506896973,
      "learning_rate": 3.052432597571222e-05,
      "loss": 0.2947,
      "step": 51000
    },
    {
      "epoch": 3.933399526464523,
      "grad_norm": 8.53109073638916,
      "learning_rate": 3.0333384251126556e-05,
      "loss": 0.2746,
      "step": 51500
    },
    {
      "epoch": 3.9715878713816544,
      "grad_norm": 9.790496826171875,
      "learning_rate": 3.0142442526540904e-05,
      "loss": 0.2917,
      "step": 52000
    },
    {
      "epoch": 4.009776216298786,
      "grad_norm": 9.370100975036621,
      "learning_rate": 2.9951500801955246e-05,
      "loss": 0.2632,
      "step": 52500
    },
    {
      "epoch": 4.047964561215917,
      "grad_norm": 11.718461990356445,
      "learning_rate": 2.9760559077369587e-05,
      "loss": 0.2694,
      "step": 53000
    },
    {
      "epoch": 4.086152906133048,
      "grad_norm": 19.03695297241211,
      "learning_rate": 2.956961735278393e-05,
      "loss": 0.2871,
      "step": 53500
    },
    {
      "epoch": 4.124341251050179,
      "grad_norm": 32.05430221557617,
      "learning_rate": 2.9378675628198277e-05,
      "loss": 0.2777,
      "step": 54000
    },
    {
      "epoch": 4.162529595967311,
      "grad_norm": 5.773058891296387,
      "learning_rate": 2.918773390361262e-05,
      "loss": 0.2922,
      "step": 54500
    },
    {
      "epoch": 4.200717940884442,
      "grad_norm": 0.40718138217926025,
      "learning_rate": 2.899679217902696e-05,
      "loss": 0.2638,
      "step": 55000
    },
    {
      "epoch": 4.238906285801574,
      "grad_norm": 13.066161155700684,
      "learning_rate": 2.880585045444131e-05,
      "loss": 0.2867,
      "step": 55500
    },
    {
      "epoch": 4.277094630718705,
      "grad_norm": 6.674785614013672,
      "learning_rate": 2.861490872985565e-05,
      "loss": 0.2762,
      "step": 56000
    },
    {
      "epoch": 4.315282975635836,
      "grad_norm": 16.38603401184082,
      "learning_rate": 2.8423967005269992e-05,
      "loss": 0.2909,
      "step": 56500
    },
    {
      "epoch": 4.353471320552967,
      "grad_norm": 0.7691944241523743,
      "learning_rate": 2.8233025280684337e-05,
      "loss": 0.2834,
      "step": 57000
    },
    {
      "epoch": 4.391659665470098,
      "grad_norm": 0.43585050106048584,
      "learning_rate": 2.804208355609868e-05,
      "loss": 0.2793,
      "step": 57500
    },
    {
      "epoch": 4.4298480103872295,
      "grad_norm": 33.396419525146484,
      "learning_rate": 2.7851141831513024e-05,
      "loss": 0.2677,
      "step": 58000
    },
    {
      "epoch": 4.468036355304361,
      "grad_norm": 8.177713394165039,
      "learning_rate": 2.766020010692737e-05,
      "loss": 0.2733,
      "step": 58500
    },
    {
      "epoch": 4.506224700221493,
      "grad_norm": 10.081765174865723,
      "learning_rate": 2.746925838234171e-05,
      "loss": 0.27,
      "step": 59000
    },
    {
      "epoch": 4.544413045138624,
      "grad_norm": 14.650464057922363,
      "learning_rate": 2.7278316657756052e-05,
      "loss": 0.2916,
      "step": 59500
    },
    {
      "epoch": 4.582601390055755,
      "grad_norm": 6.256812572479248,
      "learning_rate": 2.7087374933170394e-05,
      "loss": 0.2685,
      "step": 60000
    },
    {
      "epoch": 4.620789734972886,
      "grad_norm": 0.9923094511032104,
      "learning_rate": 2.6896433208584742e-05,
      "loss": 0.27,
      "step": 60500
    },
    {
      "epoch": 4.6589780798900176,
      "grad_norm": 17.55318260192871,
      "learning_rate": 2.6705491483999084e-05,
      "loss": 0.2797,
      "step": 61000
    },
    {
      "epoch": 4.697166424807149,
      "grad_norm": 10.312139511108398,
      "learning_rate": 2.6514549759413426e-05,
      "loss": 0.269,
      "step": 61500
    },
    {
      "epoch": 4.73535476972428,
      "grad_norm": 0.3760388195514679,
      "learning_rate": 2.6323608034827774e-05,
      "loss": 0.2731,
      "step": 62000
    },
    {
      "epoch": 4.773543114641411,
      "grad_norm": 0.3794688880443573,
      "learning_rate": 2.6132666310242116e-05,
      "loss": 0.2641,
      "step": 62500
    },
    {
      "epoch": 4.811731459558542,
      "grad_norm": 24.687969207763672,
      "learning_rate": 2.5941724585656457e-05,
      "loss": 0.2569,
      "step": 63000
    },
    {
      "epoch": 4.849919804475674,
      "grad_norm": 0.35477590560913086,
      "learning_rate": 2.5750782861070806e-05,
      "loss": 0.2821,
      "step": 63500
    },
    {
      "epoch": 4.888108149392806,
      "grad_norm": 12.996932983398438,
      "learning_rate": 2.5559841136485147e-05,
      "loss": 0.2594,
      "step": 64000
    },
    {
      "epoch": 4.926296494309937,
      "grad_norm": 26.96327781677246,
      "learning_rate": 2.536889941189949e-05,
      "loss": 0.2673,
      "step": 64500
    },
    {
      "epoch": 4.964484839227068,
      "grad_norm": 8.330635070800781,
      "learning_rate": 2.5177957687313837e-05,
      "loss": 0.2757,
      "step": 65000
    },
    {
      "epoch": 5.002673184144199,
      "grad_norm": 14.076995849609375,
      "learning_rate": 2.498701596272818e-05,
      "loss": 0.2725,
      "step": 65500
    },
    {
      "epoch": 5.04086152906133,
      "grad_norm": 0.25298964977264404,
      "learning_rate": 2.479607423814252e-05,
      "loss": 0.2542,
      "step": 66000
    },
    {
      "epoch": 5.0790498739784615,
      "grad_norm": 46.578426361083984,
      "learning_rate": 2.4605132513556866e-05,
      "loss": 0.261,
      "step": 66500
    },
    {
      "epoch": 5.117238218895593,
      "grad_norm": 10.432655334472656,
      "learning_rate": 2.4414190788971207e-05,
      "loss": 0.2851,
      "step": 67000
    },
    {
      "epoch": 5.155426563812725,
      "grad_norm": 4.167952060699463,
      "learning_rate": 2.422324906438555e-05,
      "loss": 0.2735,
      "step": 67500
    },
    {
      "epoch": 5.193614908729856,
      "grad_norm": 0.27316340804100037,
      "learning_rate": 2.4032307339799894e-05,
      "loss": 0.2628,
      "step": 68000
    },
    {
      "epoch": 5.231803253646987,
      "grad_norm": 0.5950897336006165,
      "learning_rate": 2.3841365615214235e-05,
      "loss": 0.2683,
      "step": 68500
    },
    {
      "epoch": 5.269991598564118,
      "grad_norm": 34.143428802490234,
      "learning_rate": 2.365042389062858e-05,
      "loss": 0.258,
      "step": 69000
    },
    {
      "epoch": 5.3081799434812496,
      "grad_norm": 0.8260636329650879,
      "learning_rate": 2.3459482166042925e-05,
      "loss": 0.2586,
      "step": 69500
    },
    {
      "epoch": 5.346368288398381,
      "grad_norm": 0.716440737247467,
      "learning_rate": 2.3268540441457267e-05,
      "loss": 0.2679,
      "step": 70000
    },
    {
      "epoch": 5.384556633315512,
      "grad_norm": 0.38433006405830383,
      "learning_rate": 2.3077598716871612e-05,
      "loss": 0.276,
      "step": 70500
    },
    {
      "epoch": 5.422744978232643,
      "grad_norm": 8.556076049804688,
      "learning_rate": 2.2886656992285954e-05,
      "loss": 0.2814,
      "step": 71000
    },
    {
      "epoch": 5.460933323149774,
      "grad_norm": 0.5107830166816711,
      "learning_rate": 2.26957152677003e-05,
      "loss": 0.2599,
      "step": 71500
    },
    {
      "epoch": 5.499121668066906,
      "grad_norm": 1.2700514793395996,
      "learning_rate": 2.2504773543114644e-05,
      "loss": 0.2495,
      "step": 72000
    },
    {
      "epoch": 5.537310012984038,
      "grad_norm": 26.120574951171875,
      "learning_rate": 2.2313831818528985e-05,
      "loss": 0.2665,
      "step": 72500
    },
    {
      "epoch": 5.575498357901169,
      "grad_norm": 2.1999335289001465,
      "learning_rate": 2.212289009394333e-05,
      "loss": 0.2635,
      "step": 73000
    },
    {
      "epoch": 5.6136867028183,
      "grad_norm": 14.655807495117188,
      "learning_rate": 2.1931948369357675e-05,
      "loss": 0.279,
      "step": 73500
    },
    {
      "epoch": 5.651875047735431,
      "grad_norm": 0.479753315448761,
      "learning_rate": 2.1741006644772017e-05,
      "loss": 0.2587,
      "step": 74000
    },
    {
      "epoch": 5.690063392652562,
      "grad_norm": 0.5939254760742188,
      "learning_rate": 2.1550064920186362e-05,
      "loss": 0.2728,
      "step": 74500
    },
    {
      "epoch": 5.7282517375696935,
      "grad_norm": 5.450633525848389,
      "learning_rate": 2.1359123195600704e-05,
      "loss": 0.2533,
      "step": 75000
    },
    {
      "epoch": 5.766440082486825,
      "grad_norm": 33.33818054199219,
      "learning_rate": 2.116818147101505e-05,
      "loss": 0.2711,
      "step": 75500
    },
    {
      "epoch": 5.804628427403957,
      "grad_norm": 0.6927990913391113,
      "learning_rate": 2.097723974642939e-05,
      "loss": 0.272,
      "step": 76000
    },
    {
      "epoch": 5.842816772321088,
      "grad_norm": 9.646309852600098,
      "learning_rate": 2.0786298021843735e-05,
      "loss": 0.2731,
      "step": 76500
    },
    {
      "epoch": 5.881005117238219,
      "grad_norm": 5.817882537841797,
      "learning_rate": 2.0595356297258077e-05,
      "loss": 0.2601,
      "step": 77000
    },
    {
      "epoch": 5.91919346215535,
      "grad_norm": 26.427865982055664,
      "learning_rate": 2.040441457267242e-05,
      "loss": 0.2734,
      "step": 77500
    },
    {
      "epoch": 5.9573818070724815,
      "grad_norm": 5.949215412139893,
      "learning_rate": 2.0213472848086764e-05,
      "loss": 0.2831,
      "step": 78000
    },
    {
      "epoch": 5.995570151989613,
      "grad_norm": 38.148624420166016,
      "learning_rate": 2.002253112350111e-05,
      "loss": 0.2526,
      "step": 78500
    },
    {
      "epoch": 6.033758496906744,
      "grad_norm": 7.834826469421387,
      "learning_rate": 1.983158939891545e-05,
      "loss": 0.277,
      "step": 79000
    },
    {
      "epoch": 6.071946841823875,
      "grad_norm": 0.4554772973060608,
      "learning_rate": 1.9640647674329795e-05,
      "loss": 0.2583,
      "step": 79500
    },
    {
      "epoch": 6.110135186741006,
      "grad_norm": 17.07042694091797,
      "learning_rate": 1.944970594974414e-05,
      "loss": 0.2579,
      "step": 80000
    },
    {
      "epoch": 6.1483235316581375,
      "grad_norm": 2.2619404792785645,
      "learning_rate": 1.9258764225158482e-05,
      "loss": 0.2592,
      "step": 80500
    },
    {
      "epoch": 6.18651187657527,
      "grad_norm": 56.6258659362793,
      "learning_rate": 1.9067822500572827e-05,
      "loss": 0.2634,
      "step": 81000
    },
    {
      "epoch": 6.224700221492401,
      "grad_norm": 12.97281551361084,
      "learning_rate": 1.887688077598717e-05,
      "loss": 0.2477,
      "step": 81500
    },
    {
      "epoch": 6.262888566409532,
      "grad_norm": 16.288732528686523,
      "learning_rate": 1.8685939051401514e-05,
      "loss": 0.2677,
      "step": 82000
    },
    {
      "epoch": 6.301076911326663,
      "grad_norm": 9.395675659179688,
      "learning_rate": 1.849499732681586e-05,
      "loss": 0.2554,
      "step": 82500
    },
    {
      "epoch": 6.339265256243794,
      "grad_norm": 37.248382568359375,
      "learning_rate": 1.83040556022302e-05,
      "loss": 0.2639,
      "step": 83000
    },
    {
      "epoch": 6.3774536011609255,
      "grad_norm": 8.459151268005371,
      "learning_rate": 1.8113113877644545e-05,
      "loss": 0.2566,
      "step": 83500
    },
    {
      "epoch": 6.415641946078057,
      "grad_norm": 8.407461166381836,
      "learning_rate": 1.7922172153058887e-05,
      "loss": 0.2674,
      "step": 84000
    },
    {
      "epoch": 6.453830290995188,
      "grad_norm": 19.92375373840332,
      "learning_rate": 1.7731230428473232e-05,
      "loss": 0.2678,
      "step": 84500
    },
    {
      "epoch": 6.49201863591232,
      "grad_norm": 3.2271833419799805,
      "learning_rate": 1.7540288703887577e-05,
      "loss": 0.2487,
      "step": 85000
    },
    {
      "epoch": 6.530206980829451,
      "grad_norm": 1.807456612586975,
      "learning_rate": 1.734934697930192e-05,
      "loss": 0.264,
      "step": 85500
    },
    {
      "epoch": 6.568395325746582,
      "grad_norm": 0.8742185235023499,
      "learning_rate": 1.715840525471626e-05,
      "loss": 0.2681,
      "step": 86000
    },
    {
      "epoch": 6.6065836706637135,
      "grad_norm": 0.47028228640556335,
      "learning_rate": 1.6967463530130605e-05,
      "loss": 0.2309,
      "step": 86500
    },
    {
      "epoch": 6.644772015580845,
      "grad_norm": 0.6502563953399658,
      "learning_rate": 1.6776521805544947e-05,
      "loss": 0.2631,
      "step": 87000
    },
    {
      "epoch": 6.682960360497976,
      "grad_norm": 3.7508881092071533,
      "learning_rate": 1.6585580080959292e-05,
      "loss": 0.2559,
      "step": 87500
    },
    {
      "epoch": 6.721148705415107,
      "grad_norm": 14.914066314697266,
      "learning_rate": 1.6394638356373633e-05,
      "loss": 0.2597,
      "step": 88000
    },
    {
      "epoch": 6.759337050332238,
      "grad_norm": 15.901938438415527,
      "learning_rate": 1.620369663178798e-05,
      "loss": 0.2563,
      "step": 88500
    },
    {
      "epoch": 6.7975253952493695,
      "grad_norm": 14.233125686645508,
      "learning_rate": 1.6012754907202323e-05,
      "loss": 0.2441,
      "step": 89000
    },
    {
      "epoch": 6.835713740166501,
      "grad_norm": 0.3414585590362549,
      "learning_rate": 1.5821813182616665e-05,
      "loss": 0.2716,
      "step": 89500
    },
    {
      "epoch": 6.873902085083633,
      "grad_norm": 8.390944480895996,
      "learning_rate": 1.563087145803101e-05,
      "loss": 0.2658,
      "step": 90000
    },
    {
      "epoch": 6.912090430000764,
      "grad_norm": 0.49760687351226807,
      "learning_rate": 1.543992973344535e-05,
      "loss": 0.2517,
      "step": 90500
    },
    {
      "epoch": 6.950278774917895,
      "grad_norm": 21.84235382080078,
      "learning_rate": 1.5248988008859697e-05,
      "loss": 0.2565,
      "step": 91000
    },
    {
      "epoch": 6.988467119835026,
      "grad_norm": 0.9249453544616699,
      "learning_rate": 1.5058046284274042e-05,
      "loss": 0.2468,
      "step": 91500
    },
    {
      "epoch": 7.0266554647521575,
      "grad_norm": 0.1719362586736679,
      "learning_rate": 1.4867104559688383e-05,
      "loss": 0.2605,
      "step": 92000
    },
    {
      "epoch": 7.064843809669289,
      "grad_norm": 0.2985737919807434,
      "learning_rate": 1.4676162835102728e-05,
      "loss": 0.2513,
      "step": 92500
    },
    {
      "epoch": 7.10303215458642,
      "grad_norm": 0.32206135988235474,
      "learning_rate": 1.4485221110517072e-05,
      "loss": 0.2478,
      "step": 93000
    },
    {
      "epoch": 7.141220499503551,
      "grad_norm": 2.1343390941619873,
      "learning_rate": 1.4294279385931413e-05,
      "loss": 0.2496,
      "step": 93500
    },
    {
      "epoch": 7.179408844420683,
      "grad_norm": 18.07288360595703,
      "learning_rate": 1.4103337661345758e-05,
      "loss": 0.2385,
      "step": 94000
    },
    {
      "epoch": 7.217597189337814,
      "grad_norm": 2.5710365772247314,
      "learning_rate": 1.39123959367601e-05,
      "loss": 0.2465,
      "step": 94500
    },
    {
      "epoch": 7.2557855342549455,
      "grad_norm": 6.738758087158203,
      "learning_rate": 1.3721454212174445e-05,
      "loss": 0.2505,
      "step": 95000
    },
    {
      "epoch": 7.293973879172077,
      "grad_norm": 13.017762184143066,
      "learning_rate": 1.353051248758879e-05,
      "loss": 0.2518,
      "step": 95500
    },
    {
      "epoch": 7.332162224089208,
      "grad_norm": 0.1454649418592453,
      "learning_rate": 1.3339570763003132e-05,
      "loss": 0.2577,
      "step": 96000
    },
    {
      "epoch": 7.370350569006339,
      "grad_norm": 11.271116256713867,
      "learning_rate": 1.3148629038417477e-05,
      "loss": 0.2366,
      "step": 96500
    },
    {
      "epoch": 7.40853891392347,
      "grad_norm": 14.102458000183105,
      "learning_rate": 1.2957687313831818e-05,
      "loss": 0.2461,
      "step": 97000
    },
    {
      "epoch": 7.4467272588406015,
      "grad_norm": 0.18860508501529694,
      "learning_rate": 1.2766745589246163e-05,
      "loss": 0.2707,
      "step": 97500
    },
    {
      "epoch": 7.484915603757733,
      "grad_norm": 10.16494369506836,
      "learning_rate": 1.2575803864660507e-05,
      "loss": 0.2373,
      "step": 98000
    },
    {
      "epoch": 7.523103948674865,
      "grad_norm": 2.8103532791137695,
      "learning_rate": 1.238486214007485e-05,
      "loss": 0.2441,
      "step": 98500
    },
    {
      "epoch": 7.561292293591996,
      "grad_norm": 0.11790781468153,
      "learning_rate": 1.2193920415489193e-05,
      "loss": 0.271,
      "step": 99000
    },
    {
      "epoch": 7.599480638509127,
      "grad_norm": 0.9925351738929749,
      "learning_rate": 1.2002978690903536e-05,
      "loss": 0.2507,
      "step": 99500
    },
    {
      "epoch": 7.637668983426258,
      "grad_norm": 0.6430020928382874,
      "learning_rate": 1.181203696631788e-05,
      "loss": 0.2489,
      "step": 100000
    },
    {
      "epoch": 7.6758573283433895,
      "grad_norm": 1.6207213401794434,
      "learning_rate": 1.1621095241732225e-05,
      "loss": 0.2768,
      "step": 100500
    },
    {
      "epoch": 7.714045673260521,
      "grad_norm": 0.1914842575788498,
      "learning_rate": 1.1430153517146568e-05,
      "loss": 0.2399,
      "step": 101000
    },
    {
      "epoch": 7.752234018177652,
      "grad_norm": 33.76418685913086,
      "learning_rate": 1.1239211792560911e-05,
      "loss": 0.2578,
      "step": 101500
    },
    {
      "epoch": 7.790422363094783,
      "grad_norm": 0.5514010190963745,
      "learning_rate": 1.1048270067975255e-05,
      "loss": 0.2745,
      "step": 102000
    },
    {
      "epoch": 7.828610708011915,
      "grad_norm": 0.24419894814491272,
      "learning_rate": 1.0857328343389598e-05,
      "loss": 0.2652,
      "step": 102500
    },
    {
      "epoch": 7.866799052929046,
      "grad_norm": 21.101341247558594,
      "learning_rate": 1.0666386618803941e-05,
      "loss": 0.2378,
      "step": 103000
    },
    {
      "epoch": 7.9049873978461775,
      "grad_norm": 9.419160842895508,
      "learning_rate": 1.0475444894218285e-05,
      "loss": 0.2424,
      "step": 103500
    },
    {
      "epoch": 7.943175742763309,
      "grad_norm": 8.504898071289062,
      "learning_rate": 1.0284503169632628e-05,
      "loss": 0.256,
      "step": 104000
    },
    {
      "epoch": 7.98136408768044,
      "grad_norm": 4.782492637634277,
      "learning_rate": 1.0093561445046971e-05,
      "loss": 0.2582,
      "step": 104500
    },
    {
      "epoch": 8.019552432597571,
      "grad_norm": 17.487850189208984,
      "learning_rate": 9.902619720461316e-06,
      "loss": 0.2641,
      "step": 105000
    },
    {
      "epoch": 8.057740777514702,
      "grad_norm": 16.74688148498535,
      "learning_rate": 9.71167799587566e-06,
      "loss": 0.2355,
      "step": 105500
    },
    {
      "epoch": 8.095929122431833,
      "grad_norm": 20.714765548706055,
      "learning_rate": 9.520736271290003e-06,
      "loss": 0.231,
      "step": 106000
    },
    {
      "epoch": 8.134117467348965,
      "grad_norm": 50.70199966430664,
      "learning_rate": 9.329794546704346e-06,
      "loss": 0.2396,
      "step": 106500
    },
    {
      "epoch": 8.172305812266096,
      "grad_norm": 53.29233169555664,
      "learning_rate": 9.13885282211869e-06,
      "loss": 0.2463,
      "step": 107000
    },
    {
      "epoch": 8.210494157183227,
      "grad_norm": 19.27553939819336,
      "learning_rate": 8.947911097533033e-06,
      "loss": 0.2298,
      "step": 107500
    },
    {
      "epoch": 8.248682502100358,
      "grad_norm": 0.38581547141075134,
      "learning_rate": 8.756969372947376e-06,
      "loss": 0.2373,
      "step": 108000
    },
    {
      "epoch": 8.28687084701749,
      "grad_norm": 17.17620086669922,
      "learning_rate": 8.56602764836172e-06,
      "loss": 0.2481,
      "step": 108500
    },
    {
      "epoch": 8.325059191934622,
      "grad_norm": 5.392579555511475,
      "learning_rate": 8.375085923776065e-06,
      "loss": 0.2496,
      "step": 109000
    },
    {
      "epoch": 8.363247536851754,
      "grad_norm": 41.63316345214844,
      "learning_rate": 8.184144199190408e-06,
      "loss": 0.2637,
      "step": 109500
    },
    {
      "epoch": 8.401435881768885,
      "grad_norm": 7.807092666625977,
      "learning_rate": 7.993202474604751e-06,
      "loss": 0.2469,
      "step": 110000
    },
    {
      "epoch": 8.439624226686016,
      "grad_norm": 11.120017051696777,
      "learning_rate": 7.802260750019095e-06,
      "loss": 0.2454,
      "step": 110500
    },
    {
      "epoch": 8.477812571603147,
      "grad_norm": 1.167780876159668,
      "learning_rate": 7.611319025433437e-06,
      "loss": 0.2397,
      "step": 111000
    },
    {
      "epoch": 8.516000916520278,
      "grad_norm": 0.8853473663330078,
      "learning_rate": 7.420377300847782e-06,
      "loss": 0.2669,
      "step": 111500
    },
    {
      "epoch": 8.55418926143741,
      "grad_norm": 0.1403081715106964,
      "learning_rate": 7.2294355762621254e-06,
      "loss": 0.2481,
      "step": 112000
    },
    {
      "epoch": 8.59237760635454,
      "grad_norm": 0.39849111437797546,
      "learning_rate": 7.038493851676469e-06,
      "loss": 0.2676,
      "step": 112500
    },
    {
      "epoch": 8.630565951271672,
      "grad_norm": 0.23956739902496338,
      "learning_rate": 6.847552127090811e-06,
      "loss": 0.2281,
      "step": 113000
    },
    {
      "epoch": 8.668754296188803,
      "grad_norm": 16.296506881713867,
      "learning_rate": 6.656610402505156e-06,
      "loss": 0.2477,
      "step": 113500
    },
    {
      "epoch": 8.706942641105934,
      "grad_norm": 7.46291446685791,
      "learning_rate": 6.4656686779194996e-06,
      "loss": 0.2551,
      "step": 114000
    },
    {
      "epoch": 8.745130986023065,
      "grad_norm": 5.537749767303467,
      "learning_rate": 6.274726953333843e-06,
      "loss": 0.2646,
      "step": 114500
    },
    {
      "epoch": 8.783319330940197,
      "grad_norm": 14.058670997619629,
      "learning_rate": 6.083785228748186e-06,
      "loss": 0.2391,
      "step": 115000
    },
    {
      "epoch": 8.821507675857328,
      "grad_norm": 0.6137887835502625,
      "learning_rate": 5.8928435041625295e-06,
      "loss": 0.2376,
      "step": 115500
    },
    {
      "epoch": 8.859696020774459,
      "grad_norm": 0.47878482937812805,
      "learning_rate": 5.701901779576874e-06,
      "loss": 0.2248,
      "step": 116000
    },
    {
      "epoch": 8.89788436569159,
      "grad_norm": 0.9939274787902832,
      "learning_rate": 5.510960054991217e-06,
      "loss": 0.2483,
      "step": 116500
    },
    {
      "epoch": 8.936072710608721,
      "grad_norm": 17.498517990112305,
      "learning_rate": 5.320018330405561e-06,
      "loss": 0.2471,
      "step": 117000
    },
    {
      "epoch": 8.974261055525854,
      "grad_norm": 0.3158620595932007,
      "learning_rate": 5.129076605819904e-06,
      "loss": 0.2395,
      "step": 117500
    },
    {
      "epoch": 9.012449400442986,
      "grad_norm": 16.087156295776367,
      "learning_rate": 4.938134881234248e-06,
      "loss": 0.2478,
      "step": 118000
    },
    {
      "epoch": 9.050637745360117,
      "grad_norm": 0.20076848566532135,
      "learning_rate": 4.747193156648591e-06,
      "loss": 0.2126,
      "step": 118500
    },
    {
      "epoch": 9.088826090277248,
      "grad_norm": 18.471643447875977,
      "learning_rate": 4.5562514320629344e-06,
      "loss": 0.2682,
      "step": 119000
    },
    {
      "epoch": 9.12701443519438,
      "grad_norm": 8.81783390045166,
      "learning_rate": 4.365309707477279e-06,
      "loss": 0.2389,
      "step": 119500
    },
    {
      "epoch": 9.16520278011151,
      "grad_norm": 0.23712675273418427,
      "learning_rate": 4.174367982891621e-06,
      "loss": 0.2473,
      "step": 120000
    },
    {
      "epoch": 9.203391125028642,
      "grad_norm": 16.373945236206055,
      "learning_rate": 3.983426258305965e-06,
      "loss": 0.2333,
      "step": 120500
    },
    {
      "epoch": 9.241579469945773,
      "grad_norm": 9.088841438293457,
      "learning_rate": 3.7924845337203086e-06,
      "loss": 0.2537,
      "step": 121000
    },
    {
      "epoch": 9.279767814862904,
      "grad_norm": 0.28555241227149963,
      "learning_rate": 3.6015428091346523e-06,
      "loss": 0.2318,
      "step": 121500
    },
    {
      "epoch": 9.317956159780035,
      "grad_norm": 0.1986660361289978,
      "learning_rate": 3.4106010845489956e-06,
      "loss": 0.2312,
      "step": 122000
    },
    {
      "epoch": 9.356144504697166,
      "grad_norm": 0.18439681828022003,
      "learning_rate": 3.2196593599633394e-06,
      "loss": 0.2635,
      "step": 122500
    },
    {
      "epoch": 9.394332849614297,
      "grad_norm": 13.836210250854492,
      "learning_rate": 3.0287176353776827e-06,
      "loss": 0.2432,
      "step": 123000
    },
    {
      "epoch": 9.432521194531429,
      "grad_norm": 69.16944885253906,
      "learning_rate": 2.8377759107920264e-06,
      "loss": 0.2646,
      "step": 123500
    },
    {
      "epoch": 9.47070953944856,
      "grad_norm": 12.72176456451416,
      "learning_rate": 2.6468341862063698e-06,
      "loss": 0.2617,
      "step": 124000
    },
    {
      "epoch": 9.508897884365691,
      "grad_norm": 0.22945483028888702,
      "learning_rate": 2.4558924616207135e-06,
      "loss": 0.2465,
      "step": 124500
    },
    {
      "epoch": 9.547086229282822,
      "grad_norm": 0.40071621537208557,
      "learning_rate": 2.264950737035057e-06,
      "loss": 0.2535,
      "step": 125000
    },
    {
      "epoch": 9.585274574199953,
      "grad_norm": 0.3415454030036926,
      "learning_rate": 2.0740090124494006e-06,
      "loss": 0.2507,
      "step": 125500
    },
    {
      "epoch": 9.623462919117085,
      "grad_norm": 13.619522094726562,
      "learning_rate": 1.883067287863744e-06,
      "loss": 0.2292,
      "step": 126000
    },
    {
      "epoch": 9.661651264034216,
      "grad_norm": 0.44193190336227417,
      "learning_rate": 1.6921255632780876e-06,
      "loss": 0.2347,
      "step": 126500
    },
    {
      "epoch": 9.699839608951349,
      "grad_norm": 44.76580810546875,
      "learning_rate": 1.501183838692431e-06,
      "loss": 0.2204,
      "step": 127000
    },
    {
      "epoch": 9.73802795386848,
      "grad_norm": 5.926690578460693,
      "learning_rate": 1.3102421141067747e-06,
      "loss": 0.2452,
      "step": 127500
    },
    {
      "epoch": 9.776216298785611,
      "grad_norm": 0.9525282979011536,
      "learning_rate": 1.1193003895211182e-06,
      "loss": 0.2151,
      "step": 128000
    },
    {
      "epoch": 9.814404643702742,
      "grad_norm": 0.7455090880393982,
      "learning_rate": 9.283586649354618e-07,
      "loss": 0.2351,
      "step": 128500
    },
    {
      "epoch": 9.852592988619874,
      "grad_norm": 1.9444575309753418,
      "learning_rate": 7.374169403498053e-07,
      "loss": 0.2745,
      "step": 129000
    },
    {
      "epoch": 9.890781333537005,
      "grad_norm": 52.323150634765625,
      "learning_rate": 5.464752157641488e-07,
      "loss": 0.2349,
      "step": 129500
    },
    {
      "epoch": 9.928969678454136,
      "grad_norm": 8.839405059814453,
      "learning_rate": 3.5553349117849236e-07,
      "loss": 0.2635,
      "step": 130000
    },
    {
      "epoch": 9.967158023371267,
      "grad_norm": 1.1357852220535278,
      "learning_rate": 1.6459176659283587e-07,
      "loss": 0.2131,
      "step": 130500
    },
    {
      "epoch": 10.0,
      "step": 130930,
      "total_flos": 2.4450933594903552e+17,
      "train_loss": 0.2816662991100624,
      "train_runtime": 20033.2347,
      "train_samples_per_second": 52.285,
      "train_steps_per_second": 6.536
    }
  ],
  "logging_steps": 500,
  "max_steps": 130930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4450933594903552e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
